{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: opendatatoronto\n",
      "\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'tidyjson'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.2     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyjson\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mdplyr\u001b[39m::filter(), \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m       masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "Linking to GEOS 3.11.2, GDAL 3.8.2, PROJ 9.3.1; sf_use_s2() is TRUE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load all required libraries for the notebook, including data package\n",
    "if(!require(\"opendatatoronto\")) {\n",
    "    install.packages(\"opendatatoronto\")\n",
    "    library(opendatatoronto)\n",
    "}\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "library(ggplot2)\n",
    "library(ggspatial)\n",
    "library(tidyjson)\n",
    "library(tidyverse)\n",
    "library(tidygeocoder)\n",
    "library(sf)\n",
    "library(mapview)\n",
    "library(opendatatoronto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Traffice\n",
    "# output Data Description:\n",
    "# Dataframe with all intersection and daily count ( peak 4 hours), including lng / lat\n",
    "\n",
    "# ? and todo:\n",
    "# is separate street name needed\n",
    "# direction of the street to be determined. How?\n",
    "\n",
    "\n",
    "# package_traffic <- show_package(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# get all resources for this package\n",
    "resources <- list_package_resources(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "datastore_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"geojson\"))\n",
    "\n",
    "# load data\n",
    "location <- filter(datastore_resources, row_number() == 1) %>% get_resource()\n",
    "traffic1 <- filter(datastore_resources, row_number() == 3) %>% get_resource()\n",
    "traffic2 <- filter(datastore_resources, row_number() == 4) %>% get_resource()\n",
    "traffic3 <- filter(datastore_resources, row_number() == 5) %>% get_resource()\n",
    "traffic4 <- filter(datastore_resources, row_number() == 6) %>% get_resource()\n",
    "traffic5 <- filter(datastore_resources, row_number() == 7) %>% get_resource()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'count_date', 'location_id', 'location',\n",
      "'lng', 'lat'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'count_date', 'location_id', 'location',\n",
      "'lng'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'count_date', 'location_id', 'location',\n",
      "'lng', 'lat'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'count_date', 'location_id', 'location',\n",
      "'lng'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'count_date', 'location_id', 'location',\n",
      "'lng', 'lat'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'count_date', 'location_id', 'location',\n",
      "'lng'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'count_date', 'location_id', 'location',\n",
      "'lng', 'lat'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'count_date', 'location_id', 'location',\n",
      "'lng'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'count_date', 'location_id', 'location',\n",
      "'lng', 'lat'. You can override using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'count_date', 'location_id', 'location',\n",
      "'lng'. You can override using the `.groups` argument.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A grouped_df: 6 × 10</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>count_date</th><th scope=col>location_id</th><th scope=col>location</th><th scope=col>lng</th><th scope=col>lat</th><th scope=col>total_int_traffic</th><th scope=col>nb_exit_traffic</th><th scope=col>sb_exit_traffic</th><th scope=col>wb_exit_traffic</th><th scope=col>eb_exit_traffic</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1984-01-03</td><td>4167</td><td>DUNDAS ST AT SPADINA AVE (PX 277)            </td><td>-79.39805</td><td>43.65294</td><td>8407</td><td>3286</td><td>2540</td><td>1545</td><td>1036</td></tr>\n",
       "\t<tr><td>1984-01-03</td><td>4386</td><td>DUNDAS ST AT SCARLETT RD (PX 496)            </td><td>-79.49921</td><td>43.66552</td><td>9414</td><td>1845</td><td>   0</td><td>4736</td><td>2833</td></tr>\n",
       "\t<tr><td>1984-01-03</td><td>5292</td><td>BAY ST AT DUNDAS ST W (PX 66)                </td><td>-79.38377</td><td>43.65571</td><td>8238</td><td>2545</td><td>2046</td><td>1643</td><td>2004</td></tr>\n",
       "\t<tr><td>1984-01-04</td><td>4993</td><td>EGLINTON AVE AT SPADINA RD (PX 99)           </td><td>-79.41911</td><td>43.70235</td><td>7868</td><td>   0</td><td>1539</td><td>4076</td><td>2253</td></tr>\n",
       "\t<tr><td>1984-01-04</td><td>5349</td><td>DUFFERIN ST AT DUNDAS ST W (PX 190)          </td><td>-79.43145</td><td>43.64965</td><td>6514</td><td>1685</td><td>1084</td><td>1820</td><td>1925</td></tr>\n",
       "\t<tr><td>1984-01-04</td><td>5589</td><td>DIXON AVE AT DUNDAS ST &amp; KINGSTON RD (PX 163)</td><td>-79.31118</td><td>43.66997</td><td>4625</td><td>2348</td><td>1075</td><td>1202</td><td><span style=white-space:pre-wrap>   0</span></td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A grouped\\_df: 6 × 10\n",
       "\\begin{tabular}{llllllllll}\n",
       " count\\_date & location\\_id & location & lng & lat & total\\_int\\_traffic & nb\\_exit\\_traffic & sb\\_exit\\_traffic & wb\\_exit\\_traffic & eb\\_exit\\_traffic\\\\\n",
       " <chr> & <int> & <chr> & <dbl> & <dbl> & <int> & <int> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t 1984-01-03 & 4167 & DUNDAS ST AT SPADINA AVE (PX 277)             & -79.39805 & 43.65294 & 8407 & 3286 & 2540 & 1545 & 1036\\\\\n",
       "\t 1984-01-03 & 4386 & DUNDAS ST AT SCARLETT RD (PX 496)             & -79.49921 & 43.66552 & 9414 & 1845 &    0 & 4736 & 2833\\\\\n",
       "\t 1984-01-03 & 5292 & BAY ST AT DUNDAS ST W (PX 66)                 & -79.38377 & 43.65571 & 8238 & 2545 & 2046 & 1643 & 2004\\\\\n",
       "\t 1984-01-04 & 4993 & EGLINTON AVE AT SPADINA RD (PX 99)            & -79.41911 & 43.70235 & 7868 &    0 & 1539 & 4076 & 2253\\\\\n",
       "\t 1984-01-04 & 5349 & DUFFERIN ST AT DUNDAS ST W (PX 190)           & -79.43145 & 43.64965 & 6514 & 1685 & 1084 & 1820 & 1925\\\\\n",
       "\t 1984-01-04 & 5589 & DIXON AVE AT DUNDAS ST \\& KINGSTON RD (PX 163) & -79.31118 & 43.66997 & 4625 & 2348 & 1075 & 1202 &    0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A grouped_df: 6 × 10\n",
       "\n",
       "| count_date &lt;chr&gt; | location_id &lt;int&gt; | location &lt;chr&gt; | lng &lt;dbl&gt; | lat &lt;dbl&gt; | total_int_traffic &lt;int&gt; | nb_exit_traffic &lt;int&gt; | sb_exit_traffic &lt;int&gt; | wb_exit_traffic &lt;int&gt; | eb_exit_traffic &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1984-01-03 | 4167 | DUNDAS ST AT SPADINA AVE (PX 277)             | -79.39805 | 43.65294 | 8407 | 3286 | 2540 | 1545 | 1036 |\n",
       "| 1984-01-03 | 4386 | DUNDAS ST AT SCARLETT RD (PX 496)             | -79.49921 | 43.66552 | 9414 | 1845 |    0 | 4736 | 2833 |\n",
       "| 1984-01-03 | 5292 | BAY ST AT DUNDAS ST W (PX 66)                 | -79.38377 | 43.65571 | 8238 | 2545 | 2046 | 1643 | 2004 |\n",
       "| 1984-01-04 | 4993 | EGLINTON AVE AT SPADINA RD (PX 99)            | -79.41911 | 43.70235 | 7868 |    0 | 1539 | 4076 | 2253 |\n",
       "| 1984-01-04 | 5349 | DUFFERIN ST AT DUNDAS ST W (PX 190)           | -79.43145 | 43.64965 | 6514 | 1685 | 1084 | 1820 | 1925 |\n",
       "| 1984-01-04 | 5589 | DIXON AVE AT DUNDAS ST &amp; KINGSTON RD (PX 163) | -79.31118 | 43.66997 | 4625 | 2348 | 1075 | 1202 |    0 |\n",
       "\n"
      ],
      "text/plain": [
       "  count_date location_id location                                     \n",
       "1 1984-01-03 4167        DUNDAS ST AT SPADINA AVE (PX 277)            \n",
       "2 1984-01-03 4386        DUNDAS ST AT SCARLETT RD (PX 496)            \n",
       "3 1984-01-03 5292        BAY ST AT DUNDAS ST W (PX 66)                \n",
       "4 1984-01-04 4993        EGLINTON AVE AT SPADINA RD (PX 99)           \n",
       "5 1984-01-04 5349        DUFFERIN ST AT DUNDAS ST W (PX 190)          \n",
       "6 1984-01-04 5589        DIXON AVE AT DUNDAS ST & KINGSTON RD (PX 163)\n",
       "  lng       lat      total_int_traffic nb_exit_traffic sb_exit_traffic\n",
       "1 -79.39805 43.65294 8407              3286            2540           \n",
       "2 -79.49921 43.66552 9414              1845               0           \n",
       "3 -79.38377 43.65571 8238              2545            2046           \n",
       "4 -79.41911 43.70235 7868                 0            1539           \n",
       "5 -79.43145 43.64965 6514              1685            1084           \n",
       "6 -79.31118 43.66997 4625              2348            1075           \n",
       "  wb_exit_traffic eb_exit_traffic\n",
       "1 1545            1036           \n",
       "2 4736            2833           \n",
       "3 1643            2004           \n",
       "4 4076            2253           \n",
       "5 1820            1925           \n",
       "6 1202               0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clean and transform load - Traffic Data\n",
    "# Output data for modelling CleanTraffic\n",
    "# define parameters for cleaning\n",
    "peakhours <- 4 # number of peak hours of data per day. value should be between 1 and 10\n",
    "\n",
    "\n",
    "clean_T1 <- traffic1 %>%\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"centreline_type\",\n",
    "    \"time_start\", \"sb_cars_r\", \"sb_cars_t\", \"sb_cars_l\",\n",
    "    \"nb_cars_r\", \"nb_cars_t\", \"nb_cars_l\", \"wb_cars_r\", \"wb_cars_t\", \"wb_cars_l\",\n",
    "    \"eb_cars_r\", \"eb_cars_t\", \"eb_cars_l\"\n",
    "  ))) %>% # select needed attributes\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t + eb_cars_l + wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t + eb_cars_r + wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t + nb_cars_l + sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t + nb_cars_r + sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) # aggregate daily peak hour volume\n",
    "clean_T2 <- traffic2 %>%\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"centreline_type\",\n",
    "    \"time_start\", \"sb_cars_r\", \"sb_cars_t\", \"sb_cars_l\",\n",
    "    \"nb_cars_r\", \"nb_cars_t\", \"nb_cars_l\", \"wb_cars_r\", \"wb_cars_t\", \"wb_cars_l\",\n",
    "    \"eb_cars_r\", \"eb_cars_t\", \"eb_cars_l\"\n",
    "  ))) %>% # select needed attributes\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t + eb_cars_l + wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t + eb_cars_r + wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t + nb_cars_l + sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t + nb_cars_r + sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggsregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T3 <- traffic3 %>%\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"centreline_type\",\n",
    "    \"time_start\", \"sb_cars_r\", \"sb_cars_t\", \"sb_cars_l\",\n",
    "    \"nb_cars_r\", \"nb_cars_t\", \"nb_cars_l\", \"wb_cars_r\", \"wb_cars_t\", \"wb_cars_l\",\n",
    "    \"eb_cars_r\", \"eb_cars_t\", \"eb_cars_l\"\n",
    "  ))) %>% # select needed attributes\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t + eb_cars_l + wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t + eb_cars_r + wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t + nb_cars_l + sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t + nb_cars_r + sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T4 <- traffic4 %>%\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"centreline_type\",\n",
    "    \"time_start\", \"sb_cars_r\", \"sb_cars_t\", \"sb_cars_l\",\n",
    "    \"nb_cars_r\", \"nb_cars_t\", \"nb_cars_l\", \"wb_cars_r\", \"wb_cars_t\", \"wb_cars_l\",\n",
    "    \"eb_cars_r\", \"eb_cars_t\", \"eb_cars_l\"\n",
    "  ))) %>% # select needed attributes\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t + eb_cars_l + wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t + eb_cars_r + wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t + nb_cars_l + sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t + nb_cars_r + sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T5 <- traffic5 %>%\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"centreline_type\",\n",
    "    \"time_start\", \"sb_cars_r\", \"sb_cars_t\", \"sb_cars_l\",\n",
    "    \"nb_cars_r\", \"nb_cars_t\", \"nb_cars_l\", \"wb_cars_r\", \"wb_cars_t\", \"wb_cars_l\",\n",
    "    \"eb_cars_r\", \"eb_cars_t\", \"eb_cars_l\"\n",
    "  ))) %>% # select needed attributes\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t + eb_cars_l + wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t + eb_cars_r + wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t + nb_cars_l + sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t + nb_cars_r + sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "\n",
    "CleanTraffic <- bind_rows(clean_T1, clean_T2, clean_T3, clean_T4, clean_T5)\n",
    "head(CleanTraffic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>address</dt><dd>'character'</dd><dt>lat</dt><dd>'character'</dd><dt>lng</dt><dd>'character'</dd><dt>carpark_type</dt><dd>'character'</dd><dt>rate_half_hr</dt><dd>'character'</dd><dt>capacity</dt><dd>'character'</dd><dt>rate</dt><dd>'character'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[address] 'character'\n",
       "\\item[lat] 'character'\n",
       "\\item[lng] 'character'\n",
       "\\item[carpark\\textbackslash{}\\_type] 'character'\n",
       "\\item[rate\\textbackslash{}\\_half\\textbackslash{}\\_hr] 'character'\n",
       "\\item[capacity] 'character'\n",
       "\\item[rate] 'character'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "address\n",
       ":   'character'lat\n",
       ":   'character'lng\n",
       ":   'character'carpark_type\n",
       ":   'character'rate_half_hr\n",
       ":   'character'capacity\n",
       ":   'character'rate\n",
       ":   'character'\n",
       "\n"
      ],
      "text/plain": [
       "     address          lat          lng carpark_type rate_half_hr     capacity \n",
       " \"character\"  \"character\"  \"character\"  \"character\"  \"character\"  \"character\" \n",
       "        rate \n",
       " \"character\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>address</dt><dd>'character'</dd><dt>lat</dt><dd>'numeric'</dd><dt>lng</dt><dd>'numeric'</dd><dt>carpark_type</dt><dd>'character'</dd><dt>rate_half_hr</dt><dd>'numeric'</dd><dt>capacity</dt><dd>'numeric'</dd><dt>rate</dt><dd>'character'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[address] 'character'\n",
       "\\item[lat] 'numeric'\n",
       "\\item[lng] 'numeric'\n",
       "\\item[carpark\\textbackslash{}\\_type] 'character'\n",
       "\\item[rate\\textbackslash{}\\_half\\textbackslash{}\\_hr] 'numeric'\n",
       "\\item[capacity] 'numeric'\n",
       "\\item[rate] 'character'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "address\n",
       ":   'character'lat\n",
       ":   'numeric'lng\n",
       ":   'numeric'carpark_type\n",
       ":   'character'rate_half_hr\n",
       ":   'numeric'capacity\n",
       ":   'numeric'rate\n",
       ":   'character'\n",
       "\n"
      ],
      "text/plain": [
       "     address          lat          lng carpark_type rate_half_hr     capacity \n",
       " \"character\"    \"numeric\"    \"numeric\"  \"character\"    \"numeric\"    \"numeric\" \n",
       "        rate \n",
       " \"character\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "FALSE"
      ],
      "text/latex": [
       "FALSE"
      ],
      "text/markdown": [
       "FALSE"
      ],
      "text/plain": [
       "[1] FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing 220 coordinates to the Nominatim single coordinate geocoder\n",
      "\n",
      "Query completed in: 225.5 seconds\n",
      "\n",
      "\u001b[1m\u001b[22mNew names:\n",
      "\u001b[36m•\u001b[39m `address` -> `address...1`\n",
      "\u001b[36m•\u001b[39m `address` -> `address...9`\n"
     ]
    }
   ],
   "source": [
    "# Get Green P Parking package from Open Data-Toronto\n",
    "package <- show_package(\"b66466c3-69c8-4825-9c8b-04b270069193\")\n",
    "\n",
    "data=as.data.frame('Green P Parking')  # read the dataset Green P Parking in the package \n",
    "data<-show_package(package)\n",
    "\n",
    "resources<-list_package_resources(package)\n",
    "\n",
    "# Identify resources\n",
    "data_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"json\"))\n",
    "\n",
    "# Load Green P Parking 2019 data\n",
    "data <- filter(data_resources, row_number() == 1) %>% get_resource()\n",
    "\n",
    "# Extract required columns from main data\n",
    "data<- data.frame(address=data$carparks$address,\n",
    "                                     lat=data$carparks$lat,\n",
    "                                     lng=data$carparks$lng,\n",
    "                                      carpark_type=data$carparks$carpark_type_str,\n",
    "                                      rate_half_hr=data$carparks$rate_half_hour,\n",
    "                                      capacity=data$carparks$capacity,\n",
    "                                      rate=data$carparks$rate_half_hour\n",
    "                  )\n",
    "\n",
    "# Check class of each attribute\n",
    "sapply(data, class) \n",
    "\n",
    "# Convert char to numeric class\n",
    "data$lat<-as.numeric(data$lat)\n",
    "data$lng<-as.numeric(data$lng)\n",
    "data$rate_half_hr<-as.numeric(data$rate_half_hr)\n",
    "data$capacity<-as.numeric(data$capacity)\n",
    "\n",
    "sapply(data, class) \n",
    "\n",
    "# Check for missing values\n",
    "any(is.na(data))\n",
    "\n",
    "# Extract street name from address\n",
    "data <- data %>%\n",
    "  mutate(extracted_address = str_replace_all(data$address, \"\\\\(.*?\\\\)\",\"\"))\n",
    "\n",
    "data$extracted_address<-str_replace_all(data$extracted_address, \"-.*\", \"\")\n",
    "data$extracted_address<-str_replace_all(data$extracted_address, \",.*\", \"\")\n",
    "\n",
    "# Extract data with carpark_type as 'Surface'\n",
    "data <- data %>%\n",
    "  filter(carpark_type == \"Surface\")\n",
    "\n",
    "# Convert Lat/Lng to address\n",
    "geo_rev_data<-data %>%\n",
    "  tidygeocoder::reverse_geocode(\n",
    "    lat=lat,\n",
    "    long=lng,\n",
    "    method=\"osm\")\n",
    "\n",
    "# Plot map\n",
    "map<-data %>%\n",
    "  st_as_sf(\n",
    "    coords=c(\"lng\",\"lat\"),\n",
    "    crs=4326\n",
    "  )\n",
    "\n",
    "map %>% mapview()\n",
    "\n",
    "# Define the polygon coordinates\n",
    "polygon_coords <- matrix(c(\n",
    "  -79.4289964889767, 43.6700360241176, -79.4226792245877, 43.6543887000655, -79.4000484228339, 43.657948514946, -79.4070875693025, 43.6748646586934,-79.4289964889767, 43.6700360241176  # Repeat first point to close the polygon exactly\n",
    "), ncol = 2, byrow = TRUE)\n",
    "\n",
    "# Create a polygon geometry\n",
    "polygon <- st_polygon(list(polygon_coords))\n",
    "\n",
    "# Convert the polygon object to an 'sf' object with a specified CRS (Coordinate Reference System)\n",
    "polygon <- st_sfc(polygon, crs = 4326)\n",
    "\n",
    "# Convert the data frame 'data' to an 'sf' object, specifying the columns containing longitude and latitude as coordinates, and set the CRS\n",
    "data_sf <- st_as_sf(data, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Find the indices of the rows in 'data_sf' that fall within the polygon\n",
    "indices <- st_within(data_sf, polygon)\n",
    "\n",
    "# Convert the indices to a data frame\n",
    "indices_df<-data.frame(indices)\n",
    "\n",
    "selected_rows <- data_sf[match(indices_df$row.id, seq_len(nrow(data))), ]\n",
    "\n",
    "# Plot selected rows on map\n",
    "map_df <- selected_rows %>%\n",
    "  st_as_sf() %>%\n",
    "  st_set_crs(4326) %>%\n",
    "  fortify()   # Convert the 'sf' object to a format suitable for use with 'ggplot2'\n",
    "\n",
    "# Display the spatial object using 'mapview'\n",
    "mapview(map_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple feature collection with 8 features and 6 fields\n",
      "Geometry type: POINT\n",
      "Dimension:     XY\n",
      "Bounding box:  xmin: -79.42565 ymin: 43.65635 xmax: -79.40412 ymax: 43.66688\n",
      "Geodetic CRS:  WGS 84\n",
      "                                    address carpark_type rate_half_hr capacity\n",
      "16                    365 Lippincott Street      Surface          2.0      144\n",
      "27                    557 Palmerston Avenue      Surface          2.0       55\n",
      "33                       675 Manning Avenue      Surface          2.0       49\n",
      "34  745 Ossington Avenue, 16 Carling Avenue      Surface          2.0       45\n",
      "48                       376 Clinton Street      Surface          1.5       33\n",
      "90                        80 Clinton Street      Surface          1.5       25\n",
      "110                          4 Spadina Road      Surface          1.5       51\n",
      "121                    292 Brunswick Avenue      Surface          2.0       19\n",
      "    rate     extracted_address                   geometry\n",
      "16  2.00 365 Lippincott Street POINT (-79.40966 43.66505)\n",
      "27  2.00 557 Palmerston Avenue POINT (-79.41358 43.66504)\n",
      "33  2.00    675 Manning Avenue POINT (-79.41601 43.66465)\n",
      "34  2.00  745 Ossington Avenue POINT (-79.42565 43.66243)\n",
      "48  1.50    376 Clinton Street POINT (-79.41758 43.66444)\n",
      "90  1.50     80 Clinton Street POINT (-79.41455 43.65635)\n",
      "110 1.50        4 Spadina Road POINT (-79.40412 43.66688)\n",
      "121 2.00  292 Brunswick Avenue POINT (-79.40764 43.66537)\n"
     ]
    }
   ],
   "source": [
    "# Store output in a csv file\n",
    "write.csv(selected_rows, \"Parking.csv\", row.names = FALSE)\n",
    "print(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Intersection\n",
    "# output Data Description:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Business\n",
    "# output Data Description: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define Region of Interest - Boundary\n",
    "## coordinates manually looked up from location dataset\n",
    "# 1406\t5370\tDUPONT ST AT OSSINGTON AVE (PX 842)\t-79.429019\t43.670031996501194\n",
    "# 251\t4180\tDUPONT ST AT SPADINA RD (PX 840)\t-79.407122\t43.67485699954096\n",
    "# 1885\t5864\tCOLLEGE ST AT OSSINGTON AVE (PX 829)\t-79.422705\t43.65439999619167\n",
    "# 241\t4170\tCOLLEGE ST AT SPADINA AVE (PX 279)\t-79.400048\t43.65794800150128\n",
    "\n",
    "# Input\n",
    "# Output\n",
    "\n",
    "boundary <- location %>%\n",
    "  select(location_id, location, lng, lat) %>%\n",
    "  filter(location_id %in% list(5370, 4180, 5864, 4170)) # boundary intersection ID\n",
    "\n",
    "lng_min <- min(boundary$lng) # west most value since it's negative\n",
    "lng_max <- max(boundary$lng) # east most value\n",
    "lat_min <- min(boundary$lat) # south most value\n",
    "lat_max <- max(boundary$lat) # north most value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine Data for model building\n",
    "# what is the expected output of data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1 - Time Series Forecast\n",
    "# additional data processing needed before modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in `st_geometry<-.data.frame`(`*tmp*`, value = value): inherits(value, \"sfc\") || is.character(value) is not TRUE\n",
     "output_type": "error",
     "traceback": [
      "Error in `st_geometry<-.data.frame`(`*tmp*`, value = value): inherits(value, \"sfc\") || is.character(value) is not TRUE\nTraceback:\n",
      "1. st_set_geometry(parking_data, NULL)",
      "2. `st_geometry<-`(`*tmp*`, value = value)",
      "3. `st_geometry<-.data.frame`(`*tmp*`, value = value)",
      "4. stopifnot(inherits(value, \"sfc\") || is.character(value))"
     ]
    }
   ],
   "source": [
    "parking_data<-read.csv(\"Parking.csv\")\n",
    "\n",
    "# Convert the parking dataset to a spatial object\n",
    "# Convert geometry column to latitude and longitude columns\n",
    "parking_data <- st_set_geometry(parking_data, NULL)  # Remove geometry column\n",
    "parking_data$latitude <- st_coordinates(parking_data)[, \"Y\"]\n",
    "parking_data$longitude <- st_coordinates(parking_data)[, \"X\"]\n",
    "parking_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in `[.data.frame`(x, coords): undefined columns selected\n",
     "output_type": "error",
     "traceback": [
      "Error in `[.data.frame`(x, coords): undefined columns selected\nTraceback:\n",
      "1. st_as_sf(parking, coords = c(\"lng\", \"lat\"), crs = 4326)",
      "2. st_as_sf.data.frame(parking, coords = c(\"lng\", \"lat\"), crs = 4326)",
      "3. as.data.frame(lapply(x[coords], as.numeric))",
      "4. lapply(x[coords], as.numeric)",
      "5. x[coords]",
      "6. `[.data.frame`(x, coords)",
      "7. stop(\"undefined columns selected\")"
     ]
    }
   ],
   "source": [
    "## Model 2 - Regression Model\n",
    "\n",
    "# Read data\n",
    "parking<-read.csv(\"Parking.csv\")\n",
    "business<-read.csv(\"business.csv\")\n",
    "\n",
    "# Convert the business dataset to a spatial object\n",
    "business_sf <- st_as_sf(business, coords = c(\"long\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Convert the parking dataset to a spatial object\n",
    "parking_sf <- st_as_sf(parking, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Perform a spatial join to find the nearest business for each parking space\n",
    "nearest_business <- st_nearest_feature(parking_sf, business_sf)\n",
    "\n",
    "# Add the nearest business information to the parking dataset\n",
    "parking_data_with_nearest_business <- cbind(parking, nearest_business)\n",
    "parking$traffic_volume= sample(2:200,nrow(parking), replace=F)  # To be replaced with traffic data\n",
    "\n",
    "# An empty list to store the results\n",
    "result_list <- list()\n",
    "parking_data_with_nearest_business <- parking\n",
    "\n",
    "\n",
    "# An empty list to store the results\n",
    "result_list <- list()\n",
    "\n",
    "# Function to calculate angular distance between two points on Earth\n",
    "haversine_distance <- function(lon1, lat1, lon2, lat2) {\n",
    "  R <- 6371 # Earth radius in km\n",
    "  dlat <- (lat2 - lat1) * pi / 180\n",
    "  dlon <- (lon2 - lon1) * pi / 180\n",
    "  a <- sin(dlat/2)^2 + cos(lat1 * pi / 180) * cos(lat2 * pi / 180) * sin(dlon/2)^2\n",
    "  c <- 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "  distance <- R * c\n",
    "  return(distance) # Distance in km\n",
    "}\n",
    "    \n",
    "View(parking_data_with_nearest_business)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in data.frame(address = character(), lat = double(), lng = double(), : argument is missing, with no default\n",
     "output_type": "error",
     "traceback": [
      "Error in data.frame(address = character(), lat = double(), lng = double(), : argument is missing, with no default\nTraceback:\n",
      "1. data.frame(address = character(), lat = double(), lng = double(), \n .     distance = double(), capacity = integer(), traffic_volume = integer(), \n .     rate_half_hr = double(), n_customers = integer(), time_spent = double(), \n .     category = character(), interaction_term = integer(), )"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the results\n",
    "result_list <- list()\n",
    "\n",
    "for (i in 1:nrow(parking_data_with_nearest_business)){\n",
    "  \n",
    "  # Create a temporary data frame to store the results for this parking spot\n",
    "  temp_df <- data.frame(\n",
    "    address = character(),\n",
    "    lat = double(),\n",
    "    lng = double(),\n",
    "    distance = double(),\n",
    "    capacity = integer(),\n",
    "    traffic_volume = integer(),\n",
    "    rate_half_hr= double(),\n",
    "    #n_business = integer(),\n",
    "    n_customers =integer(),\n",
    "    time_spent = double(),\n",
    "    category = character(),\n",
    "    interaction_term = integer(),\n",
    "  )\n",
    "  \n",
    "  for( j in 1:nrow(business)){\n",
    "    lon1 <- parking_data_with_nearest_business[i,\"lng\"]\n",
    "    lat1 <- parking_data_with_nearest_business[i,\"lat\"]\n",
    "    lon2 <- business[j, \"long\"]\n",
    "    lat2 <- business[j, \"lat\"]\n",
    "    \n",
    "    # Calculate distance\n",
    "    distance <- st_distance(st_point(c(lon1, lat1)), st_point(c(lon2, lat2)))\n",
    "    \n",
    "    # Store the results in the temporary data frame\n",
    "    temp_df[nrow(temp_df) + 1, ] <- list(\n",
    "      address = parking_data_with_nearest_business[i,\"address\"],\n",
    "      lat = parking_data_with_nearest_business[i,\"lat\"],\n",
    "      lng = parking_data_with_nearest_business[i,\"lng\"],\n",
    "      distance = distance,\n",
    "      capacity = parking_data_with_nearest_business[i,\"capacity\"],\n",
    "      traffic_volume = parking_data_with_nearest_business[i,\"traffic_volume\"],\n",
    "      #n_business = parking_data_with_nearest_business[i,\"nearest_business\"],\n",
    "      rate_half_hr = parking_data_with_nearest_business[i,\"rate_half_hr\"],\n",
    "      n_customers = business[j,\"qCustomer\"],\n",
    "      time_spent = business[j,\"tCustomer\"],\n",
    "      category = business[j,\"Category\"],\n",
    "      interaction_term = business[j,\"qCustomer\"] * business[j,\"tCustomer\"]\n",
    "    )\n",
    "  }\n",
    "  \n",
    "  # Append the temporary data frame to the result list\n",
    "  result_list[[i]] <- temp_df\n",
    "}\n",
    "\n",
    "# Combine all the results into a single data frame\n",
    "result_df <- do.call(rbind, result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in x[[jj]][iseq] <- vjj: replacement has length zero\n",
     "output_type": "error",
     "traceback": [
      "Error in x[[jj]][iseq] <- vjj: replacement has length zero\nTraceback:\n",
      "1. `[<-`(`*tmp*`, nrow(temp_df) + 1, , value = list(address = \"Surface\", \n .     lat = NULL, lng = NULL, distance = numeric(0), capacity = 2, \n .     traffic_volume = 156L, rate_half_hr = 144L, n_customers = 5L, \n .     time_spent = 0.469866224, category = \"PRIVATE PARKING ENFORCEMENT AGENCY\", \n .     interaction_term = 2.34933112))",
      "2. `[<-.data.frame`(`*tmp*`, nrow(temp_df) + 1, , value = list(address = \"Surface\", \n .     lat = NULL, lng = NULL, distance = numeric(0), capacity = 2, \n .     traffic_volume = 156L, rate_half_hr = 144L, n_customers = 5L, \n .     time_spent = 0.469866224, category = \"PRIVATE PARKING ENFORCEMENT AGENCY\", \n .     interaction_term = 2.34933112))"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Iterate through each parking spot and business data\n",
    "for (i in 1:nrow(parking_data_with_nearest_business)){\n",
    "  \n",
    "  # A temporary data frame to store the results for this parking spot\n",
    "  temp_df <- data.frame(\n",
    "    address = character(),\n",
    "    lat = double(),\n",
    "    lng = double(),\n",
    "    distance = double(),\n",
    "    capacity = integer(),\n",
    "    traffic_volume = integer(),\n",
    "    rate_half_hr= double(),\n",
    "    #n_business = integer(),\n",
    "    n_customers =integer(),\n",
    "    time_spent = double(),\n",
    "    category = character(),\n",
    "    interaction_term = integer(),\n",
    "    \n",
    "    stringsAsFactors = FALSE\n",
    "  )\n",
    "  \n",
    "  for( j in 1:nrow(business)){\n",
    "    lon1 <- parking_data_with_nearest_business[i,\"lng\"]\n",
    "    lat1 <- parking_data_with_nearest_business[i,\"lat\"]\n",
    "    lon2 <- business[j, \"long\"]\n",
    "    lat2 <- business[j, \"lat\"]\n",
    "    \n",
    "    \n",
    "    distance <- haversine_distance(lon1, lat1, lon2, lat2)\n",
    "\n",
    "    # Store the results in the temporary data frame\n",
    "    temp_df[nrow(temp_df) + 1, ] <- list(\n",
    "      address = parking_data_with_nearest_business[i,\"address\"],\n",
    "      lat = parking_data_with_nearest_business[i,\"lat\"],\n",
    "      lng = parking_data_with_nearest_business[i,\"lng\"],\n",
    "      distance = distance,\n",
    "      capacity = parking_data_with_nearest_business[i,\"capacity\"],\n",
    "      traffic_volume = parking_data_with_nearest_business[i,\"traffic_volume\"],\n",
    "      #n_business = parking_data_with_nearest_business[i,\"nearest_business\"],\n",
    "      rate_half_hr = parking_data_with_nearest_business[i,\"rate_half_hr\"],\n",
    "      n_customers = business[j,\"qCustomer\"],\n",
    "      time_spent = business[j,\"tCustomer\"],\n",
    "      category = business[j,\"Category\"],\n",
    "      interaction_term = business[j,\"qCustomer\"] * business[j,\"tCustomer\"]\n",
    "    )\n",
    "  }\n",
    "  \n",
    "  # Append the temporary data frame to the result list\n",
    "  result_list[[i]] <- temp_df\n",
    "}\n",
    "\n",
    "result_df <- do.call(rbind, result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filter rows where distance is less than 250 meters.\n",
    "filtered_result_df <- result_df[result_df$distance <= 0.25, ]\n",
    "a=filtered_result_df %>% count(address)\n",
    "\n",
    "\n",
    "filtered_result_df <- filtered_result_df %>%\n",
    "  left_join(a, by = \"address\")  # Adjust \"by\" argument if needed\n",
    "\n",
    "# 3. Select desired columns and rename the \"n\" column\n",
    "filtered_result_df <- filtered_result_df %>%\n",
    "  select(address, lat,lng, distance,rate_half_hr, n_businesses = n, capacity, n_customers, time_spent, traffic_volume) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define a scoring function\n",
    "calculate_score <- function(traffic_volume, capacity, rate_half_hr, nearest_businesses, customers, c_time, distance) {\n",
    "  # Define weights for each factor\n",
    "  weights <- c(0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.1)\n",
    "  \n",
    "  # Normalize each factor\n",
    "  normalized_traffic <- (traffic_volume - min(traffic_volume)) / (max(traffic_volume) - min(traffic_volume))\n",
    "  normalized_capacity <- (capacity - min(capacity)) / (max(capacity) - min(capacity))\n",
    "  normalized_rate <- (rate_half_hr - min(rate_half_hr)) / (max(rate_half_hr) - min(rate_half_hr))\n",
    "  normalized_n_businesses <- (nearest_businesses - min(nearest_businesses)) / (max(nearest_businesses) - min(nearest_businesses))\n",
    "  normalized_customers <-(customers - min(customers)) / (max(customers) - min(customers))\n",
    "  normalized_time <- (c_time - min(c_time)) / (max(c_time) - min(c_time))\n",
    "  normalized_distance <- (distance - min(distance)) / (max(distance) - min(distance))\n",
    "\n",
    "  # Calculate the score\n",
    "  score <- weights[1] * normalized_traffic +\n",
    "    weights[2] * normalized_capacity +\n",
    "    weights[3] * normalized_distance +\n",
    "    weights[4] * normalized_n_businesses + \n",
    "    weights[5] * (normalized_customers * normalized_time) +\n",
    "    weights[6] * (normalized_rate)\n",
    "\n",
    "  return(abs(score))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate score for each parking spot\n",
    "filtered_result_df$score <- calculate_score(filtered_result_df$traffic_volume, filtered_result_df$capacity, filtered_result_df$rate_half_hr, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent,filtered_result_df$distance)\n",
    "# Rank the parking spots based on the score\n",
    "ranked_data <- filtered_result_df[order(-filtered_result_df$score),]\n",
    "\n",
    "# Find highest scored parking spot\n",
    "highest_score_index <- which.max(ranked_data$score)\n",
    "highest_score_parking_spot <- filtered_result_df[highest_score_index, ]\n",
    "\n",
    "# Print the result\n",
    "print(paste0(\"Address of parking spot: \",highest_score_parking_spot$address))\n",
    "print(paste0(\"Latitude of parking spot: \",highest_score_parking_spot$lat))\n",
    "print(paste0(\"Longitude of parking spot: \",highest_score_parking_spot$lng))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Filter test data for distances less than 250\n",
    "test_data_filtered <- data %>% filter(distance < 250)\n",
    "\n",
    "model <- lm(capacity ~ traffic_volume  + distance + n_customers + time_spent + interaction_term + score + rate_half_hr, data = filtered_result_df)\n",
    "\n",
    "summary(model)\n",
    "\n",
    "model2 <- lm(capacity ~ traffic_volume  + distance +  score + rate_half_hr, data = filtered_result_df)\n",
    "summary(model2)\n",
    "\n",
    "\n",
    "# ----------------------------For 0.4 * existing traffic_volume -----------------------------------\n",
    "\n",
    "all_results <- data.frame()\n",
    "\n",
    "x_percent=0.4\n",
    "new_traffic_scenario = filtered_result_df$traffic_volume * x_percent\n",
    "newdata = data.frame(traffic_volume = new_traffic_scenario,\n",
    "                     address=filtered_result_df$address,\n",
    "                     distance = filtered_result_df$distance,\n",
    "                     n_customers = filtered_result_df$n_customers,\n",
    "                     time_spent = filtered_result_df$time_spent,\n",
    "                     interaction_term = filtered_result_df$interaction_term,\n",
    "                     score= filtered_result_df$score,\n",
    "                     rate_half_hr= filtered_result_df$rate_half_hr)\n",
    "\n",
    "# Make predictions\n",
    "predicted_capacity <- predict(model2, newdata)\n",
    "\n",
    "# Determine conversion needs\n",
    "capacity_needed <- ifelse(predicted_capacity > 1, ceiling(predicted_capacity), 0)\n",
    "\n",
    "# Store results for this scenario \n",
    "results <- data.frame(filtered_result_df$address, filtered_result_df$lat, filtered_result_df$lng, filtered_result_df$capacity,capacity_needed, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent)\n",
    "\n",
    "\n",
    "# ----------------------------For different % of traffic_volumes -----------------------------------\n",
    "\n",
    "# Iterate for different EV adoption rates\n",
    "x_percent_values <- seq(from = 0.1, to = 1, by = 0.4)  \n",
    "all_results <- data.frame()\n",
    "\n",
    "for (x_percent in x_percent_values) {\n",
    "  # Create new traffic scenario\n",
    "  new_traffic_scenario = result_df$traffic_volume * x_percent\n",
    "  # Make predictions\n",
    "  predicted_capacity <- predict(model, newdata)\n",
    "  # Determine conversion needs\n",
    "  capacity_needed <- ifelse(predicted_capacity > 1, ceiling(predicted_capacity), 0)\n",
    "\n",
    "  # Store results for this scenario \n",
    "  results <- data.frame(data.frame(filtered_result_df$address, filtered_result_df$lat, filtered_result_df$lng, filtered_result_df$capacity,capacity_needed, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent))\n",
    "  all_results <- rbind(all_results, results)\n",
    "}\n",
    "\n",
    "# Sort combined results\n",
    "all_results <- arrange(all_results, x_percent)\n",
    "\n",
    "# Create table\n",
    "library(kableExtra)  \n",
    "table <- kable(all_results, caption = \"Conversion Needs by EV Adoption Rate (Distance < 50)\")\n",
    "print(table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Result and Discussion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
