{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load all required libraries for the notebook, including data package\n",
    "if(!require(\"opendatatoronto\")) install.packages(\"opendatatoronto\");    library(opendatatoronto) # data source\n",
    "if(!require(\"tidyjson\")) install.packages(\"tidyjson\");    library(tidyjson)\n",
    "if(!require(\"tidygeocoder\")) install.packages(\"tidygeocoder\");    library(tidygeocoder)\n",
    "if(!require(\"sf\"))   install.packages(\"sf\");    library(sf)\n",
    "if(!require(\"ggspatial\")) install.packages(\"ggspatial\");    library(ggspatial)\n",
    "if(!require(\"stringr\")) install.packages(\"stringr\");    library(stringr)\n",
    "if(!require(\"dplyr\")) install.packages(\"dplyr\");    library(dplyr)\n",
    "if(!require(\"ggplot2\")) install.packages(\"ggplot2\");    library(ggplot2)\n",
    "if(!require(\"tidyverse\")) install.packages(\"tidyverse\");    library(tidyverse)\n",
    "if(!require(\"FNN\")) install.packages(\"FNN\");    library(FNN)\n",
    "if(!require(\"terra\")) install.packages(\"terra\");    library(terra)\n",
    "if(!require(\"mapview\")) install.packages(\"mapview\");    library(mapview)\n",
    "if(!require(\"forecast\")) install.packages(\"forecast\");    library(forecast)\n",
    "if(!require(\"purrr\")) install.packages(\"purrr\"); library(purrr)\n",
    "if(!require(\"e1071\")) install.packages(\"e1071\");    library(e1071)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"RUN_DATA_PROCESSING is FALSE\"\n"
     ]
    }
   ],
   "source": [
    "# set RUN_DATA_PROCESSING to FALSE by default as all the data processing has been done to speed up the code run time\n",
    "# set it to TRUE if you are want to run the code to process the raw data from scratch. \n",
    "# Or if the pre-processed data files are not available in ../Data/DataProcessing/\n",
    "RUN_DATA_PROCESSING <- FALSE\n",
    "\n",
    "if(RUN_DATA_PROCESSING) {\n",
    "    print(\"RUN_DATA_PROCESSING is TRUE\")\n",
    "} else {\n",
    "    print(\"RUN_DATA_PROCESSING is FALSE\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"RUN_DATA_PROCESSING is FALSE\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>year</th><th scope=col>location_id</th><th scope=col>location</th><th scope=col>lat</th><th scope=col>lng</th><th scope=col>AvgTotal</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>1984</td><td>3926</td><td>BLOOR ST AT SOUTH KINGSWAY &amp; RIVERVIEW GARDENS (PX 334)</td><td>43.64831</td><td>-79.48575</td><td> 8474</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>1984</td><td>3934</td><td>LAKE SHORE BLVD W AT LONG BRANCH AVE (PX 240)          </td><td>43.59436</td><td>-79.53402</td><td> 5647</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>1984</td><td>3940</td><td>BLACK CREEK DR AT LAWRENCE AVE W (PX 1348)             </td><td>43.70495</td><td>-79.49410</td><td>17625</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>1984</td><td>3950</td><td><span style=white-space:pre-wrap>KINGSTON RD AT BROOKLAWN AVE &amp; ST CLAIR AVE E          </span></td><td>43.72203</td><td>-79.23602</td><td>11820</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>1984</td><td>3953</td><td>KINGSTON RD AT LAWRENCE AVE (PX 144)                   </td><td>43.76765</td><td>-79.18961</td><td>13885</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>1984</td><td>3968</td><td>FINCH AVE AT WESTON RD (PX 589)                        </td><td>43.75209</td><td>-79.54238</td><td>12023</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & X & year & location\\_id & location & lat & lng & AvgTotal\\\\\n",
       "  & <int> & <int> & <int> & <chr> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 1984 & 3926 & BLOOR ST AT SOUTH KINGSWAY \\& RIVERVIEW GARDENS (PX 334) & 43.64831 & -79.48575 &  8474\\\\\n",
       "\t2 & 2 & 1984 & 3934 & LAKE SHORE BLVD W AT LONG BRANCH AVE (PX 240)           & 43.59436 & -79.53402 &  5647\\\\\n",
       "\t3 & 3 & 1984 & 3940 & BLACK CREEK DR AT LAWRENCE AVE W (PX 1348)              & 43.70495 & -79.49410 & 17625\\\\\n",
       "\t4 & 4 & 1984 & 3950 & KINGSTON RD AT BROOKLAWN AVE \\& ST CLAIR AVE E           & 43.72203 & -79.23602 & 11820\\\\\n",
       "\t5 & 5 & 1984 & 3953 & KINGSTON RD AT LAWRENCE AVE (PX 144)                    & 43.76765 & -79.18961 & 13885\\\\\n",
       "\t6 & 6 & 1984 & 3968 & FINCH AVE AT WESTON RD (PX 589)                         & 43.75209 & -79.54238 & 12023\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 7\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | year &lt;int&gt; | location_id &lt;int&gt; | location &lt;chr&gt; | lat &lt;dbl&gt; | lng &lt;dbl&gt; | AvgTotal &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | 1984 | 3926 | BLOOR ST AT SOUTH KINGSWAY &amp; RIVERVIEW GARDENS (PX 334) | 43.64831 | -79.48575 |  8474 |\n",
       "| 2 | 2 | 1984 | 3934 | LAKE SHORE BLVD W AT LONG BRANCH AVE (PX 240)           | 43.59436 | -79.53402 |  5647 |\n",
       "| 3 | 3 | 1984 | 3940 | BLACK CREEK DR AT LAWRENCE AVE W (PX 1348)              | 43.70495 | -79.49410 | 17625 |\n",
       "| 4 | 4 | 1984 | 3950 | KINGSTON RD AT BROOKLAWN AVE &amp; ST CLAIR AVE E           | 43.72203 | -79.23602 | 11820 |\n",
       "| 5 | 5 | 1984 | 3953 | KINGSTON RD AT LAWRENCE AVE (PX 144)                    | 43.76765 | -79.18961 | 13885 |\n",
       "| 6 | 6 | 1984 | 3968 | FINCH AVE AT WESTON RD (PX 589)                         | 43.75209 | -79.54238 | 12023 |\n",
       "\n"
      ],
      "text/plain": [
       "  X year location_id location                                               \n",
       "1 1 1984 3926        BLOOR ST AT SOUTH KINGSWAY & RIVERVIEW GARDENS (PX 334)\n",
       "2 2 1984 3934        LAKE SHORE BLVD W AT LONG BRANCH AVE (PX 240)          \n",
       "3 3 1984 3940        BLACK CREEK DR AT LAWRENCE AVE W (PX 1348)             \n",
       "4 4 1984 3950        KINGSTON RD AT BROOKLAWN AVE & ST CLAIR AVE E          \n",
       "5 5 1984 3953        KINGSTON RD AT LAWRENCE AVE (PX 144)                   \n",
       "6 6 1984 3968        FINCH AVE AT WESTON RD (PX 589)                        \n",
       "  lat      lng       AvgTotal\n",
       "1 43.64831 -79.48575  8474   \n",
       "2 43.59436 -79.53402  5647   \n",
       "3 43.70495 -79.49410 17625   \n",
       "4 43.72203 -79.23602 11820   \n",
       "5 43.76765 -79.18961 13885   \n",
       "6 43.75209 -79.54238 12023   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Get Data 1 - Traffic\n",
    "\n",
    "\n",
    "# # load data # The method of loading data directly using turns out to be insufficient as the get_resource() \n",
    "# only returns first 32000 rows of record.\n",
    "\n",
    "# To Run the code download the raw files from \n",
    "# https://open.toronto.ca/dataset/traffic-volumes-at-intersections-for-all-modes/ \n",
    "# and save the files in .csv format to the path: ../Data/Toronto/Traffic, 7 Files below. \n",
    "# count_metadata.csv\n",
    "# locations.csv\n",
    "# raw-data-1980-1989.csv\n",
    "# raw-data-1990-1999.csv\n",
    "# raw-data-2000-2009.csv\n",
    "# raw-data-2010-2019.csv\n",
    "# raw-data-2020-2029.csv\n",
    "\n",
    "# Dataframe with all intersection and average traffic per year per intersection from 1984 to 2023. \n",
    "\n",
    "\n",
    "if(RUN_DATA_PROCESSING) {\n",
    "    print(\"RUN_DATA_PROCESSING is TRUE\")\n",
    "    location <- read.csv(\"../Data/Toronto/Traffic/locations.csv\") # ensure these path are correct if you have to download the files manually. \n",
    "    traffic1 <- read.csv(\"../Data/Toronto/Traffic/raw-data-1980-1989.csv\")\n",
    "    traffic2 <- read.csv(\"../Data/Toronto/Traffic/raw-data-1990-1999.csv\")\n",
    "    traffic3 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2000-2009.csv\")\n",
    "    traffic4 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2010-2019.csv\")\n",
    "    traffic5 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2020-2029.csv\")\n",
    "    all_traffic = bind_rows(traffic1,traffic2,traffic3,traffic4,traffic5) # combine all raw data into one data frame\n",
    "\n",
    "    # clean and transform load - Traffic Data\n",
    "    # Output data for modelling CleanTraffic\n",
    "\n",
    "\n",
    "    # get full intersection volume for each intersection based on peak hours of each day. \n",
    "    # get average vol per intersection per year. \n",
    "    # get number of years list, sort from low to high\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # define parameters for cleaning\n",
    "\n",
    "    peakhours <- 4 # number of peak hours of data per day. value should be between 1 and 10\n",
    "\n",
    "    CleanTraffic <- all_traffic %>%\n",
    "      filter(centreline_type == 2) %>% # only need intersection data\n",
    "      mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "      mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "        nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "        wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "      select(one_of(c(\n",
    "        \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "        \"total_int_traffic\"\n",
    "      ))) %>% # remove raw attributes, retain aggregate only\n",
    "      group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "      summarise_at(\"total_int_traffic\",sum) %>% # agregate hourly volume\n",
    "      group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "      slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "      group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "      summarise_at(\"total_int_traffic\", sum)%>% # aggregate daily peak hour volume\n",
    "      mutate(count_date= as.Date(count_date, format(\"%Y-%m-%d\"))) %>% \n",
    "      mutate(year = as.numeric(format(count_date,'%Y'))) %>% #add year\n",
    "      group_by(across(all_of(c(\"year\", \"location_id\", \"location\", \"lat\",\"lng\")))) %>% # group by year to get the average per intersection per year\n",
    "      summarise(AvgTotal = mean(total_int_traffic), .groups = \"drop\")  # average traffic volume for that year and location\n",
    "    traffic_years <- unique(CleanTraffic$year) # get number of years list, sort from low to high\n",
    "\n",
    "    # save CleanTraffic as a csv file for ease of future use\n",
    "    write.csv(CleanTraffic, \"../Data/DataProcessing/CleanTraffic.csv\")\n",
    "} else {\n",
    "    print(\"RUN_DATA_PROCESSING is FALSE\")\n",
    "    CleanTraffic = read.csv(\"../Data/DataProcessing/CleanTraffic.csv\")\n",
    "    traffic_years <- unique(CleanTraffic$year)\n",
    "}\n",
    "head(CleanTraffic) # data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"RUN_DATA_PROCESSING is FALSE\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>Category</th><th scope=col>Operating.Name</th><th scope=col>city</th><th scope=col>Zip</th><th scope=col>Street</th><th scope=col>Address</th><th scope=col>lat</th><th scope=col>long</th><th scope=col>lamda</th><th scope=col>mu</th><th scope=col>sigma</th><th scope=col>qCustomer</th><th scope=col>tCustomer</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>TAXICAB OPERATOR                  </td><td>NORTHLAND TAXI                 </td><td>TORONTO, ON</td><td>M4H 1H2</td><td>THORNCLIFFE PARK DR</td><td>2 THORNCLIFFE PARK DR,TORONTO, ON,M4H 1H2</td><td>43.70593</td><td>-79.35204</td><td>10</td><td>0.33</td><td>0.5</td><td>10</td><td>1.6406388</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>PRIVATE PARKING ENFORCEMENT AGENCY</td><td>HALO SECURITY INC              </td><td>TORONTO, ON</td><td>M4L 1G1</td><td>QUEEN ST E         </td><td>1574 QUEEN ST E,TORONTO, ON,M4L 1G1      </td><td>43.66607</td><td>-79.31836</td><td> 5</td><td>0.33</td><td>0.5</td><td> 6</td><td>0.8364520</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>PRIVATE PARKING ENFORCEMENT AGENCY</td><td>MERIDIAN SECURITY SOLUTIONS INC</td><td>TORONTO, ON</td><td>M4N 3N1</td><td>YONGE ST           </td><td>3080 YONGE ST,TORONTO, ON,M4N 3N1        </td><td>43.72560</td><td>-79.40252</td><td> 5</td><td>0.33</td><td>0.5</td><td> 2</td><td>8.7843074</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>DRIVING SCHOOL OPERATOR (B)       </td><td>ALBERT DRIVING SCHOOL          </td><td>TORONTO, ON</td><td>M4C 1L7</td><td>DANFORTH AVE       </td><td>2704 DANFORTH AVE,TORONTO, ON,M4C 1L7    </td><td>43.68906</td><td>-79.29839</td><td> 5</td><td>1.00</td><td>0.5</td><td> 2</td><td>0.6605323</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>DRIVING SCHOOL OPERATOR (B)       </td><td>LEASIDE DRIVING ACADEMY        </td><td>TORONTO, ON</td><td>M4G 3C1</td><td>BAYVIEW AVE        </td><td>1659 BAYVIEW AVE,TORONTO, ON,M4G 3C1     </td><td>43.70734</td><td>-79.37562</td><td> 5</td><td>1.00</td><td>0.5</td><td> 4</td><td>0.2136136</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>DRIVING SCHOOL OPERATOR (B)       </td><td>NEW METHOD DRIVING SCHOOL      </td><td>TORONTO, ON</td><td>M4M 1Y5</td><td>GERRARD ST E       </td><td>737 GERRARD ST E,TORONTO, ON,M4M 1Y5     </td><td>43.66644</td><td>-79.34743</td><td> 5</td><td>1.00</td><td>0.5</td><td> 7</td><td>0.7268105</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 14\n",
       "\\begin{tabular}{r|llllllllllllll}\n",
       "  & X & Category & Operating.Name & city & Zip & Street & Address & lat & long & lamda & mu & sigma & qCustomer & tCustomer\\\\\n",
       "  & <int> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & TAXICAB OPERATOR                   & NORTHLAND TAXI                  & TORONTO, ON & M4H 1H2 & THORNCLIFFE PARK DR & 2 THORNCLIFFE PARK DR,TORONTO, ON,M4H 1H2 & 43.70593 & -79.35204 & 10 & 0.33 & 0.5 & 10 & 1.6406388\\\\\n",
       "\t2 & 2 & PRIVATE PARKING ENFORCEMENT AGENCY & HALO SECURITY INC               & TORONTO, ON & M4L 1G1 & QUEEN ST E          & 1574 QUEEN ST E,TORONTO, ON,M4L 1G1       & 43.66607 & -79.31836 &  5 & 0.33 & 0.5 &  6 & 0.8364520\\\\\n",
       "\t3 & 3 & PRIVATE PARKING ENFORCEMENT AGENCY & MERIDIAN SECURITY SOLUTIONS INC & TORONTO, ON & M4N 3N1 & YONGE ST            & 3080 YONGE ST,TORONTO, ON,M4N 3N1         & 43.72560 & -79.40252 &  5 & 0.33 & 0.5 &  2 & 8.7843074\\\\\n",
       "\t4 & 4 & DRIVING SCHOOL OPERATOR (B)        & ALBERT DRIVING SCHOOL           & TORONTO, ON & M4C 1L7 & DANFORTH AVE        & 2704 DANFORTH AVE,TORONTO, ON,M4C 1L7     & 43.68906 & -79.29839 &  5 & 1.00 & 0.5 &  2 & 0.6605323\\\\\n",
       "\t5 & 5 & DRIVING SCHOOL OPERATOR (B)        & LEASIDE DRIVING ACADEMY         & TORONTO, ON & M4G 3C1 & BAYVIEW AVE         & 1659 BAYVIEW AVE,TORONTO, ON,M4G 3C1      & 43.70734 & -79.37562 &  5 & 1.00 & 0.5 &  4 & 0.2136136\\\\\n",
       "\t6 & 6 & DRIVING SCHOOL OPERATOR (B)        & NEW METHOD DRIVING SCHOOL       & TORONTO, ON & M4M 1Y5 & GERRARD ST E        & 737 GERRARD ST E,TORONTO, ON,M4M 1Y5      & 43.66644 & -79.34743 &  5 & 1.00 & 0.5 &  7 & 0.7268105\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 14\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | Category &lt;chr&gt; | Operating.Name &lt;chr&gt; | city &lt;chr&gt; | Zip &lt;chr&gt; | Street &lt;chr&gt; | Address &lt;chr&gt; | lat &lt;dbl&gt; | long &lt;dbl&gt; | lamda &lt;int&gt; | mu &lt;dbl&gt; | sigma &lt;dbl&gt; | qCustomer &lt;int&gt; | tCustomer &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | TAXICAB OPERATOR                   | NORTHLAND TAXI                  | TORONTO, ON | M4H 1H2 | THORNCLIFFE PARK DR | 2 THORNCLIFFE PARK DR,TORONTO, ON,M4H 1H2 | 43.70593 | -79.35204 | 10 | 0.33 | 0.5 | 10 | 1.6406388 |\n",
       "| 2 | 2 | PRIVATE PARKING ENFORCEMENT AGENCY | HALO SECURITY INC               | TORONTO, ON | M4L 1G1 | QUEEN ST E          | 1574 QUEEN ST E,TORONTO, ON,M4L 1G1       | 43.66607 | -79.31836 |  5 | 0.33 | 0.5 |  6 | 0.8364520 |\n",
       "| 3 | 3 | PRIVATE PARKING ENFORCEMENT AGENCY | MERIDIAN SECURITY SOLUTIONS INC | TORONTO, ON | M4N 3N1 | YONGE ST            | 3080 YONGE ST,TORONTO, ON,M4N 3N1         | 43.72560 | -79.40252 |  5 | 0.33 | 0.5 |  2 | 8.7843074 |\n",
       "| 4 | 4 | DRIVING SCHOOL OPERATOR (B)        | ALBERT DRIVING SCHOOL           | TORONTO, ON | M4C 1L7 | DANFORTH AVE        | 2704 DANFORTH AVE,TORONTO, ON,M4C 1L7     | 43.68906 | -79.29839 |  5 | 1.00 | 0.5 |  2 | 0.6605323 |\n",
       "| 5 | 5 | DRIVING SCHOOL OPERATOR (B)        | LEASIDE DRIVING ACADEMY         | TORONTO, ON | M4G 3C1 | BAYVIEW AVE         | 1659 BAYVIEW AVE,TORONTO, ON,M4G 3C1      | 43.70734 | -79.37562 |  5 | 1.00 | 0.5 |  4 | 0.2136136 |\n",
       "| 6 | 6 | DRIVING SCHOOL OPERATOR (B)        | NEW METHOD DRIVING SCHOOL       | TORONTO, ON | M4M 1Y5 | GERRARD ST E        | 737 GERRARD ST E,TORONTO, ON,M4M 1Y5      | 43.66644 | -79.34743 |  5 | 1.00 | 0.5 |  7 | 0.7268105 |\n",
       "\n"
      ],
      "text/plain": [
       "  X Category                           Operating.Name                 \n",
       "1 1 TAXICAB OPERATOR                   NORTHLAND TAXI                 \n",
       "2 2 PRIVATE PARKING ENFORCEMENT AGENCY HALO SECURITY INC              \n",
       "3 3 PRIVATE PARKING ENFORCEMENT AGENCY MERIDIAN SECURITY SOLUTIONS INC\n",
       "4 4 DRIVING SCHOOL OPERATOR (B)        ALBERT DRIVING SCHOOL          \n",
       "5 5 DRIVING SCHOOL OPERATOR (B)        LEASIDE DRIVING ACADEMY        \n",
       "6 6 DRIVING SCHOOL OPERATOR (B)        NEW METHOD DRIVING SCHOOL      \n",
       "  city        Zip     Street             \n",
       "1 TORONTO, ON M4H 1H2 THORNCLIFFE PARK DR\n",
       "2 TORONTO, ON M4L 1G1 QUEEN ST E         \n",
       "3 TORONTO, ON M4N 3N1 YONGE ST           \n",
       "4 TORONTO, ON M4C 1L7 DANFORTH AVE       \n",
       "5 TORONTO, ON M4G 3C1 BAYVIEW AVE        \n",
       "6 TORONTO, ON M4M 1Y5 GERRARD ST E       \n",
       "  Address                                   lat      long      lamda mu   sigma\n",
       "1 2 THORNCLIFFE PARK DR,TORONTO, ON,M4H 1H2 43.70593 -79.35204 10    0.33 0.5  \n",
       "2 1574 QUEEN ST E,TORONTO, ON,M4L 1G1       43.66607 -79.31836  5    0.33 0.5  \n",
       "3 3080 YONGE ST,TORONTO, ON,M4N 3N1         43.72560 -79.40252  5    0.33 0.5  \n",
       "4 2704 DANFORTH AVE,TORONTO, ON,M4C 1L7     43.68906 -79.29839  5    1.00 0.5  \n",
       "5 1659 BAYVIEW AVE,TORONTO, ON,M4G 3C1      43.70734 -79.37562  5    1.00 0.5  \n",
       "6 737 GERRARD ST E,TORONTO, ON,M4M 1Y5      43.66644 -79.34743  5    1.00 0.5  \n",
       "  qCustomer tCustomer\n",
       "1 10        1.6406388\n",
       "2  6        0.8364520\n",
       "3  2        8.7843074\n",
       "4  2        0.6605323\n",
       "5  4        0.2136136\n",
       "6  7        0.7268105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "## Get Data 2 - Business\n",
    "    \n",
    "# output Data Description: \n",
    "# the output dataframe is 'biz_geo_loc1' which contains 13 variables i.e.\n",
    "# Category : business type as defined from Opendatatoronto\n",
    "# Operating.Name: business name as registered in Opendatatoronto\n",
    "# city: City where the business is located (extracted from business address)\n",
    "# Zip: postal code where business is located (extracted from business address)\n",
    "# Street street name where business is located (extracted from business address)\n",
    "# lat, long : Lattitude , Longitude converting from address into geocoder\n",
    "# lamda : customer arrival rate used to simulate the number of customer during busy hours(assumption)\n",
    "# mu : expected time spent (in hr) during busy hours of a customer (exponential distribution) \n",
    "# qCustomer: number of customer at busy hours (simulated from lamda)\n",
    "# tCustomer: time spent at the business per customer (simulated)\n",
    "##########################THE CODES ######################################\n",
    "# codes are separated into few sections:\n",
    "#section a) load data from Opendatatoronto to biz_data dataframe\n",
    "#section b) data cleansing in preparation for geocoder conversion\n",
    "#section c) address conversion to geocoder \n",
    "#section d) adding simulated number of customer (qCustomer) and time spent (tCustomer) during busy hours\n",
    "##########################################################################\n",
    "####section a) load data from Opendatatoronto to biz_data dataframe\n",
    "# Load libraries needed for loading data from toronto open data source\n",
    "\n",
    "if(RUN_DATA_PROCESSING) {\n",
    "    print(\"RUN_DATA_PROCESSING is TRUE\")\n",
    "    \n",
    "    if (!require(opendatatoronto)) install.packages(\"opendatatoronto\")\n",
    "    library(opendatatoronto)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # get package\n",
    "    package <- show_package(\"57b2285f-4f80-45fb-ae3e-41a02c3a137f\")\n",
    "    #package\n",
    "\n",
    "    # get all resources for this package\n",
    "    resources <- list_package_resources(\"57b2285f-4f80-45fb-ae3e-41a02c3a137f\")\n",
    "\n",
    "    # identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "    datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))\n",
    "\n",
    "    # load the first datastore resource as a sample\n",
    "    biz_data <- filter(datastore_resources, row_number()==1) %>% get_resource()\n",
    "    #biz_data\n",
    "\n",
    "    ### backup data to biz_data_bak\n",
    "    biz_data_bak = biz_data\n",
    "\n",
    "    ###Meaning of the data according to the readme from website are as follows\n",
    "    ###Category=Type of licence or permit\n",
    "    ###Licence No=Number. of licence issued by City of Toronto\n",
    "    ###Operating Name=Name that company operates under\n",
    "    ###Issued=Date of issue of licence/permit\n",
    "    ###Client Name=Name that the licence is issued to\n",
    "    ###Business Phone=Client Business Phone Number\n",
    "    ###Business Phone Ext.=Client Business Phone Extension Number\n",
    "    ###Licence Address Line 1=First line of client's business address\n",
    "    ###Licence Address Line 2=Client address town and province\n",
    "    ###Licence Address Line 3=Client address postal code\n",
    "    ###Conditions=Restriction on the licence/permit recorded in the licensing system\n",
    "    ###Free Form Conditions Line 1=Restriction/comment on the licence/permit\n",
    "    ###Free Form Conditions Line 2=Continuation of line 1 \n",
    "    ###Plate No.=Licence identifying plate, issued to most vehicles\n",
    "    ###Endorsements=Activity permitted under the licence\n",
    "    ###Cancel Date=Date the license or permit was cancelled\n",
    "    ############### End Of Data loading from  Toronto Open Data Source########\n",
    "    ##########################################################################\n",
    "    ####section b) data cleansing in preparation for geocoder conversion\n",
    "    ### Start cleaning up with change data type, filled in any empty data in Operating Name\n",
    "    biz_data$Category = as.factor(biz_data$Category)\n",
    "    biz_data$`Licence Address Line 2` = as.factor(biz_data$`Licence Address Line 2`)\n",
    "    biz_data$Issued = as.Date(biz_data$Issued)\n",
    "    biz_data$`Cancel Date` = as.Date(biz_data$`Cancel Date`)\n",
    "    biz_data$`Last Record Update` = as.Date(biz_data$`Last Record Update`)\n",
    "    biz_data$'Operating Name' <-ifelse(biz_data$'Operating Name' == \"\",biz_data$'Client Name',biz_data$'Operating Name')\n",
    "    #str(biz_data)\n",
    "    #summary(biz_data)\n",
    "    #head(biz_data)\n",
    "\n",
    "    ### remove biz that have cancel date as it indicates that business has already been cancelled (i.e. terminated)\n",
    "    biz_data = biz_data[which(is.na(biz_data$'Cancel Date')),]\n",
    "\n",
    "    #################################################################################################\n",
    "    ### only select business in Toronto with zip code starting with M3, M4, M5 and M6\n",
    "    biz_data = biz_data[which(biz_data$'Licence Address Line 2' == \"TORONTO, ON\"),]\n",
    "    biz_data = biz_data[which(biz_data$'Licence Address Line 3' > \"M3\" & biz_data$'Licence Address Line 3' < \"M7\"),]\n",
    "    #################################################################################################\n",
    "    #biz_data = biz_data %>%\n",
    "    #  select(-'Cancel Date')\n",
    "\n",
    "    ###make column to identify street name from Licence.Address.Line.1 (might be useful for cluster work later)\n",
    "    ###first extracting the address number. grab only the data that are after the first space\n",
    "    biz_data$Street <- sub(\"^\\\\S+\\\\s+\",'', biz_data$'Licence Address Line 1')\n",
    "    ###first extracting the address number. remove number\n",
    "    biz_data$Street <- gsub(\"[[:digit:]]\", \"\", biz_data$Street)\n",
    "    ###remove other unneccessary characters\n",
    "    biz_data$Street <- sub('-  ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('&A ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('& A ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('&B ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('& B ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('&  ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('&& ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('& ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('/ ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('-A ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('A-', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('- A ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('-B ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub('- B ', '', biz_data$Street)\n",
    "    biz_data$Street <- sub(\"(?<=^.{0}),\", \"\", biz_data$Street, perl = TRUE )\n",
    "    biz_data$Street <- sub(\"(?<=^.{0})&\", \"\", biz_data$Street, perl = TRUE )\n",
    "    biz_data$Street <- sub(\"(?<=^.{0})/\", \"\", biz_data$Street, perl = TRUE )\n",
    "    biz_data$Street <- sub(\"(?<=^.{0})-\", \"\", biz_data$Street, perl = TRUE )\n",
    "    ### as data is not clean, there are sometimes suite number or other suffix follow them. therefore, we clean that part up too.\n",
    "    biz_data$Street <- sub(\", #.*\", '', biz_data$Street)\n",
    "    biz_data$Street <- sub(\" #.*\", '', biz_data$Street)\n",
    "    biz_data$Street <- sub(\"#.*\", '', biz_data$Street)\n",
    "    biz_data$Street <- sub(\" ,.*\", '', biz_data$Street)\n",
    "    biz_data$Street <- sub(\",.*\", '', biz_data$Street)\n",
    "\n",
    "    ### use similar code to clean data and prepare for geo location\n",
    "    biz_data$StreetAddress = paste(biz_data$'Licence Address Line 1')\n",
    "    ###remove other characters from address one\n",
    "    biz_data$StreetAddress <- sub('-  ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('&A ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('& A ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('&B ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('& B ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('&  ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('&& ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('& ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('/ ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('-A ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('A-', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('- A ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('-B ', '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub('- B ', '', biz_data$StreetAddress)\n",
    "    ### Removing suite number or other suffix follow them. therefore\n",
    "    biz_data$StreetAddress <- sub(\", #.*\", '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub(\" #.*\", '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub(\"#.*\", '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub(\" ,.*\", '', biz_data$StreetAddress)\n",
    "    biz_data$StreetAddress <- sub(\",.*\", '', biz_data$StreetAddress)\n",
    "    ############################### End of Data Cleansing ####################\n",
    "    ##########################################################################\n",
    "    ####section c) address conversion to geocoder \n",
    "    ###convert to Lat- Long using tidygeocode : Reference https://www.youtube.com/watch?v=7nFZ5BwkAXc\n",
    "    ### Load libraries needed for geocode\n",
    "    if (!require(tidyverse)) install.packages(\"tidyverse\")\n",
    "    library(tidyverse)  \n",
    "    if (!require(tidygeocoder)) install.packages(\"tidygeocoder\")\n",
    "    library(tidygeocoder)  \n",
    "    if (!require(sf)) install.packages(\"sf\")\n",
    "    library(sf) \n",
    "    # if (!require(mapview)) install.packages(\"mapview\")\n",
    "    # library(mapview) \n",
    "\n",
    "    ### Prepare Data to be converted\n",
    "    biz_data$Address <- paste(biz_data$StreetAddress,biz_data$'Licence Address Line 2',biz_data$'Licence Address Line 3', sep = \",\")\n",
    "    biz_geo_loc_a = biz_data %>%\n",
    "      select(Category,`Operating Name`,city = 'Licence Address Line 2',Zip = 'Licence Address Line 3',Street, Address)\n",
    "\n",
    "    ### Convert address to lat - long\n",
    "    biz_geo_loc = biz_geo_loc_a %>% filter(str_detect(Zip, \"M4\"))%>%\n",
    "      tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "    biz_geo_loc1 = biz_geo_loc[-which(is.na(biz_geo_loc$lat)),]\n",
    "    biz_geo_loc2 = biz_geo_loc[which(is.na(biz_geo_loc$lat)),]\n",
    "\n",
    "    biz_geo_loc = biz_geo_loc_a %>% filter(str_detect(Zip, \"M5\"))%>%\n",
    "      tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "    biz_geo_loc1 = rbind(biz_geo_loc1,biz_geo_loc[-which(is.na(biz_geo_loc$lat)),])\n",
    "    biz_geo_loc2 = rbind(biz_geo_loc2,biz_geo_loc[which(is.na(biz_geo_loc$lat)),])\n",
    "\n",
    "    biz_geo_loc = biz_geo_loc_a %>% filter(str_detect(Zip, \"M6\"))%>%\n",
    "      tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "    biz_geo_loc1 = rbind(biz_geo_loc1,biz_geo_loc[-which(is.na(biz_geo_loc$lat)),])\n",
    "    biz_geo_loc2 = rbind(biz_geo_loc2,biz_geo_loc[which(is.na(biz_geo_loc$lat)),])\n",
    "\n",
    "    biz_geo_loc = biz_geo_loc_a %>% filter(str_detect(Zip, \"M3\"))%>%\n",
    "      tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "    biz_geo_loc1 = rbind(biz_geo_loc1,biz_geo_loc[-which(is.na(biz_geo_loc$lat)),])\n",
    "    biz_geo_loc2 = rbind(biz_geo_loc2,biz_geo_loc[which(is.na(biz_geo_loc$lat)),])\n",
    "\n",
    "    biz_geo_loc = biz_geo_loc_a %>% filter(str_detect(Zip, \"M7\"))%>%\n",
    "      tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "    biz_geo_loc1 = rbind(biz_geo_loc1,biz_geo_loc[-which(is.na(biz_geo_loc$lat)),])\n",
    "    biz_geo_loc2 = rbind(biz_geo_loc2,biz_geo_loc[which(is.na(biz_geo_loc$lat)),])\n",
    "\n",
    "    ###check if any na\n",
    "    sapply(biz_geo_loc1, function(x) sum(is.na(x)))\n",
    "\n",
    "    # write.csv(biz_geo_loc1, \"~/biz_geo_loc1.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###display on map # only works in R not Jupyter\n",
    "    biz_geo_loc_sf = biz_geo_loc1 %>%\n",
    "      st_as_sf(\n",
    "        coords = c(\"long\",\"lat\"),\n",
    "        crs = 4326\n",
    "      )\n",
    "\n",
    "    biz_geo_loc_sf %>% mapview()\n",
    "\n",
    "    ##########################################################################\n",
    "    ##########################################################################\n",
    "    ####section d) adding simulated number of customer (qCustomer) and time spent (tCustomer) during busy hours\n",
    "\n",
    "    biz_cat1 = data.frame(cbind(\n",
    "      c(\"RETAIL STORE (FOOD)\",\"HOLISTIC CENTRE\",\"DRIVING SCHOOL OPERATOR (B)\",\t\n",
    "        \"DRIVE-SELF RENTAL OWNER\",\"PLACE OF AMUSEMENT\",\t\"PRIVATE PARKING ENFORCEMENT AGENCY\",\t\n",
    "        \"SMOKE SHOP\",\t\"BILLIARD HALL\",\"BODY RUB PARLOUR\",\t\"TAXICAB BROKER\",\t\"BOWLING HOUSE\",\t\n",
    "        \"ADULT ENTERTAINMENT CLUB\",\t\"LIMOUSINE SERVICE COMPANY\",\t\n",
    "        \"PRIVATE TRANSPORTATION COMPANY\",\t\"CARNIVAL\",\t\"TEMPORARY SIGN PROVIDER\",\n",
    "        \"TAXICAB OPERATOR\",\t\"SHORT TERM RENTAL COMPANY\",\"CIRCUS\"), \n",
    "      c(30,5,5,10,30,5,10,20,10,10,20,5,10,10,3,3,10,3,100)) , \n",
    "      c(1,1.5,1,0.33,1,0.33,0.5,1,1,0.33,1,1,0.33,0.33,0.33,0.33,0.33,0.33,2) ,\n",
    "      c(0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5)\n",
    "      )\n",
    "    colnames(biz_cat1) = c(\"Category\",\"lamda\",\"mu\",\"sigma\")\n",
    "    biz_cat1$lamda = as.integer(biz_cat1$lamda)\n",
    "    biz_cat1$mu = as.numeric(biz_cat1$mu)\n",
    "    biz_cat1$sigma = as.numeric(biz_cat1$sigma)\n",
    "\n",
    "    biz_customer = as.data.frame(biz_cat1)\n",
    "\n",
    "    biz_geo_loc1 = left_join(biz_geo_loc1,biz_customer, by = \"Category\")\n",
    "\n",
    "    # for reproducibility but mask it when want to do simulation\n",
    "    set.seed(138)\n",
    "    k = nrow(biz_geo_loc1)\n",
    "    biz_geo_loc1 = data.frame(Category = biz_geo_loc1$Category, Operating.Name = biz_geo_loc1$'Operating.Name',\n",
    "                              city = biz_geo_loc1$city, Zip = biz_geo_loc1$Zip,  Street =biz_geo_loc1$Street,\n",
    "                              Address = biz_geo_loc1$Address, lat = biz_geo_loc1$lat,long = biz_geo_loc1$long,\n",
    "                              lamda =biz_geo_loc1$lamda,  mu = biz_geo_loc1$mu, sigma = biz_geo_loc1$sigma,\n",
    "                              qCustomer = rpois(k,biz_geo_loc1$lamda),\n",
    "                              tCustomer = rexp(k,biz_geo_loc1$mu)) \n",
    "   \n",
    "           \n",
    "    #review qCustomer * tCustomer summary\n",
    "    qCustomer_input_summary = biz_geo_loc1 %>%                            \n",
    "      group_by(Category = biz_geo_loc1$Category, lamda = biz_geo_loc1$lamda ) %>%\n",
    "      summarize(n = n(), min = min(qCustomer), q1 = quantile(qCustomer, 0.25), median = median(qCustomer), mean = mean(qCustomer), q3 = quantile(qCustomer, 0.75), max = max(qCustomer))\n",
    "    #qCustomer_input_summary\n",
    "\n",
    "    tCustomer_input_summary = biz_geo_loc1 %>%                            \n",
    "      group_by(Category = biz_geo_loc1$Category,mu = biz_geo_loc1$mu) %>%\n",
    "      summarize(n = n(), min = min(tCustomer), q1 = quantile(tCustomer, 0.25), median = median(tCustomer), mean = mean(tCustomer), q3 = quantile(tCustomer, 0.75), max = max(tCustomer))\n",
    "    #tCustomer_input_summary\n",
    "    write.csv(biz_geo_loc1, \"../Data/DataProcessing/biz_geo_loc1.csv\")\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "} else {\n",
    "    print(\"RUN_DATA_PROCESSING is FALSE\")\n",
    "    biz_geo_loc1 <- read.csv(\"../Data/DataProcessing/biz_geo_loc1.csv\")\n",
    "}\n",
    "head(biz_geo_loc1) # data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"RUN_DATA_PROCESSING is FALSE\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 10</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>id</th><th scope=col>address</th><th scope=col>lat</th><th scope=col>lng</th><th scope=col>carpark_type</th><th scope=col>rate_half_hr</th><th scope=col>capacity</th><th scope=col>rate</th><th scope=col>extracted_address</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td> 3</td><td>13 Isabella Street      </td><td>43.66758</td><td>-79.38471</td><td>Surface</td><td>3.00</td><td> 33</td><td>3.00</td><td>13 Isabella Street      </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td> 5</td><td>15 Wellesley Street East</td><td>43.66484</td><td>-79.38359</td><td>Surface</td><td>3.00</td><td>135</td><td>3.00</td><td>15 Wellesley Street East</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>12</td><td>30 Alvin Avenue         </td><td>43.68919</td><td>-79.39270</td><td>Surface</td><td>3.50</td><td>188</td><td>3.50</td><td>30 Alvin Avenue         </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>17</td><td>716 Pape Avenue         </td><td>43.67971</td><td>-79.34538</td><td>Surface</td><td>1.75</td><td> 70</td><td>1.75</td><td>716 Pape Avenue         </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>18</td><td>351 Keele Street        </td><td>43.66458</td><td>-79.46399</td><td>Surface</td><td>1.50</td><td> 77</td><td>1.50</td><td>351 Keele Street        </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>19</td><td>385 Pacific Avenue      </td><td>43.66474</td><td>-79.46812</td><td>Surface</td><td>1.50</td><td> 71</td><td>1.50</td><td>385 Pacific Avenue      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 10\n",
       "\\begin{tabular}{r|llllllllll}\n",
       "  & X & id & address & lat & lng & carpark\\_type & rate\\_half\\_hr & capacity & rate & extracted\\_address\\\\\n",
       "  & <int> & <int> & <chr> & <dbl> & <dbl> & <chr> & <dbl> & <int> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 &  3 & 13 Isabella Street       & 43.66758 & -79.38471 & Surface & 3.00 &  33 & 3.00 & 13 Isabella Street      \\\\\n",
       "\t2 & 2 &  5 & 15 Wellesley Street East & 43.66484 & -79.38359 & Surface & 3.00 & 135 & 3.00 & 15 Wellesley Street East\\\\\n",
       "\t3 & 3 & 12 & 30 Alvin Avenue          & 43.68919 & -79.39270 & Surface & 3.50 & 188 & 3.50 & 30 Alvin Avenue         \\\\\n",
       "\t4 & 4 & 17 & 716 Pape Avenue          & 43.67971 & -79.34538 & Surface & 1.75 &  70 & 1.75 & 716 Pape Avenue         \\\\\n",
       "\t5 & 5 & 18 & 351 Keele Street         & 43.66458 & -79.46399 & Surface & 1.50 &  77 & 1.50 & 351 Keele Street        \\\\\n",
       "\t6 & 6 & 19 & 385 Pacific Avenue       & 43.66474 & -79.46812 & Surface & 1.50 &  71 & 1.50 & 385 Pacific Avenue      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 10\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | id &lt;int&gt; | address &lt;chr&gt; | lat &lt;dbl&gt; | lng &lt;dbl&gt; | carpark_type &lt;chr&gt; | rate_half_hr &lt;dbl&gt; | capacity &lt;int&gt; | rate &lt;dbl&gt; | extracted_address &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 |  3 | 13 Isabella Street       | 43.66758 | -79.38471 | Surface | 3.00 |  33 | 3.00 | 13 Isabella Street       |\n",
       "| 2 | 2 |  5 | 15 Wellesley Street East | 43.66484 | -79.38359 | Surface | 3.00 | 135 | 3.00 | 15 Wellesley Street East |\n",
       "| 3 | 3 | 12 | 30 Alvin Avenue          | 43.68919 | -79.39270 | Surface | 3.50 | 188 | 3.50 | 30 Alvin Avenue          |\n",
       "| 4 | 4 | 17 | 716 Pape Avenue          | 43.67971 | -79.34538 | Surface | 1.75 |  70 | 1.75 | 716 Pape Avenue          |\n",
       "| 5 | 5 | 18 | 351 Keele Street         | 43.66458 | -79.46399 | Surface | 1.50 |  77 | 1.50 | 351 Keele Street         |\n",
       "| 6 | 6 | 19 | 385 Pacific Avenue       | 43.66474 | -79.46812 | Surface | 1.50 |  71 | 1.50 | 385 Pacific Avenue       |\n",
       "\n"
      ],
      "text/plain": [
       "  X id address                  lat      lng       carpark_type rate_half_hr\n",
       "1 1  3 13 Isabella Street       43.66758 -79.38471 Surface      3.00        \n",
       "2 2  5 15 Wellesley Street East 43.66484 -79.38359 Surface      3.00        \n",
       "3 3 12 30 Alvin Avenue          43.68919 -79.39270 Surface      3.50        \n",
       "4 4 17 716 Pape Avenue          43.67971 -79.34538 Surface      1.75        \n",
       "5 5 18 351 Keele Street         43.66458 -79.46399 Surface      1.50        \n",
       "6 6 19 385 Pacific Avenue       43.66474 -79.46812 Surface      1.50        \n",
       "  capacity rate extracted_address       \n",
       "1  33      3.00 13 Isabella Street      \n",
       "2 135      3.00 15 Wellesley Street East\n",
       "3 188      3.50 30 Alvin Avenue         \n",
       "4  70      1.75 716 Pape Avenue         \n",
       "5  77      1.50 351 Keele Street        \n",
       "6  71      1.50 385 Pacific Avenue      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Get data 3 - Parking Data (GreenPParking) \n",
    "# Output:\n",
    "# address : Address of the parking spot\n",
    "# lat : Latitude of parking spot\n",
    "# lng : Longitude of parking spot\n",
    "# half_hr : rate of parking/half hr\n",
    "# capacity : capacity of parking spot\n",
    "\n",
    "## Cleaning Green P Parking\n",
    "\n",
    "if(RUN_DATA_PROCESSING) {\n",
    "    print(\"RUN_DATA_PROCESSING is TRUE\")\n",
    "\n",
    "    # Get Green P Parking package from Open Data-Toronto\n",
    "    package <- show_package(\"b66466c3-69c8-4825-9c8b-04b270069193\")\n",
    "\n",
    "    data=as.data.frame('Green P Parking')  # read the dataset Green P Parking in the package \n",
    "    data<-show_package(package)\n",
    "\n",
    "    resources<-list_package_resources(package)\n",
    "\n",
    "    # Identify resources\n",
    "    data_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"json\"))\n",
    "\n",
    "    # Load Green P Parking data\n",
    "    data <- filter(data_resources, row_number() == 1) %>% get_resource()\n",
    "\n",
    "    # Extract required columns from main data\n",
    "    data<- data.frame(id = data$carparks$id,\n",
    "                      address=data$carparks$address,\n",
    "                                         lat=data$carparks$lat,\n",
    "                                         lng=data$carparks$lng,\n",
    "                                          carpark_type=data$carparks$carpark_type_str,\n",
    "                                          rate_half_hr=data$carparks$rate_half_hour,\n",
    "                                          capacity=data$carparks$capacity,\n",
    "                                          rate=data$carparks$rate_half_hour\n",
    "                      )\n",
    "\n",
    "    # Check class of each attribute\n",
    "    sapply(data, class) \n",
    "\n",
    "    # Convert char to numeric class\n",
    "    data$lat<-as.numeric(data$lat)\n",
    "    data$lng<-as.numeric(data$lng)\n",
    "    data$rate_half_hr<-as.numeric(data$rate_half_hr)\n",
    "    data$capacity<-as.numeric(data$capacity)\n",
    "\n",
    "    sapply(data, class) \n",
    "\n",
    "    # Check for missing values\n",
    "    any(is.na(data))\n",
    "\n",
    "    # Extract street name from address\n",
    "    data <- data %>%\n",
    "      mutate(extracted_address = str_replace_all(data$address, \"\\\\(.*?\\\\)\",\"\"))\n",
    "\n",
    "    data$extracted_address<-str_replace_all(data$extracted_address, \"-.*\", \"\")\n",
    "    data$extracted_address<-str_replace_all(data$extracted_address, \",.*\", \"\")\n",
    "\n",
    "\n",
    "    data <- data %>%\n",
    "      filter(carpark_type == \"Surface\")\n",
    "\n",
    "    #save data the car parking as a csv file for ease of future use\n",
    "    write.csv(data, \"../Data/DataProcessing/carpark_Surface_data.csv\")\n",
    "    \n",
    "} else {\n",
    "    print(\"RUN_DATA_PROCESSING is FALSE\")\n",
    "    data <- read.csv(\"../Data/DataProcessing/carpark_Surface_data.csv\") # read from pre-processed data \n",
    "}\n",
    "head(data) # data preview of the surface carpark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Pre-Processing 1 : Use KNN to get near by historic traffic for each parking lot\n",
    "\n",
    "# Combine Parking Data and Clean Traffic Data to prepare input data for Time Series Model to predict traffic / EV charging demand\n",
    "\n",
    "# loop through low to high year number\n",
    "# filter each year, to list of unique intersections with traffic volume\n",
    "# run knn algo against parking lot, find k nearst intersection\n",
    "# use knn nn.index to find the k intersection vol, get average, creating a vector\n",
    "# add vector to parking data as new column with year and volume\n",
    "# next loop for the next year\n",
    "\n",
    "#Output TS_Input\n",
    "\n",
    "if(RUN_DATA_PROCESSING) {\n",
    "    print(\"RUN_DATA_PROCESSING is TRUE\")\n",
    "\n",
    "\n",
    "    K <- 8 # Parameter used in knn calculation. \n",
    "    All_park <- data %>%\n",
    "        select(one_of(c(\"lat\",\"lng\"))) # location coordinates of all surface car parks. \n",
    "\n",
    "    TS_Input <- data # TS_Input is the input data for the time series of traffic volume forecast. \n",
    "\n",
    "    for (i in traffic_years) {\n",
    "        # print(paste(\"This is year\" ,i))\n",
    "        year_traffic<- filter(CleanTraffic, year == i) # get the traffic volume, intersection for each year.\n",
    "        All_int <-select(year_traffic,one_of(c(\"lat\",\"lng\"))) # extract just the coordinates for K nearest neighter calculation\n",
    "        knn_dist <- get.knnx(All_int, All_park, k=K, algorithm=\"kd_tree\") # get the K nearest intersection to the parking lot and their index list\n",
    "\n",
    "        get.mean <- function(x) { # custom function defined to calculate the average of the K nearest intersection volume\n",
    "        mean(slice(year_traffic, c(x))$AvgTotal)\n",
    "        }\n",
    "\n",
    "        TS_Input[paste0(\"NearbyTraffic_\",i)]  <- apply(knn_dist$nn.index,1,get.mean) # calculate the avaerage per row of indices\n",
    "\n",
    "    }\n",
    "\n",
    "    #save TS_Input as a csv file for ease of future anaylsis. \n",
    "    write.csv(TS_Input, \"../Data/DataProcessing/TS_Input.csv\")\n",
    "\n",
    "} else {\n",
    "    print(\"RUN_DATA_PROCESSING is FALSE\")\n",
    "    TS_Input <-read.csv(\"../Data/DataProcessing/TS_Input.csv\") # read from pre-processed data\n",
    "}\n",
    "head(TS_Input) # data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"RUN_DATA_PROCESSING is FALSE\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>TS_Input.address</th><th scope=col>TS_Input.lat</th><th scope=col>TS_Input.lng</th><th scope=col>TS_Input.NearbyTraffic_2022</th><th scope=col>TS_Output_2024</th><th scope=col>EV_nearbyTraffic_2022</th><th scope=col>EV_nearbyTraffic_2024</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>13 Isabella Street      </td><td>43.66758</td><td>-79.38471</td><td>4848.616</td><td>4497</td><td>145</td><td>240</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>15 Wellesley Street East</td><td>43.66484</td><td>-79.38359</td><td>5281.462</td><td>5540</td><td>158</td><td>295</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>30 Alvin Avenue         </td><td>43.68919</td><td>-79.39270</td><td>4521.144</td><td>4811</td><td>136</td><td>256</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>716 Pape Avenue         </td><td>43.67971</td><td>-79.34538</td><td>4912.333</td><td>3750</td><td>147</td><td>200</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>351 Keele Street        </td><td>43.66458</td><td>-79.46399</td><td>6077.057</td><td>4739</td><td>182</td><td>253</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>385 Pacific Avenue      </td><td>43.66474</td><td>-79.46812</td><td>5776.635</td><td>5188</td><td>173</td><td>277</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 8\n",
       "\\begin{tabular}{r|llllllll}\n",
       "  & X & TS\\_Input.address & TS\\_Input.lat & TS\\_Input.lng & TS\\_Input.NearbyTraffic\\_2022 & TS\\_Output\\_2024 & EV\\_nearbyTraffic\\_2022 & EV\\_nearbyTraffic\\_2024\\\\\n",
       "  & <int> & <chr> & <dbl> & <dbl> & <dbl> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 13 Isabella Street       & 43.66758 & -79.38471 & 4848.616 & 4497 & 145 & 240\\\\\n",
       "\t2 & 2 & 15 Wellesley Street East & 43.66484 & -79.38359 & 5281.462 & 5540 & 158 & 295\\\\\n",
       "\t3 & 3 & 30 Alvin Avenue          & 43.68919 & -79.39270 & 4521.144 & 4811 & 136 & 256\\\\\n",
       "\t4 & 4 & 716 Pape Avenue          & 43.67971 & -79.34538 & 4912.333 & 3750 & 147 & 200\\\\\n",
       "\t5 & 5 & 351 Keele Street         & 43.66458 & -79.46399 & 6077.057 & 4739 & 182 & 253\\\\\n",
       "\t6 & 6 & 385 Pacific Avenue       & 43.66474 & -79.46812 & 5776.635 & 5188 & 173 & 277\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 8\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | TS_Input.address &lt;chr&gt; | TS_Input.lat &lt;dbl&gt; | TS_Input.lng &lt;dbl&gt; | TS_Input.NearbyTraffic_2022 &lt;dbl&gt; | TS_Output_2024 &lt;int&gt; | EV_nearbyTraffic_2022 &lt;int&gt; | EV_nearbyTraffic_2024 &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | 13 Isabella Street       | 43.66758 | -79.38471 | 4848.616 | 4497 | 145 | 240 |\n",
       "| 2 | 2 | 15 Wellesley Street East | 43.66484 | -79.38359 | 5281.462 | 5540 | 158 | 295 |\n",
       "| 3 | 3 | 30 Alvin Avenue          | 43.68919 | -79.39270 | 4521.144 | 4811 | 136 | 256 |\n",
       "| 4 | 4 | 716 Pape Avenue          | 43.67971 | -79.34538 | 4912.333 | 3750 | 147 | 200 |\n",
       "| 5 | 5 | 351 Keele Street         | 43.66458 | -79.46399 | 6077.057 | 4739 | 182 | 253 |\n",
       "| 6 | 6 | 385 Pacific Avenue       | 43.66474 | -79.46812 | 5776.635 | 5188 | 173 | 277 |\n",
       "\n"
      ],
      "text/plain": [
       "  X TS_Input.address         TS_Input.lat TS_Input.lng\n",
       "1 1 13 Isabella Street       43.66758     -79.38471   \n",
       "2 2 15 Wellesley Street East 43.66484     -79.38359   \n",
       "3 3 30 Alvin Avenue          43.68919     -79.39270   \n",
       "4 4 716 Pape Avenue          43.67971     -79.34538   \n",
       "5 5 351 Keele Street         43.66458     -79.46399   \n",
       "6 6 385 Pacific Avenue       43.66474     -79.46812   \n",
       "  TS_Input.NearbyTraffic_2022 TS_Output_2024 EV_nearbyTraffic_2022\n",
       "1 4848.616                    4497           145                  \n",
       "2 5281.462                    5540           158                  \n",
       "3 4521.144                    4811           136                  \n",
       "4 4912.333                    3750           147                  \n",
       "5 6077.057                    4739           182                  \n",
       "6 5776.635                    5188           173                  \n",
       "  EV_nearbyTraffic_2024\n",
       "1 240                  \n",
       "2 295                  \n",
       "3 256                  \n",
       "4 200                  \n",
       "5 253                  \n",
       "6 277                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pre-Processing 2 - Get 2022 and 2024 ( forecasted) EV traffic data near each parking lot\n",
    "# \n",
    "# Time Series Forecast traffic for 2024 given the TS_Input\n",
    "# apply % of EV vehicle multiplier for 2022 and predicted year 2024 to get amount of estimated EV traffic.\n",
    "# multiplier % based on assumption 30% of all car traffic ( based on  website) will be EV by 2030 and in 2022 3% of all car \n",
    "# traffic are EV. ( based on website). Assumping constant rate of increase from 2022 to 2030, i.e. 30% y.o.y increase\n",
    "# data frame that has the original location, EV traffic for 2022, and predicted EV traffic for 2024\n",
    "\n",
    "\n",
    "library(forecast)\n",
    "library(purrr)\n",
    "\n",
    "\n",
    "if(RUN_DATA_PROCESSING) {\n",
    "    print(\"RUN_DATA_PROCESSING is TRUE\")\n",
    "\n",
    "\n",
    "    # Time series model and Forecast for 2024\n",
    "    arima_models <- apply(TS_Input[, -c(1,2,3,4,5,6,7,8)], 1, auto.arima)\n",
    "    model_forecasts_2024 <- lapply(arima_models, function(x) forecast(x, h = 1))\n",
    "\n",
    "    TS_Output_2024 <- map_dbl(model_forecasts_2024, \"mean\")\n",
    "    TS_Output_2024 <- round(TS_Output_2024)\n",
    "\n",
    "\n",
    "    # Format output for 2024\n",
    "    # Data frame that contains the original location, lat, and lng columns,\n",
    "    # % of EV traffic for 2022 and % of EV traffic for predicted 2024\n",
    "\n",
    "    # % of EV vehicle multiplier for 2022\n",
    "    mulitplier_2022 = .03\n",
    "\n",
    "    # % of EV Vehicle multiplier for predicted year \n",
    "    multiplier_predicted = .0533\n",
    "\n",
    "    TS_Output_df = data.frame(TS_Input$address,TS_Input$lat,TS_Input$lng, TS_Input$NearbyTraffic_2022,TS_Output_2024)\n",
    "    #head(TS_Output_df)\n",
    "\n",
    "    # Apply % of EV Vehicle multiplier to 2022 and predicted year 2024, present a new columns to Df\n",
    "    traffic_2022 <- data.frame(TS_Output_df$TS_Input.NearbyTraffic_2022)\n",
    "    traffic_2024 <-data.frame(TS_Output_df$TS_Output_2024)\n",
    "\n",
    "    TS_Output_df$EV_nearbyTraffic_2022 <- apply(traffic_2022, 1, function(x) round(x * mulitplier_2022))\n",
    "    TS_Output_df$EV_nearbyTraffic_2024 <- apply(traffic_2024, 1, function(x) round(x * multiplier_predicted))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # save TS_Output_df as a csv file for ease of future use\n",
    "    write.csv(TS_Output_df, \"../Data/DataProcessing/TS_Output.csv\")    \n",
    "\n",
    "} else {\n",
    "    print(\"RUN_DATA_PROCESSING is FALSE\")\n",
    "    TS_Output_df <-read.csv(\"../Data/DataProcessing/TS_Output.csv\") # read from pre-processed data\n",
    "}      \n",
    "                                            \n",
    "# Final Output\n",
    "head(TS_Output_df)  # data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"RUN_DATA_PROCESSING is FALSE\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>id</th><th scope=col>address</th><th scope=col>lat</th><th scope=col>lng</th><th scope=col>capacity</th><th scope=col>Convert</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td> 3</td><td>13 Isabella Street      </td><td>43.66758</td><td>-79.38471</td><td> 33</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td> 5</td><td>15 Wellesley Street East</td><td>43.66484</td><td>-79.38359</td><td>135</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>12</td><td>30 Alvin Avenue         </td><td>43.68919</td><td>-79.39270</td><td>188</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>17</td><td>716 Pape Avenue         </td><td>43.67971</td><td>-79.34538</td><td> 70</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>18</td><td>351 Keele Street        </td><td>43.66458</td><td>-79.46399</td><td> 77</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>19</td><td>385 Pacific Avenue      </td><td>43.66474</td><td>-79.46812</td><td> 71</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & X & id & address & lat & lng & capacity & Convert\\\\\n",
       "  & <int> & <int> & <chr> & <dbl> & <dbl> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 1 &  3 & 13 Isabella Street       & 43.66758 & -79.38471 &  33 & 0\\\\\n",
       "\t2 & 2 &  5 & 15 Wellesley Street East & 43.66484 & -79.38359 & 135 & 0\\\\\n",
       "\t3 & 3 & 12 & 30 Alvin Avenue          & 43.68919 & -79.39270 & 188 & 0\\\\\n",
       "\t4 & 4 & 17 & 716 Pape Avenue          & 43.67971 & -79.34538 &  70 & 0\\\\\n",
       "\t5 & 5 & 18 & 351 Keele Street         & 43.66458 & -79.46399 &  77 & 0\\\\\n",
       "\t6 & 6 & 19 & 385 Pacific Avenue       & 43.66474 & -79.46812 &  71 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 7\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | id &lt;int&gt; | address &lt;chr&gt; | lat &lt;dbl&gt; | lng &lt;dbl&gt; | capacity &lt;int&gt; | Convert &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 |  3 | 13 Isabella Street       | 43.66758 | -79.38471 |  33 | 0 |\n",
       "| 2 | 2 |  5 | 15 Wellesley Street East | 43.66484 | -79.38359 | 135 | 0 |\n",
       "| 3 | 3 | 12 | 30 Alvin Avenue          | 43.68919 | -79.39270 | 188 | 0 |\n",
       "| 4 | 4 | 17 | 716 Pape Avenue          | 43.67971 | -79.34538 |  70 | 0 |\n",
       "| 5 | 5 | 18 | 351 Keele Street         | 43.66458 | -79.46399 |  77 | 0 |\n",
       "| 6 | 6 | 19 | 385 Pacific Avenue       | 43.66474 | -79.46812 |  71 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  X id address                  lat      lng       capacity Convert\n",
       "1 1  3 13 Isabella Street       43.66758 -79.38471  33      0      \n",
       "2 2  5 15 Wellesley Street East 43.66484 -79.38359 135      0      \n",
       "3 3 12 30 Alvin Avenue          43.68919 -79.39270 188      0      \n",
       "4 4 17 716 Pape Avenue          43.67971 -79.34538  70      0      \n",
       "5 5 18 351 Keele Street         43.66458 -79.46399  77      0      \n",
       "6 6 19 385 Pacific Avenue       43.66474 -79.46812  71      0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Pre-Processing 3 : Add new column Convert to indicate if parking lot has EV chargers installed for each lot\n",
    "\n",
    "if(RUN_DATA_PROCESSING) {\n",
    "    print(\"RUN_DATA_PROCESSING is TRUE\")\n",
    "\n",
    "# Add convert column to GreenPParking dataset\n",
    "library(sf)\n",
    "\n",
    "# Extracting address, latitude, and longitude\n",
    "data <- data[, c(\"id\",\"address\", \"lat\", \"lng\",\"capacity\")]\n",
    "\n",
    "# Adding the new rows which represent parking lots with EV chargers already installed. \n",
    "# This information is based on the lastest EV Parking location update from the TPA Greep P website. \n",
    "# https://parking.greenp.com/ev-charging/\n",
    "# These parking lots are considred high priority lots, there are 9 of these in total. \n",
    "new_rows <- data.frame(\n",
    "  address = c(\n",
    "    \"365 Lippincott Street\",\n",
    "    \"35 Erindale Avenue\",\n",
    "    \"14 Arundel Avenue\",\n",
    "    \"265 Armadale Avenue\",\n",
    "    \"1612 Danforth Avenue\",\n",
    "    \"117 Hammersmith Avenue\",\n",
    "    \"166 Woodbine Ave\",\n",
    "    \"19 Spadina Road\",\n",
    "    \"2300 Lake shore Boulevard West\",\n",
    "    \"265 Armadale Avenue\",\n",
    "    \"2300 Lake shore Boulevard West\"\n",
    "  ),\n",
    "  lat = c(\n",
    "    43.665054,\n",
    "    43.688543,\n",
    "    43.695882,\n",
    "    43.721568,\n",
    "    43.684903,\n",
    "    43.693819,\n",
    "    43.674124,\n",
    "    43.677754,\n",
    "    43.623545\n",
    "  ),\n",
    "  lng = c(\n",
    "    -79.409662,\n",
    "    -79.411305,\n",
    "    -79.42134,\n",
    "    -79.427191,\n",
    "    -79.325679,\n",
    "    -79.428246,\n",
    "    -79.319325,\n",
    "    -79.403948,\n",
    "    -79.479056\n",
    "  )\n",
    ")\n",
    "\n",
    "# Adding the new rows to the extracted GreenPParking dataset\n",
    "# data <- rbind(data, new_rows)\n",
    "\n",
    "# Creating the 'Convert' column\n",
    "data$Convert <- ifelse(data$address %in% new_rows$address, 1, 0)\n",
    "\n",
    "# save the updated data df as a csv file for ease of future use\n",
    "write.csv(data, \"../Data/DataProcessing/carpark_Training_Data.csv\")   \n",
    "} else {\n",
    "    print(\"RUN_DATA_PROCESSING is FALSE\")\n",
    "    data <- read.csv(\"../Data/DataProcessing/carpark_Training_Data.csv\") # read data from pre-processed files\n",
    "}\n",
    "head(data) # preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ############################################## METHOD 1 - SVM (Without KNN) ##################################################\n",
    "\n",
    "# # Read data\n",
    "# parking<-data\n",
    "# business<-biz_geo_loc1\n",
    "\n",
    "# parking_sf <- st_as_sf(parking, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# # Convert the business dataset to a spatial object\n",
    "# business_sf <- st_as_sf(business, coords = c(\"long\", \"lat\"), crs = 4326)\n",
    "\n",
    "# # Convert the parking dataset to a spatial object\n",
    "# parking_sf <- st_as_sf(parking, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# # Perform a spatial join to find the nearest business for each parking space\n",
    "# nearest_business <- st_nearest_feature(parking_sf, business_sf)\n",
    "# nearest_points <-st_nearest_points(parking_sf,business_sf)\n",
    "\n",
    "# # Add the nearest business information to the parking dataset\n",
    "# parking_data_with_nearest_business <- cbind(parking, nearest_business)\n",
    "\n",
    "# # Function to calculate angular distance between two points on Earth\n",
    "# haversine_distance <- function(lon1, lat1, lon2, lat2) {\n",
    "#   R <- 6371 # Earth radius in km\n",
    "#   dlat <- (lat2 - lat1) * pi / 180\n",
    "#   dlon <- (lon2 - lon1) * pi / 180\n",
    "#   a <- sin(dlat/2)^2 + cos(lat1 * pi / 180) * cos(lat2 * pi / 180) * sin(dlon/2)^2\n",
    "#   c <- 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "#   distance <- R * c\n",
    "#   return(distance) # Distance in km\n",
    "# }\n",
    "# parking_data_with_nearest_business$traffic_volume=TS_Output_df$EV_nearbyTraffic_2022\t\n",
    "\n",
    "\n",
    "# # # Convert Lat/Lng to address\n",
    "# # geo_rev_data<-data %>%\n",
    "# #   tidygeocoder::reverse_geocode(\n",
    "# #     lat=lat,\n",
    "# #     long=lng,\n",
    "# #     method=\"osm\")\n",
    "\n",
    "\n",
    "# ## Calculate distance between each parking spot and each business\n",
    "\n",
    "# # Create an empty list to store the results\n",
    "# result_list <- list()\n",
    "\n",
    "# for (i in 1:nrow(parking_data_with_nearest_business)){\n",
    "  \n",
    "#   # Create a temporary data frame to store the results for this parking spot\n",
    "#   temp_df <- data.frame(\n",
    "#     address = character(),\n",
    "#     lat = double(),\n",
    "#     lng = double(),\n",
    "#     Convert = integer(),\n",
    "#     distance = double(),\n",
    "#     #capacity = integer(),\n",
    "#     traffic_volume = double(),\n",
    "#     #rate_half_hr= double(),\n",
    "#     n_business = double(),\n",
    "#     n_customers =double(),\n",
    "#     time_spent = double(),\n",
    "#     category = character(),\n",
    "#     Operating.name = character(),\n",
    "#     interaction_term = double()\n",
    "# )\n",
    "  \n",
    "#   for( j in 1:nrow(business)){\n",
    "#     lon1 <- parking_data_with_nearest_business[i,\"lng\"]\n",
    "#     lat1 <- parking_data_with_nearest_business[i,\"lat\"]\n",
    "#     lon2 <- business[j, \"long\"]\n",
    "#     lat2 <- business[j, \"lat\"]\n",
    "\n",
    "#     # # Calculate distance\n",
    "#     distance <- haversine_distance(lon1,lat1, lon2, lat2)\n",
    "    \n",
    "#     # Store the results in the temporary data frame\n",
    "#     temp_df[nrow(temp_df) + 1, ] <- list(\n",
    "#       address = parking_data_with_nearest_business[i,\"address\"],\n",
    "#       lat = parking_data_with_nearest_business[i,\"lat\"],\n",
    "#       lng = parking_data_with_nearest_business[i,\"lng\"],\n",
    "#       Convert = parking_data_with_nearest_business[i,\"Convert\"],\n",
    "#       distance = distance,\n",
    "#       #capacity = parking_data_with_nearest_business[i,\"capacity\"],\n",
    "#       traffic_volume = parking_data_with_nearest_business[i,\"traffic_volume\"],\n",
    "#       n_business = parking_data_with_nearest_business[i,\"nearest_business\"],\n",
    "#       #rate_half_hr = parking_data_with_nearest_business[i,\"rate_half_hr\"],\n",
    "#       n_customers = business[j,\"qCustomer\"],\n",
    "#       time_spent = business[j,\"tCustomer\"],\n",
    "#       category = business[j,\"Category\"],\n",
    "#       Operating.name = business[j,\"Operating.Name\"],\n",
    "#       interaction_term = business[j,\"qCustomer\"] * business[j,\"tCustomer\"]\n",
    "#     )\n",
    "#   }\n",
    "  \n",
    "#   # Append the temporary data frame to the result list\n",
    "#   result_list[[i]] <- temp_df\n",
    "# }\n",
    "\n",
    "# # Combine all the results into a single data frame\n",
    "# result_df <- do.call(rbind, result_list)\n",
    "\n",
    "# library(dplyr)\n",
    "# filtered_result_df2 <- result_df %>%\n",
    "#   group_by(Operating.name) %>% \n",
    "#   slice(which.min(distance))\n",
    "\n",
    "# summarized_result_df <- filtered_result_df2 %>%\n",
    "#   group_by(address) %>%\n",
    "#   summarize(\n",
    "#     mean_lat = mean(lat),\n",
    "#     mean_lng = mean(lng),\n",
    "#     mean_distance = mean(distance),\n",
    "#     mean_traffic_volume = mean(traffic_volume),\n",
    "#     mean_n_business = mean(n_business),\n",
    "#     mean_n_customers = mean(n_customers),\n",
    "#     mean_time_spent = mean(time_spent),\n",
    "#     mean_interaction_term = mean(interaction_term),\n",
    "#     convert=mean(Convert)\n",
    "#   )\n",
    "# #save summarized_result_df as a csv for future ease of use\n",
    "# write.csv(summarized_result_df,\"../Data/DataProcessing/summarized_result_df.csv\")\n",
    "\n",
    "# # train_indices <- sample(1:nrow(parking_data]), 0.7 * nrow(parking_data))  # 70% for training\n",
    "# # train_data <- parking_data[train_indices, ]\n",
    "# # test_data <- parking_data[-train_indices, ]\n",
    "\n",
    "# # Create a formula including predictor columns\n",
    "# formula <- as.formula(\"convert ~ mean_distance + mean_traffic_volume + mean_n_business\")\n",
    "\n",
    "# # Create the SVM model with the formula\n",
    "# svm_model <- svm(formula, data = summarized_result_df, kernel = \"linear\")\n",
    "\n",
    "# # Coefficients from the SVM model\n",
    "# coefficients <- coef(svm_model)[-1]  # Exclude the intercept\n",
    "\n",
    "# # Select the columns for which to calculate the score\n",
    "# cols <- c(\"mean_distance\", \"mean_n_business\", \"mean_traffic_volume\")\n",
    "\n",
    "# # Calculate the score for each row\n",
    "# summarized_result_df$score <- rowSums(summarized_result_df[cols] * coefficients)\n",
    "# # Sort the rows in descending order according to the score\n",
    "# summarized_result_df <- summarized_result_df %>%\n",
    "#   arrange(desc(score))\n",
    "\n",
    "# # View the sorted result (Top 12 Parking Locations)\n",
    "# head(summarized_result_df,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"RUN_DATA_PROCESSING is FALSE\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>id</th><th scope=col>address</th><th scope=col>lat</th><th scope=col>lng</th><th scope=col>capacity</th><th scope=col>Convert</th><th scope=col>n_business</th><th scope=col>distance</th><th scope=col>n_customers</th><th scope=col>time_spent</th><th scope=col>traffic_volume</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td> 3</td><td>13 Isabella Street      </td><td>43.66758</td><td>-79.38471</td><td> 33</td><td>0</td><td>20</td><td>0.001647831</td><td>28.80</td><td>1.2391036</td><td>145</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td> 5</td><td>15 Wellesley Street East</td><td>43.66484</td><td>-79.38359</td><td>135</td><td>0</td><td>20</td><td>0.002253017</td><td>28.70</td><td>1.0503689</td><td>158</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>12</td><td>30 Alvin Avenue         </td><td>43.68919</td><td>-79.39270</td><td>188</td><td>0</td><td>20</td><td>0.004607941</td><td>27.20</td><td>0.9009667</td><td>136</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>17</td><td>716 Pape Avenue         </td><td>43.67971</td><td>-79.34538</td><td> 70</td><td>0</td><td>20</td><td>0.002608467</td><td>25.90</td><td>1.0526270</td><td>147</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>18</td><td>351 Keele Street        </td><td>43.66458</td><td>-79.46399</td><td> 77</td><td>0</td><td>20</td><td>0.006052567</td><td>30.75</td><td>1.0121779</td><td>182</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>19</td><td>385 Pacific Avenue      </td><td>43.66474</td><td>-79.46812</td><td> 71</td><td>0</td><td>20</td><td>0.004097295</td><td>30.05</td><td>0.8493223</td><td>173</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 12\n",
       "\\begin{tabular}{r|llllllllllll}\n",
       "  & X & id & address & lat & lng & capacity & Convert & n\\_business & distance & n\\_customers & time\\_spent & traffic\\_volume\\\\\n",
       "  & <int> & <int> & <chr> & <dbl> & <dbl> & <int> & <int> & <int> & <dbl> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 1 &  3 & 13 Isabella Street       & 43.66758 & -79.38471 &  33 & 0 & 20 & 0.001647831 & 28.80 & 1.2391036 & 145\\\\\n",
       "\t2 & 2 &  5 & 15 Wellesley Street East & 43.66484 & -79.38359 & 135 & 0 & 20 & 0.002253017 & 28.70 & 1.0503689 & 158\\\\\n",
       "\t3 & 3 & 12 & 30 Alvin Avenue          & 43.68919 & -79.39270 & 188 & 0 & 20 & 0.004607941 & 27.20 & 0.9009667 & 136\\\\\n",
       "\t4 & 4 & 17 & 716 Pape Avenue          & 43.67971 & -79.34538 &  70 & 0 & 20 & 0.002608467 & 25.90 & 1.0526270 & 147\\\\\n",
       "\t5 & 5 & 18 & 351 Keele Street         & 43.66458 & -79.46399 &  77 & 0 & 20 & 0.006052567 & 30.75 & 1.0121779 & 182\\\\\n",
       "\t6 & 6 & 19 & 385 Pacific Avenue       & 43.66474 & -79.46812 &  71 & 0 & 20 & 0.004097295 & 30.05 & 0.8493223 & 173\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 12\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | id &lt;int&gt; | address &lt;chr&gt; | lat &lt;dbl&gt; | lng &lt;dbl&gt; | capacity &lt;int&gt; | Convert &lt;int&gt; | n_business &lt;int&gt; | distance &lt;dbl&gt; | n_customers &lt;dbl&gt; | time_spent &lt;dbl&gt; | traffic_volume &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 |  3 | 13 Isabella Street       | 43.66758 | -79.38471 |  33 | 0 | 20 | 0.001647831 | 28.80 | 1.2391036 | 145 |\n",
       "| 2 | 2 |  5 | 15 Wellesley Street East | 43.66484 | -79.38359 | 135 | 0 | 20 | 0.002253017 | 28.70 | 1.0503689 | 158 |\n",
       "| 3 | 3 | 12 | 30 Alvin Avenue          | 43.68919 | -79.39270 | 188 | 0 | 20 | 0.004607941 | 27.20 | 0.9009667 | 136 |\n",
       "| 4 | 4 | 17 | 716 Pape Avenue          | 43.67971 | -79.34538 |  70 | 0 | 20 | 0.002608467 | 25.90 | 1.0526270 | 147 |\n",
       "| 5 | 5 | 18 | 351 Keele Street         | 43.66458 | -79.46399 |  77 | 0 | 20 | 0.006052567 | 30.75 | 1.0121779 | 182 |\n",
       "| 6 | 6 | 19 | 385 Pacific Avenue       | 43.66474 | -79.46812 |  71 | 0 | 20 | 0.004097295 | 30.05 | 0.8493223 | 173 |\n",
       "\n"
      ],
      "text/plain": [
       "  X id address                  lat      lng       capacity Convert n_business\n",
       "1 1  3 13 Isabella Street       43.66758 -79.38471  33      0       20        \n",
       "2 2  5 15 Wellesley Street East 43.66484 -79.38359 135      0       20        \n",
       "3 3 12 30 Alvin Avenue          43.68919 -79.39270 188      0       20        \n",
       "4 4 17 716 Pape Avenue          43.67971 -79.34538  70      0       20        \n",
       "5 5 18 351 Keele Street         43.66458 -79.46399  77      0       20        \n",
       "6 6 19 385 Pacific Avenue       43.66474 -79.46812  71      0       20        \n",
       "  distance    n_customers time_spent traffic_volume\n",
       "1 0.001647831 28.80       1.2391036  145           \n",
       "2 0.002253017 28.70       1.0503689  158           \n",
       "3 0.004607941 27.20       0.9009667  136           \n",
       "4 0.002608467 25.90       1.0526270  147           \n",
       "5 0.006052567 30.75       1.0121779  182           \n",
       "6 0.004097295 30.05       0.8493223  173           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "## Pre-Processing 4 : \n",
    "# Use KNN to find nearest distance, average number of customers and average time spent at business location.\n",
    "# Add EV traffic volume data for year 2022 and 2024. \n",
    "# Assume business are static \n",
    "# output data will be used for training of the classification model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if(RUN_DATA_PROCESSING) {\n",
    "    print(\"RUN_DATA_PROCESSING is TRUE\")\n",
    "\n",
    "\n",
    "\n",
    "    # Read data\n",
    "    parking_data <- data\n",
    "    business_data <- biz_geo_loc1\n",
    "\n",
    "    K <- 20  # Number of nearest businesses to consider\n",
    "\n",
    "    for (i in 1:nrow(parking_data)) {\n",
    "        parking_spot <- parking_data[i, c(\"lat\", \"lng\")]  # Coordinates of the parking spot\n",
    "        nearest_biz_indices <- get.knnx(business_data[, c(\"lat\", \"long\")], parking_spot, k = K, algorithm = \"kd_tree\")$nn.index\n",
    "        nearest_biz_distances <- get.knnx(business_data[, c(\"lat\", \"long\")], parking_spot, k = K, algorithm = \"kd_tree\")$nn.dist\n",
    "\n",
    "        # Calculate the number of nearest businesses and their distances\n",
    "        num_nearest_biz <- length(nearest_biz_indices)\n",
    "        avg_distance <- mean(nearest_biz_distances)\n",
    "\n",
    "        nearest_biz_customers <- sapply(nearest_biz_indices, function(idx) {\n",
    "      mean(business_data[idx, \"qCustomer\"])\n",
    "    })\n",
    "        nearest_biz_time_spent <- sapply(nearest_biz_indices, function(idx) {\n",
    "      mean(business_data[idx, \"tCustomer\"])\n",
    "    })\n",
    "\n",
    "        overall_mean_customers <- mean(nearest_biz_customers)\n",
    "        overall_mean_time_spent <- mean(nearest_biz_time_spent)\n",
    "\n",
    "\n",
    "        # Add the results to the parking_data dataframe\n",
    "    #     parking_data[i, paste0(\"nearest_biz_count_\", K)] <- num_nearest_biz\n",
    "    #     parking_data[i, paste0(\"avg_distance_to_biz_\", K)] <- avg_distance\n",
    "    #     parking_data[i, paste0(\"avg_customers_nearby_\", K)] <- mean(overall_mean_customers)\n",
    "    #     parking_data[i, paste0(\"avg_time_spent_nearby_\", K)] <- mean(overall_mean_time_spent)\n",
    "        parking_data[i, \"n_business\"] <- num_nearest_biz\n",
    "        parking_data[i, \"distance\"] <- avg_distance\n",
    "        parking_data[i, \"n_customers\"] <- mean(overall_mean_customers)\n",
    "        parking_data[i, \"time_spent\"] <- mean(overall_mean_time_spent)\n",
    "    }\n",
    "\n",
    "\n",
    "    # Add EV Traffic data from 2022 for training. \n",
    "    parking_data$traffic_volume=TS_Output_df$EV_nearbyTraffic_2022\t\n",
    "\n",
    "    # #save parking_data as a csv for future ease of use\n",
    "    # write.csv(parking_data,\"../Data/DataProcessing/parking_data_pre_grouping.csv\")\n",
    "\n",
    "\n",
    "    # # Group by address\n",
    "    # parking_data <- parking_data %>%\n",
    "    #   group_by(address) %>%\n",
    "    #   summarise(\n",
    "    #     distance = mean(avg_distance_to_biz_8),\n",
    "    #     n_business = mean(nearest_biz_count_8),\n",
    "    #     time_spent =mean(avg_time_spent_nearby_8),\n",
    "    #     n_customers=mean(avg_customers_nearby_8),\n",
    "    #     traffic_volume = mean(traffic_volume),\n",
    "    #     convert = mean(Convert)\n",
    "    #   )\n",
    "\n",
    "\n",
    "    # Group by ID\n",
    "    # parking_data <- parking_data %>%\n",
    "    #   group_by(id) %>%\n",
    "    #   summarise(\n",
    "    # #     address = \n",
    "    #     distance = mean(avg_distance_to_biz_8),\n",
    "    #     n_business = mean(nearest_biz_count_8),\n",
    "    #     time_spent =mean(avg_time_spent_nearby_8),\n",
    "    #     n_customers=mean(avg_customers_nearby_8),\n",
    "    #     traffic_volume = mean(traffic_volume),\n",
    "    #     convert = mean(Convert),\n",
    "    #     capacity = mean(capacity)\n",
    "    #   )\n",
    "\n",
    "\n",
    "    # Normalize predictors\n",
    "    # parking_data$distance <- scale(parking_data$distance)\n",
    "    # parking_data$traffic_volume <- scale(parking_data$traffic_volume)\n",
    "    # parking_data$time_spent<- scale(parking_data$time_spent)\n",
    "    # parking_data$n_customers<- scale(parking_data$n_customers)\n",
    "\n",
    "    # no scale\n",
    "    # parking_data <- parking_data %>%\n",
    "    #     mutate(distance = distance/max(distance)) %>%\n",
    "    #     mutate(traffic_volume = traffic_volume/max(traffic_volume)) %>%\n",
    "    #     mutate(time_spent = time_spent/max(time_spent)) %>%\n",
    "    #     mutate(n_customers = n_customers/max(n_customers)) %>%\n",
    "    #     mutate(capacity = capacity/max(capacity))\n",
    "\n",
    "    #save summarized_result_df as a csv for future ease of use\n",
    "    write.csv(parking_data,\"../Data/DataProcessing/parking_data.csv\")\n",
    "\n",
    "} else {\n",
    "    print(\"RUN_DATA_PROCESSING is FALSE\")\n",
    "    parking_data <- read.csv(\"../Data/DataProcessing/parking_data.csv\") # read from pre-processed file\n",
    "}\n",
    "head(parking_data) # preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "svm(formula = formula, data = train_data, kernel = \"linear\", type = \"C-classification\")\n",
       "\n",
       "\n",
       "Parameters:\n",
       "   SVM-Type:  C-classification \n",
       " SVM-Kernel:  linear \n",
       "       cost:  1 \n",
       "\n",
       "Number of Support Vectors:  15\n",
       "\n",
       " ( 7 8 )\n",
       "\n",
       "\n",
       "Number of Classes:  2 \n",
       "\n",
       "Levels: \n",
       " 0 1\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "    \n",
       "pred 0 1\n",
       "   0 7 1\n",
       "   1 3 8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'SVM Model prediction accuracy is 78.95 %'"
      ],
      "text/latex": [
       "'SVM Model prediction accuracy is 78.95 \\%'"
      ],
      "text/markdown": [
       "'SVM Model prediction accuracy is 78.95 %'"
      ],
      "text/plain": [
       "[1] \"SVM Model prediction accuracy is 78.95 %\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>id</th><th scope=col>address</th><th scope=col>d_value</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl[,1]&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 44</td><td>14 Fuller Avenue         </td><td>1.535779</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>256</td><td>1624 Queen Street West   </td><td>1.383867</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>279</td><td>287 Rushton Road         </td><td>1.293679</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>220</td><td>789 St. Clair Avenue West</td><td>1.214196</td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 71</td><td>35 Bellevue Avenue       </td><td>1.049167</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & id & address & d\\_value\\\\\n",
       "  & <int> & <chr> & <dbl{[},1{]}>\\\\\n",
       "\\hline\n",
       "\t1 &  44 & 14 Fuller Avenue          & 1.535779\\\\\n",
       "\t2 & 256 & 1624 Queen Street West    & 1.383867\\\\\n",
       "\t3 & 279 & 287 Rushton Road          & 1.293679\\\\\n",
       "\t4 & 220 & 789 St. Clair Avenue West & 1.214196\\\\\n",
       "\t5 &  71 & 35 Bellevue Avenue        & 1.049167\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 3\n",
       "\n",
       "| <!--/--> | id &lt;int&gt; | address &lt;chr&gt; | d_value &lt;dbl[,1]&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 |  44 | 14 Fuller Avenue          | 1.535779 |\n",
       "| 2 | 256 | 1624 Queen Street West    | 1.383867 |\n",
       "| 3 | 279 | 287 Rushton Road          | 1.293679 |\n",
       "| 4 | 220 | 789 St. Clair Avenue West | 1.214196 |\n",
       "| 5 |  71 | 35 Bellevue Avenue        | 1.049167 |\n",
       "\n"
      ],
      "text/plain": [
       "  id  address                   d_value \n",
       "1  44 14 Fuller Avenue          1.535779\n",
       "2 256 1624 Queen Street West    1.383867\n",
       "3 279 287 Rushton Road          1.293679\n",
       "4 220 789 St. Clair Avenue West 1.214196\n",
       "5  71 35 Bellevue Avenue        1.049167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################################## METHOD 2 - SVM (With KNN) ##################################################\n",
    "\n",
    "## Train Classification and make prediction: \n",
    "# Split input data into subsets for training and prediction\n",
    "# Make SVM model with 'convert' as dependent variable, and select others as independent variable\n",
    "# Use decision value to rank the prediction outcome and correlate to the EV conversion priority. \n",
    "# OUTPUT: parking locations to be converted to EV charging stations in a ranked order.\n",
    "\n",
    "\n",
    "set.seed(123)  # for reproducibility\n",
    "# 10% for training of non-EV and 9\n",
    "EV_parking <- filter(parking_data,Convert ==1)\n",
    "# head(EV_parking)\n",
    "Non_EV_Parking <- filter(parking_data,Convert ==0)\n",
    "# head(Non_EV_Parking)\n",
    "\n",
    "# write.csv(Non_EV_Parking,\"../Data/DataProcessing/Non_EV_Parking.csv\")\n",
    "\n",
    "train_indices <- sample(1:nrow(Non_EV_Parking), 0.05 * nrow(Non_EV_Parking))  # 10% of data\n",
    "Non_EV_train_data <- Non_EV_Parking[train_indices, ]\n",
    "# test_data <- parking_data[-train_indices, ]\n",
    "\n",
    "train_data <- bind_rows(EV_parking,Non_EV_train_data)\n",
    "# write.csv(train_data,\"../Data/DataProcessing/train_data.csv\")\n",
    "\n",
    "predict_data <- parking_data %>%\n",
    "mutate(traffic_volume = TS_Output_df$EV_nearbyTraffic_2024) %>%\n",
    "filter(Convert == 0)\n",
    "\n",
    "# write.csv(predict_data,\"../Data/DataProcessing/predict_data.csv\")\n",
    "    \n",
    "\n",
    "# # Create a formula including predictor columns ( no simulated data)\n",
    "formula <- as.formula(\"Convert ~ distance + traffic_volume + capacity + n_customers + time_spent\")\n",
    "\n",
    "# with simulated data\n",
    "# formula <- as.formula(\"Convert ~ distance + traffic_volume + \")\n",
    "\n",
    "# Create the SVM model with the formula\n",
    "# svm_model <- svm(formula, data = parking_data, kernel = \"linear\")\n",
    "\n",
    "svm_model <- svm(formula, data = train_data, kernel = \"linear\", type = \"C-classification\")\n",
    "\n",
    "summary(svm_model)\n",
    "\n",
    "pred = predict(svm_model, newdata = train_data)\n",
    "\n",
    "pred_table = table( pred, train_data$Convert)\n",
    "pred_table\n",
    "sprintf(\"SVM Model prediction accuracy is %.2f %%\",(pred_table[1,1]+pred_table[2,2])/sum(pred_table) *100)\n",
    "# x = select(train_data,one_of(c(\"distance\",\"traffic_volume\",\"capacity\")))\n",
    "# y = select(train_data,\"Convert\")\n",
    "\n",
    "\n",
    "\n",
    "# pred <- predict(svm_model, x, decision.values = TRUE)\n",
    "# d_values <- attr(pred, \"decision.values\")[,]\n",
    "\n",
    "\n",
    "# write.csv(d_values,\"../Data/DataProcessing/d_values.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# # Get the coefficients (weights) of the model\n",
    "# weights <- coef(svm_model)\n",
    "# weights\n",
    "# # Coefficients from the SVM model\n",
    "# coefficients <- coef(svm_model)[-1]  # Exclude the intercept\n",
    "\n",
    "# # Select the columns for which to calculate the score\n",
    "# cols <- c(\"distance\",  \"traffic_volume\",\"capacity\")\n",
    "\n",
    "# # Calculate the score for each row\n",
    "# parking_data$score <- rowSums(parking_data[cols] * coefficients)\n",
    "\n",
    "# # Sort the rows in descending order according to the score\n",
    "\n",
    "pred_outcome_svm = predict(svm_model, newdata = predict_data, decision.values = TRUE )\n",
    "sorted_result <- predict_data\n",
    "sorted_result$pred_outcome_svm = pred_outcome_svm\n",
    "sorted_result$d_value = attributes(pred_outcome_svm)$decision.values\n",
    "# sorted_result <- predict_data %>%\n",
    "#   mutate(pred_outcome_svm = predict(svm_model, newdata = ., decision.values = TRUE )) #%>% \n",
    "#   mutate(Pred_D_value = attr(predict(svm_model, newdata = ., decision.values = TRUE ),decision.values))\n",
    "sorted_result<- sorted_result %>%\n",
    "    arrange(desc(d_value)) %>%\n",
    "    select(id,address, d_value)\n",
    "\n",
    "# View the sorted result (Top  parking locations)\n",
    "head(sorted_result,5)\n",
    "\n",
    "#save sorted_result as a csv for future ease of use\n",
    "write.csv(sorted_result,\"../Data/DataProcessing/sorted_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Result and Discussion\n",
    "\n",
    "# The SVM model was constructed with data that had a lot of underlying assumptions, including some artificial\n",
    "# simulated data. The intention is to demonstrate a approach translate multiple sources of data into actionable\n",
    "# business decisions using  machine learning modelling. \n",
    "# The specific machine learning techniques are:\n",
    "#  K Nearest Neighbor, Time Series Forecasting and SVM Classification\n",
    "# The Final Model and prediction have several drawbacks. \n",
    "# 1) the training data is limited as there are only 9 parking lots with EV chargers out of 220 surface lots. \n",
    "# 2) the decision values are close to zero, which represents low confidence guesses. This reflects a rather poor model. \n",
    "# More data input such as near by population and acutal car park usage rate and real business customer data could've\n",
    "# produced better output. A larger training set could also improve the performance of the model with more confident\n",
    "# predictions. Overall, the approach is shown to be feasible and could yield potential benefits in complimenting the \n",
    "# decision making process. \n",
    "\n",
    "# see more details in the report. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
