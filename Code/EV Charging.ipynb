{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load all required libraries for the notebook, including data package\n",
    "if(!require(\"opendatatoronto\")) {\n",
    "    install.packages(\"opendatatoronto\")\n",
    "    library(opendatatoronto) # data source\n",
    "}\n",
    "if(!require(\"tidyjson\")) {\n",
    "    install.packages(\"tidyjson\")\n",
    "    library(tidyjson)\n",
    "}\n",
    "if(!require(\"tidygeocoder\")) {\n",
    "    install.packages(\"tidygeocoder\")\n",
    "    library(tidygeocoder)\n",
    "}\n",
    "if(!require(\"sf\")) {\n",
    "    install.packages(\"sf\")\n",
    "    library(sf)\n",
    "}\n",
    "\n",
    "if(!require(\"ggspatial\")) {\n",
    "    install.packages(\"ggspatial\")\n",
    "    library(ggspatial)\n",
    "}\n",
    "if(!require(\"stringr\")) {\n",
    "    install.packages(\"stringr\")\n",
    "    library(stringr)\n",
    "}\n",
    "if(!require(\"dplyr\")) {\n",
    "    install.packages(\"dplyr\")\n",
    "    library(dplyr)\n",
    "}\n",
    "if(!require(\"ggplot2\")) {\n",
    "    install.packages(\"ggplot2\")\n",
    "    library(ggplot2)\n",
    "}\n",
    "if(!require(\"tidyverse\")) {\n",
    "    install.packages(\"tidyverse\")\n",
    "    library(tidyverse)\n",
    "}\n",
    "if(!require(\"FNN\")) {\n",
    "    install.packages(\"FNN\")\n",
    "    library(FNN)\n",
    "}\n",
    "\n",
    "if(!require(\"mapview\")) {\n",
    "    install.packages(\"mapview\")\n",
    "    library(mapview)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Traffic\n",
    "# output Data Description:\n",
    "# Dataframe with all intersection and daily count ( peak 4 hours), including lng / lat\n",
    "\n",
    "# # ? and todo:\n",
    "# # is separate street name needed\n",
    "# # direction of the street to be determined. How?\n",
    "\n",
    "\n",
    "# # package_traffic <- show_package(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# # get all resources for this package\n",
    "# resources <- list_package_resources(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# # identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "# datastore_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"geojson\"))\n",
    "\n",
    "# # load data # The method of loading data directly using turns out to be insufficient as the get_resource() only returns first 32000 rows of record. \n",
    "# location <- filter(datastore_resources, row_number() == 1) %>% get_resource()\n",
    "# traffic1 <- filter(datastore_resources, row_number() == 3) %>% get_resource()\n",
    "# traffic2 <- filter(datastore_resources, row_number() == 4) %>% get_resource()\n",
    "# traffic3 <- filter(datastore_resources, row_number() == 5) %>% get_resource()\n",
    "# traffic4 <- filter(datastore_resources, row_number() == 6) %>% get_resource()\n",
    "# traffic5 <- filter(datastore_resources, row_number() == 7) %>% get_resource()\n",
    "\n",
    "# To Run the code download the raw files from \n",
    "# https://open.toronto.ca/dataset/traffic-volumes-at-intersections-for-all-modes/ \n",
    "# and save the files in .csv format to the path: ../Data/Toronto/Traffic, 7 Files below. \n",
    "# count_metadata.csv\n",
    "# locations.csv\n",
    "# raw-data-1980-1989.csv\n",
    "# raw-data-1990-1999.csv\n",
    "# raw-data-2000-2009.csv\n",
    "# raw-data-2010-2019.csv\n",
    "# raw-data-2020-2029.csv\n",
    "location <- read.csv(\"../Data/Toronto/Traffic/locations.csv\") # ensure these path are correct if you have to download the files manually. \n",
    "traffic1 <- read.csv(\"../Data/Toronto/Traffic/raw-data-1980-1989.csv\")\n",
    "traffic2 <- read.csv(\"../Data/Toronto/Traffic/raw-data-1990-1999.csv\")\n",
    "traffic3 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2000-2009.csv\")\n",
    "traffic4 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2010-2019.csv\")\n",
    "traffic5 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2020-2029.csv\")\n",
    "all_traffic = bind_rows(traffic1,traffic2,traffic3,traffic4,traffic5) # combine all raw data into one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# clean and transform load - Traffic Data\n",
    "# Output data for modelling CleanTraffic\n",
    "# define parameters for cleaning\n",
    "peakhours <- 4 # number of peak hours of data per day. value should be between 1 and 10\n",
    "\n",
    "# get full intersection volume for each intersection based on peak hours of each day. \n",
    "# get average vol per intersection per year. \n",
    "# get number of years list, sort from low to high\n",
    "\n",
    "# \n",
    "\n",
    "CleanTraffic <- all_traffic %>%\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise_at(\"total_int_traffic\",sum) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise_at(\"total_int_traffic\", sum)%>% # aggregate daily peak hour volume\n",
    "  mutate(count_date= as.Date(count_date, format(\"%Y-%m-%d\"))) %>% \n",
    "  mutate(year = as.numeric(format(count_date,'%Y'))) %>% #add year\n",
    "  group_by(across(all_of(c(\"year\", \"location_id\", \"location\", \"lat\",\"lng\")))) %>% # group by year to get the average per intersection per year\n",
    "  summarise(AvgTotal = mean(total_int_traffic), .groups = \"drop\")  # average traffic volume for that year and location\n",
    "traffic_years <- unique(CleanTraffic$year) # get number of years list, sort from low to high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>address</dt><dd>'character'</dd><dt>lat</dt><dd>'character'</dd><dt>lng</dt><dd>'character'</dd><dt>carpark_type</dt><dd>'character'</dd><dt>rate_half_hr</dt><dd>'character'</dd><dt>capacity</dt><dd>'character'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[address] 'character'\n",
       "\\item[lat] 'character'\n",
       "\\item[lng] 'character'\n",
       "\\item[carpark\\textbackslash{}\\_type] 'character'\n",
       "\\item[rate\\textbackslash{}\\_half\\textbackslash{}\\_hr] 'character'\n",
       "\\item[capacity] 'character'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "address\n",
       ":   'character'lat\n",
       ":   'character'lng\n",
       ":   'character'carpark_type\n",
       ":   'character'rate_half_hr\n",
       ":   'character'capacity\n",
       ":   'character'\n",
       "\n"
      ],
      "text/plain": [
       "     address          lat          lng carpark_type rate_half_hr     capacity \n",
       " \"character\"  \"character\"  \"character\"  \"character\"  \"character\"  \"character\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>address</dt><dd>'character'</dd><dt>lat</dt><dd>'numeric'</dd><dt>lng</dt><dd>'numeric'</dd><dt>carpark_type</dt><dd>'character'</dd><dt>rate_half_hr</dt><dd>'numeric'</dd><dt>capacity</dt><dd>'numeric'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[address] 'character'\n",
       "\\item[lat] 'numeric'\n",
       "\\item[lng] 'numeric'\n",
       "\\item[carpark\\textbackslash{}\\_type] 'character'\n",
       "\\item[rate\\textbackslash{}\\_half\\textbackslash{}\\_hr] 'numeric'\n",
       "\\item[capacity] 'numeric'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "address\n",
       ":   'character'lat\n",
       ":   'numeric'lng\n",
       ":   'numeric'carpark_type\n",
       ":   'character'rate_half_hr\n",
       ":   'numeric'capacity\n",
       ":   'numeric'\n",
       "\n"
      ],
      "text/plain": [
       "     address          lat          lng carpark_type rate_half_hr     capacity \n",
       " \"character\"    \"numeric\"    \"numeric\"  \"character\"    \"numeric\"    \"numeric\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "FALSE"
      ],
      "text/latex": [
       "FALSE"
      ],
      "text/markdown": [
       "FALSE"
      ],
      "text/plain": [
       "[1] FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get Green P Parking package from Open Data-Toronto\n",
    "package <- show_package(\"b66466c3-69c8-4825-9c8b-04b270069193\")\n",
    "\n",
    "data=as.data.frame('Green P Parking')  # read the dataset Green P Parking in the package \n",
    "data<-show_package(package)\n",
    "\n",
    "resources<-list_package_resources(package)\n",
    "\n",
    "# Identify resources\n",
    "data_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"json\"))\n",
    "\n",
    "# Load Green P Parking 2019 data\n",
    "data <- filter(data_resources, row_number() == 1) %>% get_resource()\n",
    "\n",
    "# Extract required columns from main data\n",
    "data<- data.frame(address=data$carparks$address,\n",
    "                                     lat=data$carparks$lat,\n",
    "                                     lng=data$carparks$lng,\n",
    "                                      carpark_type=data$carparks$carpark_type_str,\n",
    "                                      rate_half_hr=data$carparks$rate_half_hour,\n",
    "                                      capacity=data$carparks$capacity,\n",
    "                                      rate=data$carparks$rate_half_hour\n",
    "                  )\n",
    "\n",
    "# Check class of each attribute\n",
    "sapply(data, class) \n",
    "\n",
    "# Convert char to numeric class\n",
    "data$lat<-as.numeric(data$lat)\n",
    "data$lng<-as.numeric(data$lng)\n",
    "data$rate_half_hr<-as.numeric(data$rate_half_hr)\n",
    "data$capacity<-as.numeric(data$capacity)\n",
    "\n",
    "sapply(data, class) \n",
    "\n",
    "# Check for missing values\n",
    "any(is.na(data))\n",
    "\n",
    "# Extract street name from address\n",
    "data <- data %>%\n",
    "  mutate(extracted_address = str_replace_all(data$address, \"\\\\(.*?\\\\)\",\"\"))\n",
    "\n",
    "data$extracted_address<-str_replace_all(data$extracted_address, \"-.*\", \"\")\n",
    "data$extracted_address<-str_replace_all(data$extracted_address, \",.*\", \"\")\n",
    "\n",
    "# Extract data with carpark_type as 'Surface'\n",
    "data <- data %>%\n",
    "  filter(carpark_type == \"Surface\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing 220 coordinates to the Nominatim single coordinate geocoder\n",
      "\n",
      "Query completed in: 228.1 seconds\n",
      "\n",
      "\u001b[1m\u001b[22mNew names:\n",
      "\u001b[36m•\u001b[39m `address` -> `address...1`\n",
      "\u001b[36m•\u001b[39m `address` -> `address...8`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple feature collection with 8 features and 5 fields\n",
      "Geometry type: POINT\n",
      "Dimension:     XY\n",
      "Bounding box:  xmin: -79.42565 ymin: 43.65635 xmax: -79.40412 ymax: 43.66688\n",
      "Geodetic CRS:  WGS 84\n",
      "                                    address carpark_type rate_half_hr capacity\n",
      "16                    365 Lippincott Street      Surface          2.0      144\n",
      "27                    557 Palmerston Avenue      Surface          2.0       55\n",
      "33                       675 Manning Avenue      Surface          2.0       49\n",
      "34  745 Ossington Avenue, 16 Carling Avenue      Surface          2.0       45\n",
      "48                       376 Clinton Street      Surface          1.5       33\n",
      "90                        80 Clinton Street      Surface          1.5       25\n",
      "110                          4 Spadina Road      Surface          1.5       51\n",
      "121                    292 Brunswick Avenue      Surface          2.0       19\n",
      "        extracted_address                   geometry\n",
      "16  365 Lippincott Street POINT (-79.40966 43.66505)\n",
      "27  557 Palmerston Avenue POINT (-79.41358 43.66504)\n",
      "33     675 Manning Avenue POINT (-79.41601 43.66465)\n",
      "34   745 Ossington Avenue POINT (-79.42565 43.66243)\n",
      "48     376 Clinton Street POINT (-79.41758 43.66444)\n",
      "90      80 Clinton Street POINT (-79.41455 43.65635)\n",
      "110        4 Spadina Road POINT (-79.40412 43.66688)\n",
      "121  292 Brunswick Avenue POINT (-79.40764 43.66537)\n"
     ]
    }
   ],
   "source": [
    "# Graphical View of Parking Data\n",
    "# Convert Lat/Lng to address\n",
    "geo_rev_data<-data %>%\n",
    "  tidygeocoder::reverse_geocode(\n",
    "    lat=lat,\n",
    "    long=lng,\n",
    "    method=\"osm\")\n",
    "\n",
    "# Plot map\n",
    "map<-data %>%\n",
    "  st_as_sf(\n",
    "    coords=c(\"lng\",\"lat\"),\n",
    "    crs=4326\n",
    "  )\n",
    "\n",
    "map %>% mapview()\n",
    "\n",
    "# Define the polygon coordinates\n",
    "polygon_coords <- matrix(c(\n",
    "  -79.4289964889767, 43.6700360241176, -79.4226792245877, 43.6543887000655, -79.4000484228339, 43.657948514946, -79.4070875693025, 43.6748646586934,-79.4289964889767, 43.6700360241176  # Repeat first point to close the polygon exactly\n",
    "), ncol = 2, byrow = TRUE)\n",
    "\n",
    "# Create a polygon geometry\n",
    "polygon <- st_polygon(list(polygon_coords))\n",
    "\n",
    "# Convert the polygon object to an 'sf' object with a specified CRS (Coordinate Reference System)\n",
    "polygon <- st_sfc(polygon, crs = 4326)\n",
    "\n",
    "# Convert the data frame 'data' to an 'sf' object, specifying the columns containing longitude and latitude as coordinates, and set the CRS\n",
    "data_sf <- st_as_sf(data, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Find the indices of the rows in 'data_sf' that fall within the polygon\n",
    "indices <- st_within(data_sf, polygon)\n",
    "\n",
    "# Convert the indices to a data frame\n",
    "indices_df<-data.frame(indices)\n",
    "\n",
    "selected_rows <- data_sf[match(indices_df$row.id, seq_len(nrow(data))), ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot selected rows on map\n",
    "map_df <- selected_rows %>%\n",
    "  st_as_sf() %>%\n",
    "  st_set_crs(4326) %>%\n",
    "  fortify()   # Convert the 'sf' object to a format suitable for use with 'ggplot2'\n",
    "\n",
    "# Display the spatial object using 'mapview'\n",
    "mapview(map_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(selected_rows, \"Parking.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Add lat, lng and remove geometry column\n",
    "selected_rows1<-selected_rows\n",
    "coords <- st_coordinates(selected_rows1$geometry)\n",
    "selected_rows1 <- cbind(selected_rows1, lng = coords[, \"X\"], lat = coords[, \"Y\"])\n",
    "parking_data <- st_drop_geometry(selected_rows1)\n",
    "write.csv(parking_data, \"Parking_data.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Intersection\n",
    "# output Data Description:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Business\n",
    "# output Data Description: \n",
    "# the output dataframe is 'biz_geo_loc1' which contains 13 variables i.e.\n",
    "# Category : business type as defined from Opendatatoronto\n",
    "# Operating.Name: business name as registered in Opendatatoronto\n",
    "# city: City where the business is located (extracted from business address)\n",
    "# Zip: postal code where business is located (extracted from business address)\n",
    "# Street street name where business is located (extracted from business address)\n",
    "# lat, long : Lattitude , Longitude converting from address into geocoder\n",
    "# lamda : customer arrival rate used to simulate the number of customer during busy hours(assumption) # nolint\n",
    "# mu : expected time spent (in hr) during busy hours of a customer (exponential distribution)  # nolint\n",
    "# qCustomer: number of customer at busy hours (simulated from lamda)\n",
    "# tCustomer: time spent at the business per customer (simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define Region of Interest - Boundary\n",
    "## coordinates manually looked up from location dataset\n",
    "# 1406\t5370\tDUPONT ST AT OSSINGTON AVE (PX 842)\t-79.429019\t43.670031996501194\n",
    "# 251\t4180\tDUPONT ST AT SPADINA RD (PX 840)\t-79.407122\t43.67485699954096\n",
    "# 1885\t5864\tCOLLEGE ST AT OSSINGTON AVE (PX 829)\t-79.422705\t43.65439999619167\n",
    "# 241\t4170\tCOLLEGE ST AT SPADINA AVE (PX 279)\t-79.400048\t43.65794800150128\n",
    "\n",
    "# Input\n",
    "# Output\n",
    "\n",
    "boundary <- location %>%\n",
    "  select(location_id, location, lng, lat) %>%\n",
    "  filter(location_id %in% list(5370, 4180, 5864, 4170)) # boundary intersection ID\n",
    "\n",
    "lng_min <- min(boundary$lng) # west most value since it's negative\n",
    "lng_max <- max(boundary$lng) # east most value\n",
    "lat_min <- min(boundary$lat) # south most value\n",
    "lat_max <- max(boundary$lat) # north most value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine Parking Data and Clean Traffic Data to prepare input data for Time Series Model to predict traffic / EV charging demand\n",
    "\n",
    "# loop through low to high year number\n",
    "# filter each year, to list of unique intersections with traffic volume\n",
    "# run knn algo against parking lot, find k nearst intersection\n",
    "# use knn nn.index to find the k intersection vol, get average, creating a vector\n",
    "# add vector to parking data as new column with year and volume\n",
    "# next loop for the next year\n",
    "\n",
    "#Output TS_Input\n",
    "\n",
    "K <- 5 # Parameter used in knn calculation. \n",
    "All_park <- data %>%\n",
    "    select(one_of(c(\"lat\",\"lng\"))) # location coordinates of all surface car parks. \n",
    "\n",
    "TS_Input <- data # TS_Input is the input data for the time series of traffic volume forecast. \n",
    "\n",
    "for (i in traffic_years) {\n",
    "    # print(paste(\"This is year\" ,i))\n",
    "    year_traffic<- filter(CleanTraffic, year == i) # get the traffic volume, intersection for each year.\n",
    "    All_int <-select(year_traffic,one_of(c(\"lat\",\"lng\"))) # extract just the coordinates for K nearest neighter calculation\n",
    "    knn_dist <- get.knnx(All_int, All_park, k=K, algorithm=\"kd_tree\") # get the K nearest intersection to the parking lot and their index list\n",
    "    \n",
    "    get.mean <- function(x) { # custom function defined to calculate the average of the K nearest intersection volume\n",
    "    mean(slice(year_traffic, c(x))$AvgTotal)\n",
    "    }\n",
    "\n",
    "    TS_Input[paste0(\"NearbyTraffic_\",i)]  <- apply(knn_dist$nn.index,1,get.mean) # calculate the avaerage per row of indices\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1 - Time Series Forecast\n",
    "\n",
    "# forecast traffic for 2024 given the TS_Input\n",
    "# apply % of EV vehicle multiplier for 2022 and predicted year 2024 to get amount of estimated EV traffic.\n",
    "# data frame that has the original location, EV traffic for 2022, and predicted EV traffic for 2024\n",
    "\n",
    "\n",
    "library(forecast)\n",
    "library(purrr)\n",
    "\n",
    "# Time series model and Forecast for 2024\n",
    "arima_models <- apply(TS_Input[, -c(1,2,3,4,5,6,7,8)], 1, auto.arima)\n",
    "model_forecasts_2024 <- lapply(arima_models, function(x) forecast(x, h = 1))\n",
    "\n",
    "TS_Output_2024 <- map_dbl(model_forecasts_2024, \"mean\")\n",
    "TS_Output_2024 <- round(TS_Output_2024)\n",
    "\n",
    "\n",
    "# Format output for 2024\n",
    "# Data frame that contains the original location, lat, and lng columns,\n",
    "# % of EV traffic for 2022 and % of EV traffic for predicted 2024\n",
    "\n",
    "head(TS_Output_2024)\n",
    "\n",
    "# Testing code: Compare length of real data and predicted data. Should be matching\n",
    "length(TS_Input$NearbyTraffic_2022)\n",
    "length(TS_Output_2024)\n",
    "\n",
    "# % of EV vehicle multiplier for 2022\n",
    "mulitplier_2022 = .03\n",
    "\n",
    "# % of EV Vehicle multiplier for predicted year \n",
    "multiplier_predicted = .0533\n",
    "\n",
    "TS_Output_df = data.frame(TS_Input$address,TS_Input$lat,TS_Input$lng, TS_Input$NearbyTraffic_2022,TS_Output_2024)\n",
    "head(TS_Output_df)\n",
    "\n",
    "# Apply % of EV Vehicle multiplier to 2022 and predicted year 2024, present a new columns to Df\n",
    "traffic_2022 <- data.frame(TS_Output_df$TS_Input.NearbyTraffic_2022)\n",
    "traffic_2024 <-data.frame(TS_Output_df$TS_Output_2024)\n",
    "\n",
    "TS_Output_df$EV_nearbyTraffic_2022 <- apply(traffic_2022, 1, function(x) round(x * mulitplier_2022))\n",
    "TS_Output_df$EV_nearbyTraffic_2024 <- apply(traffic_2024, 1, function(x) round(x * multiplier_predicted))\n",
    "\n",
    "\n",
    "# Final Output\n",
    "head(TS_Output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Model 2 - Regression Model\n",
    "\n",
    "# Read data\n",
    "parking<-read.csv(\"Parking_data.csv\")\n",
    "business<-read.csv(\"business.csv\")\n",
    "\n",
    "# Convert the business dataset to a spatial object\n",
    "business_sf <- st_as_sf(business, coords = c(\"long\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Convert the parking dataset to a spatial object\n",
    "parking_sf <- st_as_sf(parking, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Perform a spatial join to find the nearest business for each parking space\n",
    "nearest_business <- st_nearest_feature(parking_sf, business_sf)\n",
    "\n",
    "# Add the nearest business information to the parking dataset\n",
    "parking_data_with_nearest_business <- cbind(parking, nearest_business)\n",
    "parking_data_with_nearest_business$traffic_volume= sample(2:200,nrow(parking), replace=F)  # To be replaced with traffic data\n",
    "\n",
    "# An empty list to store the results\n",
    "result_list <- list()\n",
    "#parking_data_with_nearest_business <- parking\n",
    "\n",
    "\n",
    "# An empty list to store the results\n",
    "result_list <- list()\n",
    "\n",
    "# Function to calculate angular distance between two points on Earth\n",
    "haversine_distance <- function(lon1, lat1, lon2, lat2) {\n",
    "  R <- 6371 # Earth radius in km\n",
    "  dlat <- (lat2 - lat1) * pi / 180\n",
    "  dlon <- (lon2 - lon1) * pi / 180\n",
    "  a <- sin(dlat/2)^2 + cos(lat1 * pi / 180) * cos(lat2 * pi / 180) * sin(dlon/2)^2\n",
    "  c <- 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "  distance <- R * c\n",
    "  return(distance) # Distance in km\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate distance between each parking spot and each business\n",
    "\n",
    "# Create an empty list to store the results\n",
    "result_list <- list()\n",
    "\n",
    "for (i in 1:nrow(parking_data_with_nearest_business)){\n",
    "  \n",
    "  # Create a temporary data frame to store the results for this parking spot\n",
    "  temp_df <- data.frame(\n",
    "    address = character(),\n",
    "    lat = double(),\n",
    "    lng = double(),\n",
    "    distance = double(),\n",
    "    capacity = integer(),\n",
    "    traffic_volume = integer(),\n",
    "    rate_half_hr= double(),\n",
    "    #n_business = integer(),\n",
    "    n_customers =integer(),\n",
    "    time_spent = double(),\n",
    "    category = character(),\n",
    "    interaction_term = integer()\n",
    "  )\n",
    "  \n",
    "  for( j in 1:nrow(business)){\n",
    "    lon1 <- parking_data_with_nearest_business[i,\"lng\"]\n",
    "    lat1 <- parking_data_with_nearest_business[i,\"lat\"]\n",
    "    lon2 <- business[j, \"long\"]\n",
    "    lat2 <- business[j, \"lat\"]\n",
    " \n",
    "\n",
    "    # Calculate distance\n",
    "    distance <- st_distance(st_point(c(lon1, lat1)), st_point(c(lon2, lat2)))\n",
    "    \n",
    "    # Store the results in the temporary data frame\n",
    "    temp_df[nrow(temp_df) + 1, ] <- list(\n",
    "      address = parking_data_with_nearest_business[i,\"address\"],\n",
    "      lat = parking_data_with_nearest_business[i,\"lat\"],\n",
    "      lng = parking_data_with_nearest_business[i,\"lng\"],\n",
    "      distance = distance,\n",
    "      capacity = parking_data_with_nearest_business[i,\"capacity\"],\n",
    "      traffic_volume = parking_data_with_nearest_business[i,\"traffic_volume\"],\n",
    "      #n_business = parking_data_with_nearest_business[i,\"nearest_business\"],\n",
    "      rate_half_hr = parking_data_with_nearest_business[i,\"rate_half_hr\"],\n",
    "      n_customers = business[j,\"qCustomer\"],\n",
    "      time_spent = business[j,\"tCustomer\"],\n",
    "      category = business[j,\"Category\"],\n",
    "      interaction_term = business[j,\"qCustomer\"] * business[j,\"tCustomer\"]\n",
    "    )\n",
    "  }\n",
    "  \n",
    "  # Append the temporary data frame to the result list\n",
    "  result_list[[i]] <- temp_df\n",
    "}\n",
    "\n",
    "# Combine all the results into a single data frame\n",
    "result_df <- do.call(rbind, result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filter rows according to radius\n",
    "\n",
    "filtered_result_df <- result_df[result_df$distance <= 0.50, ]\n",
    "a=filtered_result_df %>% count(address)\n",
    "\n",
    "\n",
    "filtered_result_df <- filtered_result_df %>%\n",
    "  left_join(a, by = \"address\")\n",
    "\n",
    "# Select desired columns and rename the \"n\" column\n",
    "filtered_result_df <- filtered_result_df %>%\n",
    "  select(address, lat,lng, distance,rate_half_hr, n_businesses = n, capacity, n_customers, time_spent, traffic_volume, interaction_term) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model1 <- lm(capacity ~ traffic_volume  + distance + n_customers + time_spent + interaction_term  + rate_half_hr, data = filtered_result_df)\n",
    "\n",
    "summary(model1)\n",
    "\n",
    "model2 <- lm(capacity ~ traffic_volume  + distance  + rate_half_hr + interaction_term, data = filtered_result_df)\n",
    "summary(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------For 0.4 * existing traffic_volume -----------------------------------\n",
    "\n",
    "all_results <- data.frame()\n",
    "\n",
    "x_percent=0.4\n",
    "new_traffic_scenario = filtered_result_df$traffic_volume * x_percent\n",
    "newdata = data.frame(traffic_volume = new_traffic_scenario,\n",
    "                     address=filtered_result_df$address,\n",
    "                     distance = filtered_result_df$distance,\n",
    "                     n_customers = filtered_result_df$n_customers,\n",
    "                     time_spent = filtered_result_df$time_spent,\n",
    "                     interaction_term = filtered_result_df$interaction_term,\n",
    "                     rate_half_hr= filtered_result_df$rate_half_hr)\n",
    "\n",
    "# Make predictions\n",
    "predicted_capacity <- predict(model2, newdata)\n",
    "\n",
    "# Determine conversion needs\n",
    "capacity_needed <- ifelse(predicted_capacity > 1, ceiling(predicted_capacity), 0)\n",
    "\n",
    "# Store results for this scenario \n",
    "results <- data.frame(filtered_result_df$address, filtered_result_df$lat, filtered_result_df$lng, filtered_result_df$capacity,capacity_needed, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent)\n",
    "\n",
    "\n",
    "# ----------------------------For different % of traffic_volumes -----------------------------------\n",
    "\n",
    "# Iterate for different EV adoption rates\n",
    "x_percent_values <- seq(from = 0.1, to = 1, by = 0.4)  \n",
    "all_results <- data.frame()\n",
    "\n",
    "for (x_percent in x_percent_values) {\n",
    "  # Create new traffic scenario\n",
    "  new_traffic_scenario = result_df$traffic_volume * x_percent\n",
    "  newdata = data.frame(traffic_volume = new_traffic_scenario,\n",
    "                     address=filtered_result_df$address,\n",
    "                     distance = filtered_result_df$distance,\n",
    "                     n_customers = filtered_result_df$n_customers,\n",
    "                     time_spent = filtered_result_df$time_spent,\n",
    "                     interaction_term = filtered_result_df$interaction_term,\n",
    "                     rate_half_hr= filtered_result_df$rate_half_hr)\n",
    "\n",
    "  # Make predictions\n",
    "  predicted_capacity <- predict(model1, newdata)\n",
    "  # Determine conversion needs\n",
    "  capacity_needed <- ifelse(predicted_capacity > 1, ceiling(predicted_capacity), 0)\n",
    "\n",
    "  # Store results for this scenario \n",
    "  results <- data.frame(data.frame(filtered_result_df$address, filtered_result_df$lat, filtered_result_df$lng, filtered_result_df$capacity,capacity_needed, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent))\n",
    "  all_results <- rbind(all_results, results)\n",
    "}\n",
    "\n",
    "# Sort combined results\n",
    "all_results <- arrange(all_results, x_percent)\n",
    "\n",
    "# Create table\n",
    "library(kableExtra)  \n",
    "table <- kable(all_results, caption = \"Conversion Needs by EV Adoption Rate\")\n",
    "print(table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# # Scoring function\n",
    "# calculate_score <- function(traffic_volume, capacity, rate_half_hr, nearest_businesses, customers, c_time, distance) {\n",
    "#   # Define weights for each factor\n",
    "#   weights <- c(0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.1)\n",
    "  \n",
    "#   # Normalize each factor\n",
    "#   normalized_traffic <- (traffic_volume - min(traffic_volume)) / (max(traffic_volume) - min(traffic_volume))\n",
    "#   normalized_capacity <- (capacity - min(capacity)) / (max(capacity) - min(capacity))\n",
    "#   normalized_rate <- (rate_half_hr - min(rate_half_hr)) / (max(rate_half_hr) - min(rate_half_hr))\n",
    "#   normalized_n_businesses <- (nearest_businesses - min(nearest_businesses)) / (max(nearest_businesses) - min(nearest_businesses))\n",
    "#   normalized_customers <-(customers - min(customers)) / (max(customers) - min(customers))\n",
    "#   normalized_time <- (c_time - min(c_time)) / (max(c_time) - min(c_time))\n",
    "#   normalized_distance <- (distance - min(distance)) / (max(distance) - min(distance))\n",
    "\n",
    "#   # Calculate the score\n",
    "#   score <- weights[1] * normalized_traffic +\n",
    "#     weights[2] * normalized_capacity +\n",
    "#     weights[3] * normalized_distance +\n",
    "#     weights[4] * normalized_n_businesses + \n",
    "#     weights[5] * (normalized_customers * normalized_time) +\n",
    "#     weights[6] * (normalized_rate)\n",
    "\n",
    "#   return(abs(score))\n",
    "# }\n",
    "\n",
    "# # Calculate score for each parking spot\n",
    "# filtered_result_df$score <- calculate_score(filtered_result_df$traffic_volume, filtered_result_df$capacity, filtered_result_df$rate_half_hr, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent,filtered_result_df$distance)\n",
    "# # Rank the parking spots based on the score\n",
    "# ranked_data <- filtered_result_df[order(-filtered_result_df$score),]\n",
    "\n",
    "# # Find highest scored parking spot\n",
    "# highest_score_index <- which.max(ranked_data$score)\n",
    "# highest_score_parking_spot <- filtered_result_df[highest_score_index, ]\n",
    "\n",
    "# # Print the result\n",
    "# print(paste0(\"Address of parking spot: \",highest_score_parking_spot$address))\n",
    "# print(paste0(\"Latitude of parking spot: \",highest_score_parking_spot$lat))\n",
    "# print(paste0(\"Longitude of parking spot: \",highest_score_parking_spot$lng))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Result and Discussion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
