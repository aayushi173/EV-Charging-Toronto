{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Load all required libraries for the notebook, including data package\n",
    "if(!require(\"opendatatoronto\")){\n",
    "    install.packages(\"opendatatoronto\")\n",
    "    library(opendatatoronto)\n",
    "} \n",
    "library(dplyr)\n",
    "library(stringr) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Traffice\n",
    "# output Data Description: \n",
    "# Dataframe with all intersection and daily count ( peak 4 hours), including lng / lat\n",
    "\n",
    "#? and todo:\n",
    "# is separate street name needed\n",
    "# direction of the street to be determined. How?\n",
    "\n",
    "\n",
    "# package_traffic <- show_package(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# get all resources for this package\n",
    "resources<- list_package_resources(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    " \n",
    "# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))\n",
    " \n",
    "# load data\n",
    "location <- filter(datastore_resources, row_number()==1) %>% get_resource()\n",
    "traffic1 <-filter(datastore_resources, row_number()==3) %>% get_resource()\n",
    "traffic2 <-filter(datastore_resources, row_number()==4) %>% get_resource()\n",
    "traffic3 <-filter(datastore_resources, row_number()==5) %>% get_resource()\n",
    "traffic4 <-filter(datastore_resources, row_number()==6) %>% get_resource()\n",
    "traffic5 <-filter(datastore_resources, row_number()==7) %>% get_resource()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# clean and transform load - Traffic Data\n",
    "# Output data for modelling CleanTraffic\n",
    "# define parameters for cleaning \n",
    "peakhours = 4 # number of peak hours of data per day. value should be between 1 and 10\n",
    "\n",
    "\n",
    "clean_T1 <- traffic1 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "clean_T2 <- traffic2 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T3 <- traffic3 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T4 <- traffic4 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T5 <- traffic5 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "\n",
    "CleanTraffic <-bind_rows(clean_T1,clean_T2,clean_T3,clean_T4,clean_T5)\n",
    "head(CleanTraffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Green P Parking\n",
    "# output Data Description: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Intersection\n",
    "# output Data Description: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Business\n",
    "# output Data Description: "
     "# Load libraries needed for general use\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(ggplot2)",
    "library(opendatatoronto)\n"
   "# get package\n",
    "package <- show_package(\"57b2285f-4f80-45fb-ae3e-41a02c3a137f\")\n",
    "package\n",
    "\n",
    "# get all resources for this package\n",
    "resources <- list_package_resources(\"57b2285f-4f80-45fb-ae3e-41a02c3a137f\")\n",
    "\n",
    "# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))\n",
    "\n",
    "# load the first datastore resource as a sample\n",
    "biz_data <- filter(datastore_resources, row_number()==1) %>% get_resource()\n",
    "biz_data\n",
    "\n",
      "############################### Data Cleansing ##################################################\n",
    "### Start cleaning up with change data type, filled in any empty data in Operating Name\n",
    "biz_data$Category = as.factor(biz_data$Category)\n",
    "biz_data$`Licence Address Line 2` = as.factor(biz_data$`Licence Address Line 2`)\n",
    "biz_data$Issued = as.Date(biz_data$Issued)\n",
    "biz_data$`Cancel Date` = as.Date(biz_data$`Cancel Date`)\n",
    "biz_data$`Last Record Update` = as.Date(biz_data$`Last Record Update`)\n",
    "biz_data$'Operating Name' <-ifelse(biz_data$'Operating Name' == \"\",biz_data$'Client Name',biz_data$'Operating Name')\n",
    "#str(biz_data)\n",
    "#summary(biz_data)\n",
    "head(biz_data)\n",
    "\n",
    "### remove biz that have cancel date as it indicates that business has already been cancelled (i.e. terminated)\n",
    "biz_data = biz_data[which(is.na(biz_data$'Cancel Date')),]\n",
    "\n",
    "#################################################################################################\n",
    "### only select business in Toronto with zip code starting with M3, M4, M5 and M6\n",
    "biz_data = biz_data[which(biz_data$'Licence Address Line 2' == \"TORONTO, ON\"),]\n",
    "biz_data = biz_data[which(biz_data$'Licence Address Line 3' > \"M3\" & biz_data$'Licence Address Line 3' < \"M7\"),]\n",
    "#################################################################################################\n",
    "#biz_data = biz_data %>%\n",
    "#  select(-'Cancel Date')\n",
    "\n",
    "###make column to identify street name from Licence.Address.Line.1 (might be useful for cluster work later)\n",
    "###first extracting the address number. grab only the data that are after the first space\n",
    "biz_data$Street <- sub(\"^\\\\S+\\\\s+\",'', biz_data$'Licence Address Line 1')\n",
    "###first extracting the address number. remove number\n",
    "biz_data$Street <- gsub(\"[[:digit:]]\", \"\", biz_data$Street)\n",
    "###remove other unneccessary characters\n",
    "biz_data$Street <- sub('-  ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('&A ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('& A ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('&B ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('& B ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('&  ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('&& ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('& ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('/ ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('-A ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('A-', '', biz_data$Street)\n",
    "biz_data$Street <- sub('- A ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('-B ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('- B ', '', biz_data$Street)\n",
    "biz_data$Street <- sub(\"(?<=^.{0}),\", \"\", biz_data$Street, perl = TRUE )\n",
    "biz_data$Street <- sub(\"(?<=^.{0})&\", \"\", biz_data$Street, perl = TRUE )\n",
    "biz_data$Street <- sub(\"(?<=^.{0})/\", \"\", biz_data$Street, perl = TRUE )\n",
    "biz_data$Street <- sub(\"(?<=^.{0})-\", \"\", biz_data$Street, perl = TRUE )\n",
    "### as data is not clean, there are sometimes suite number or other suffix follow them. therefore, we clean that part up too.\n",
    "biz_data$Street <- sub(\", #.*\", '', biz_data$Street)\n",
    "biz_data$Street <- sub(\" #.*\", '', biz_data$Street)\n",
    "biz_data$Street <- sub(\"#.*\", '', biz_data$Street)\n",
    "biz_data$Street <- sub(\" ,.*\", '', biz_data$Street)\n",
    "biz_data$Street <- sub(\",.*\", '', biz_data$Street)\n",
    "\n",
    "### use similar code to clean data and prepare for geo location\n",
    "biz_data$StreetAddress = paste(biz_data$'Licence Address Line 1')\n",
    "###remove other characters from address one\n",
    "biz_data$StreetAddress <- sub('-  ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('&A ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('& A ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('&B ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('& B ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('&  ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('&& ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('& ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('/ ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('-A ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('A-', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('- A ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('-B ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('- B ', '', biz_data$StreetAddress)\n",
    "### Removing suite number or other suffix follow them. therefore\n",
    "biz_data$StreetAddress <- sub(\", #.*\", '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub(\" #.*\", '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub(\"#.*\", '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub(\" ,.*\", '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub(\",.*\", '', biz_data$StreetAddress)\n",
    "############################### End of Data Cleansing ###########################################\n",
    "#######################Converting Address to Lat-Long ###########################################\n",
    "###convert to Lat- Long using tidygeocode : Reference https://www.youtube.com/watch?v=7nFZ5BwkAXc\n",
    "### Load libraries needed for geocode\n",
    "if (!require(tidyverse)) install.packages(\"tidyverse\")\n",
    "library(tidyverse)  \n",
    "if (!require(tidygeocoder)) install.packages(\"tidygeocoder\")\n",
    "library(tidygeocoder)  \n",
    "if (!require(sf)) install.packages(\"sf\")\n",
    "library(sf) \n",
    "if (!require(mapview)) install.packages(\"mapview\")\n",
    "library(mapview) \n",
    "\n",
    "### Prepare Data to be converted\n",
    "biz_data$Address <- paste(biz_data$StreetAddress,biz_data$'Licence Address Line 2',biz_data$'Licence Address Line 3', sep = \",\")\n",
    "biz_geo_loc = biz_data %>%\n",
    "  select(Category,`Operating Name`,city = 'Licence Address Line 2',Zip = 'Licence Address Line 3',Street, Address)\n",
    "\n",
    "### We narrow down the area to save time in processing, we have identify Toronoto City Center with following zipcode\n",
    "###area around M5C = M5H(W), M5B(N), M5E(S), M5A (E), M5G (NW), M5J (SW), M5T & M5V as extended area\n",
    "### for test purpose, select only M5C, M5E\n",
    "\n",
    "#biz_geo_loc = biz_geo_loc %>% filter(str_detect(Zip, \"M5C|M5E|M5B|M5G|M5H|M5T|M5V|M5J|M5A\"))\n",
    "#biz_geo_loc = biz_geo_loc %>% filter(str_detect(Zip, \"M5C|M5E\"))\n",
    "\n",
    "biz_geo_loc = biz_geo_loc %>% filter(str_detect(Zip, \"M6G|M6H|M6J|M5T|M5S|M5R|M4V\"))\n",
    "\n",
    "### Convert address to lat - long\n",
    "biz_geo_loc = biz_geo_loc %>%\n",
    "  tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "\n",
    "###check if any na\n",
    "sapply(biz_geo_loc, function(x) sum(is.na(x)))\n",
    "\n",
    "biz_geo_loc1 = biz_geo_loc[-which(is.na(biz_geo_loc$lat)),]\n",
    "biz_geo_loc2 = biz_geo_loc[which(is.na(biz_geo_loc$lat)),]\n",
    "\n",
    "\n",

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define Region of Interest - Boundary\n",
    "## coordinates manually looked up from location dataset\n",
    "#1406\t5370\tDUPONT ST AT OSSINGTON AVE (PX 842)\t-79.429019\t43.670031996501194\n",
    "# 251\t4180\tDUPONT ST AT SPADINA RD (PX 840)\t-79.407122\t43.67485699954096\n",
    "#1885\t5864\tCOLLEGE ST AT OSSINGTON AVE (PX 829)\t-79.422705\t43.65439999619167\n",
    "#241\t4170\tCOLLEGE ST AT SPADINA AVE (PX 279)\t-79.400048\t43.65794800150128\n",
    "\n",
    "# Input\n",
    "# Output\n",
    "\n",
    "boundary <- location %>%\n",
    "  select(location_id,location,lng,lat) %>%\n",
    "  filter(location_id %in% list(5370,4180,5864,4170)) # boundary intersection ID\n",
    "\n",
    "lng_min <- min(boundary$lng) # west most value since it's negative\n",
    "lng_max <- max(boundary$lng) # east most value\n",
    "lat_min <- min(boundary$lat) # south most value\n",
    "lat_max <- max(boundary$lat) # north most value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine Data for model building\n",
    "# what is the expected output of data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1 - Time Series Forecast\n",
    "# additional data processing needed before modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 2 - Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Result and Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
