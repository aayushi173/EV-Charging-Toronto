{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load all required libraries for the notebook, including data package\n",
    "if(!require(\"opendatatoronto\")) {\n",
    "    install.packages(\"opendatatoronto\")\n",
    "    library(opendatatoronto) # data source\n",
    "}\n",
    "if(!require(\"tidyjson\")) {\n",
    "    install.packages(\"tidyjson\")\n",
    "    library(tidyjson)\n",
    "}\n",
    "if(!require(\"tidygeocoder\")) {\n",
    "    install.packages(\"tidygeocoder\")\n",
    "    library(tidygeocoder)\n",
    "}\n",
    "if(!require(\"sf\")) {\n",
    "    install.packages(\"sf\")\n",
    "    library(sf)\n",
    "}\n",
    "\n",
    "if(!require(\"ggspatial\")) {\n",
    "    install.packages(\"ggspatial\")\n",
    "    library(ggspatial)\n",
    "}\n",
    "if(!require(\"stringr\")) {\n",
    "    install.packages(\"stringr\")\n",
    "    library(stringr)\n",
    "}\n",
    "if(!require(\"dplyr\")) {\n",
    "    install.packages(\"dplyr\")\n",
    "    library(dplyr)\n",
    "}\n",
    "if(!require(\"ggplot2\")) {\n",
    "    install.packages(\"ggplot2\")\n",
    "    library(ggplot2)\n",
    "}\n",
    "if(!require(\"tidyverse\")) {\n",
    "    install.packages(\"tidyverse\")\n",
    "    library(tidyverse)\n",
    "}\n",
    "if(!require(\"FNN\")) {\n",
    "    install.packages(\"FNN\")\n",
    "    library(FNN)\n",
    "}\n",
    "\n",
    "if(!require(\"mapview\")) {\n",
    "    install.packages(\"mapview\")\n",
    "    library(mapview)\n",
    "}\n",
    "\n",
    "if(!require(\"forecast\")) {\n",
    "    install.packages(\"forecast\")\n",
    "    library(forecast)\n",
    "}\n",
    "\n",
    "if(!require(\"purrr\")) {\n",
    "    install.packages(\"purrr\")\n",
    "    library(purrr)\n",
    "}\n",
    "\n",
    "if(!require(\"e1071\")) {\n",
    "    install.packages(\"e1071\")\n",
    "    library(e1071)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Traffic\n",
    "# output Data Description:\n",
    "# Dataframe with all intersection and daily count ( peak 4 hours), including lng / lat\n",
    "\n",
    "# # ? and todo:\n",
    "# # is separate street name needed\n",
    "# # direction of the street to be determined. How?\n",
    "\n",
    "\n",
    "# # package_traffic <- show_package(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# # get all resources for this package\n",
    "# resources <- list_package_resources(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# # identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "# datastore_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"geojson\"))\n",
    "\n",
    "# # load data # The method of loading data directly using turns out to be insufficient as the get_resource() only returns first 32000 rows of record. \n",
    "# location <- filter(datastore_resources, row_number() == 1) %>% get_resource()\n",
    "# traffic1 <- filter(datastore_resources, row_number() == 3) %>% get_resource()\n",
    "# traffic2 <- filter(datastore_resources, row_number() == 4) %>% get_resource()\n",
    "# traffic3 <- filter(datastore_resources, row_number() == 5) %>% get_resource()\n",
    "# traffic4 <- filter(datastore_resources, row_number() == 6) %>% get_resource()\n",
    "# traffic5 <- filter(datastore_resources, row_number() == 7) %>% get_resource()\n",
    "\n",
    "# To Run the code download the raw files from \n",
    "# https://open.toronto.ca/dataset/traffic-volumes-at-intersections-for-all-modes/ \n",
    "# and save the files in .csv format to the path: ../Data/Toronto/Traffic, 7 Files below. \n",
    "# count_metadata.csv\n",
    "# locations.csv\n",
    "# raw-data-1980-1989.csv\n",
    "# raw-data-1990-1999.csv\n",
    "# raw-data-2000-2009.csv\n",
    "# raw-data-2010-2019.csv\n",
    "# raw-data-2020-2029.csv\n",
    "location <- read.csv(\"../Data/Toronto/Traffic/locations.csv\") # ensure these path are correct if you have to download the files manually. \n",
    "traffic1 <- read.csv(\"../Data/Toronto/Traffic/raw-data-1980-1989.csv\")\n",
    "traffic2 <- read.csv(\"../Data/Toronto/Traffic/raw-data-1990-1999.csv\")\n",
    "traffic3 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2000-2009.csv\")\n",
    "traffic4 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2010-2019.csv\")\n",
    "traffic5 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2020-2029.csv\")\n",
    "all_traffic = bind_rows(traffic1,traffic2,traffic3,traffic4,traffic5) # combine all raw data into one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# clean and transform load - Traffic Data\n",
    "# Output data for modelling CleanTraffic\n",
    "# define parameters for cleaning\n",
    "peakhours <- 4 # number of peak hours of data per day. value should be between 1 and 10\n",
    "\n",
    "# get full intersection volume for each intersection based on peak hours of each day. \n",
    "# get average vol per intersection per year. \n",
    "# get number of years list, sort from low to high\n",
    "\n",
    "# \n",
    "\n",
    "CleanTraffic <- all_traffic %>%\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise_at(\"total_int_traffic\",sum) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise_at(\"total_int_traffic\", sum)%>% # aggregate daily peak hour volume\n",
    "  mutate(count_date= as.Date(count_date, format(\"%Y-%m-%d\"))) %>% \n",
    "  mutate(year = as.numeric(format(count_date,'%Y'))) %>% #add year\n",
    "  group_by(across(all_of(c(\"year\", \"location_id\", \"location\", \"lat\",\"lng\")))) %>% # group by year to get the average per intersection per year\n",
    "  summarise(AvgTotal = mean(total_int_traffic), .groups = \"drop\")  # average traffic volume for that year and location\n",
    "traffic_years <- unique(CleanTraffic$year) # get number of years list, sort from low to high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Business\n",
    "# output Data Description: \n",
    "# the output dataframe is 'biz_geo_loc1' which contains 13 variables i.e.\n",
    "# Category : business type as defined from Opendatatoronto\n",
    "# Operating.Name: business name as registered in Opendatatoronto\n",
    "# city: City where the business is located (extracted from business address)\n",
    "# Zip: postal code where business is located (extracted from business address)\n",
    "# Street street name where business is located (extracted from business address)\n",
    "# lat, long : Lattitude , Longitude converting from address into geocoder\n",
    "# lamda : customer arrival rate used to simulate the number of customer during busy hours(assumption)\n",
    "# mu : expected time spent (in hr) during busy hours of a customer (exponential distribution) \n",
    "# qCustomer: number of customer at busy hours (simulated from lamda)\n",
    "# tCustomer: time spent at the business per customer (simulated)\n",
    "##########################THE CODES ######################################\n",
    "# codes are separated into few sections:\n",
    "#section a) load data from Opendatatoronto to biz_data dataframe\n",
    "#section b) data cleansing in preparation for geocoder conversion\n",
    "#section c) address conversion to geocoder \n",
    "#section d) adding simulated number of customer (qCustomer) and time spent (tCustomer) during busy hours\n",
    "##########################################################################\n",
    "####section a) load data from Opendatatoronto to biz_data dataframe\n",
    "# Load libraries needed for loading data from toronto open data source\n",
    "if (!require(opendatatoronto)) install.packages(\"opendatatoronto\")\n",
    "library(opendatatoronto)\n",
    "\n",
    "# get package\n",
    "package <- show_package(\"57b2285f-4f80-45fb-ae3e-41a02c3a137f\")\n",
    "#package\n",
    "\n",
    "# get all resources for this package\n",
    "resources <- list_package_resources(\"57b2285f-4f80-45fb-ae3e-41a02c3a137f\")\n",
    "\n",
    "# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))\n",
    "\n",
    "# load the first datastore resource as a sample\n",
    "biz_data <- filter(datastore_resources, row_number()==1) %>% get_resource()\n",
    "#biz_data\n",
    "\n",
    "### backup data to biz_data_bak\n",
    "biz_data_bak = biz_data\n",
    "\n",
    "###Meaning of the data according to the readme from website are as follows\n",
    "###Category=Type of licence or permit\n",
    "###Licence No=Number. of licence issued by City of Toronto\n",
    "###Operating Name=Name that company operates under\n",
    "###Issued=Date of issue of licence/permit\n",
    "###Client Name=Name that the licence is issued to\n",
    "###Business Phone=Client Business Phone Number\n",
    "###Business Phone Ext.=Client Business Phone Extension Number\n",
    "###Licence Address Line 1=First line of client's business address\n",
    "###Licence Address Line 2=Client address town and province\n",
    "###Licence Address Line 3=Client address postal code\n",
    "###Conditions=Restriction on the licence/permit recorded in the licensing system\n",
    "###Free Form Conditions Line 1=Restriction/comment on the licence/permit\n",
    "###Free Form Conditions Line 2=Continuation of line 1 \n",
    "###Plate No.=Licence identifying plate, issued to most vehicles\n",
    "###Endorsements=Activity permitted under the licence\n",
    "###Cancel Date=Date the license or permit was cancelled\n",
    "############### End Of Data loading from  Toronto Open Data Source########\n",
    "##########################################################################\n",
    "####section b) data cleansing in preparation for geocoder conversion\n",
    "### Start cleaning up with change data type, filled in any empty data in Operating Name\n",
    "biz_data$Category = as.factor(biz_data$Category)\n",
    "biz_data$`Licence Address Line 2` = as.factor(biz_data$`Licence Address Line 2`)\n",
    "biz_data$Issued = as.Date(biz_data$Issued)\n",
    "biz_data$`Cancel Date` = as.Date(biz_data$`Cancel Date`)\n",
    "biz_data$`Last Record Update` = as.Date(biz_data$`Last Record Update`)\n",
    "biz_data$'Operating Name' <-ifelse(biz_data$'Operating Name' == \"\",biz_data$'Client Name',biz_data$'Operating Name')\n",
    "#str(biz_data)\n",
    "#summary(biz_data)\n",
    "#head(biz_data)\n",
    "\n",
    "### remove biz that have cancel date as it indicates that business has already been cancelled (i.e. terminated)\n",
    "biz_data = biz_data[which(is.na(biz_data$'Cancel Date')),]\n",
    "\n",
    "#################################################################################################\n",
    "### only select business in Toronto with zip code starting with M3, M4, M5 and M6\n",
    "biz_data = biz_data[which(biz_data$'Licence Address Line 2' == \"TORONTO, ON\"),]\n",
    "biz_data = biz_data[which(biz_data$'Licence Address Line 3' > \"M3\" & biz_data$'Licence Address Line 3' < \"M7\"),]\n",
    "#################################################################################################\n",
    "#biz_data = biz_data %>%\n",
    "#  select(-'Cancel Date')\n",
    "\n",
    "###make column to identify street name from Licence.Address.Line.1 (might be useful for cluster work later)\n",
    "###first extracting the address number. grab only the data that are after the first space\n",
    "biz_data$Street <- sub(\"^\\\\S+\\\\s+\",'', biz_data$'Licence Address Line 1')\n",
    "###first extracting the address number. remove number\n",
    "biz_data$Street <- gsub(\"[[:digit:]]\", \"\", biz_data$Street)\n",
    "###remove other unneccessary characters\n",
    "biz_data$Street <- sub('-  ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('&A ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('& A ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('&B ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('& B ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('&  ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('&& ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('& ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('/ ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('-A ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('A-', '', biz_data$Street)\n",
    "biz_data$Street <- sub('- A ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('-B ', '', biz_data$Street)\n",
    "biz_data$Street <- sub('- B ', '', biz_data$Street)\n",
    "biz_data$Street <- sub(\"(?<=^.{0}),\", \"\", biz_data$Street, perl = TRUE )\n",
    "biz_data$Street <- sub(\"(?<=^.{0})&\", \"\", biz_data$Street, perl = TRUE )\n",
    "biz_data$Street <- sub(\"(?<=^.{0})/\", \"\", biz_data$Street, perl = TRUE )\n",
    "biz_data$Street <- sub(\"(?<=^.{0})-\", \"\", biz_data$Street, perl = TRUE )\n",
    "### as data is not clean, there are sometimes suite number or other suffix follow them. therefore, we clean that part up too.\n",
    "biz_data$Street <- sub(\", #.*\", '', biz_data$Street)\n",
    "biz_data$Street <- sub(\" #.*\", '', biz_data$Street)\n",
    "biz_data$Street <- sub(\"#.*\", '', biz_data$Street)\n",
    "biz_data$Street <- sub(\" ,.*\", '', biz_data$Street)\n",
    "biz_data$Street <- sub(\",.*\", '', biz_data$Street)\n",
    "\n",
    "### use similar code to clean data and prepare for geo location\n",
    "biz_data$StreetAddress = paste(biz_data$'Licence Address Line 1')\n",
    "###remove other characters from address one\n",
    "biz_data$StreetAddress <- sub('-  ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('&A ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('& A ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('&B ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('& B ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('&  ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('&& ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('& ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('/ ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('-A ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('A-', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('- A ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('-B ', '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub('- B ', '', biz_data$StreetAddress)\n",
    "### Removing suite number or other suffix follow them. therefore\n",
    "biz_data$StreetAddress <- sub(\", #.*\", '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub(\" #.*\", '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub(\"#.*\", '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub(\" ,.*\", '', biz_data$StreetAddress)\n",
    "biz_data$StreetAddress <- sub(\",.*\", '', biz_data$StreetAddress)\n",
    "############################### End of Data Cleansing ####################\n",
    "##########################################################################\n",
    "####section c) address conversion to geocoder \n",
    "###convert to Lat- Long using tidygeocode : Reference https://www.youtube.com/watch?v=7nFZ5BwkAXc\n",
    "### Load libraries needed for geocode\n",
    "if (!require(tidyverse)) install.packages(\"tidyverse\")\n",
    "library(tidyverse)  \n",
    "if (!require(tidygeocoder)) install.packages(\"tidygeocoder\")\n",
    "library(tidygeocoder)  \n",
    "if (!require(sf)) install.packages(\"sf\")\n",
    "library(sf) \n",
    "if (!require(mapview)) install.packages(\"mapview\")\n",
    "library(mapview) \n",
    "\n",
    "### Prepare Data to be converted\n",
    "biz_data$Address <- paste(biz_data$StreetAddress,biz_data$'Licence Address Line 2',biz_data$'Licence Address Line 3', sep = \",\")\n",
    "biz_geo_loc_a = biz_data %>%\n",
    "  select(Category,`Operating Name`,city = 'Licence Address Line 2',Zip = 'Licence Address Line 3',Street, Address)\n",
    "\n",
    "### Convert address to lat - long\n",
    "biz_geo_loc = biz_geo_loc_a %>% filter(str_detect(Zip, \"M4\"))%>%\n",
    "  tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "biz_geo_loc1 = biz_geo_loc[-which(is.na(biz_geo_loc$lat)),]\n",
    "biz_geo_loc2 = biz_geo_loc[which(is.na(biz_geo_loc$lat)),]\n",
    "\n",
    "biz_geo_loc = biz_geo_loc_a %>% filter(str_detect(Zip, \"M5\"))%>%\n",
    "  tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "biz_geo_loc1 = rbind(biz_geo_loc1,biz_geo_loc[-which(is.na(biz_geo_loc$lat)),])\n",
    "biz_geo_loc2 = rbind(biz_geo_loc2,biz_geo_loc[which(is.na(biz_geo_loc$lat)),])\n",
    "  \n",
    "biz_geo_loc = biz_geo_loc_a %>% filter(str_detect(Zip, \"M6\"))%>%\n",
    "  tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "biz_geo_loc1 = rbind(biz_geo_loc1,biz_geo_loc[-which(is.na(biz_geo_loc$lat)),])\n",
    "biz_geo_loc2 = rbind(biz_geo_loc2,biz_geo_loc[which(is.na(biz_geo_loc$lat)),])\n",
    "\n",
    "biz_geo_loc = biz_geo_loc_a %>% filter(str_detect(Zip, \"M3\"))%>%\n",
    "  tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "biz_geo_loc1 = rbind(biz_geo_loc1,biz_geo_loc[-which(is.na(biz_geo_loc$lat)),])\n",
    "biz_geo_loc2 = rbind(biz_geo_loc2,biz_geo_loc[which(is.na(biz_geo_loc$lat)),])\n",
    "\n",
    "biz_geo_loc = biz_geo_loc_a %>% filter(str_detect(Zip, \"M7\"))%>%\n",
    "  tidygeocoder:: geocode(address = Address, method = \"osm\")\n",
    "biz_geo_loc1 = rbind(biz_geo_loc1,biz_geo_loc[-which(is.na(biz_geo_loc$lat)),])\n",
    "biz_geo_loc2 = rbind(biz_geo_loc2,biz_geo_loc[which(is.na(biz_geo_loc$lat)),])\n",
    "\n",
    "###check if any na\n",
    "sapply(biz_geo_loc1, function(x) sum(is.na(x)))\n",
    "\n",
    "write.csv(biz_geo_loc1, \"~/biz_geo_loc1.csv\")\n",
    "\n",
    "###display on map\n",
    "biz_geo_loc_sf = biz_geo_loc1 %>%\n",
    "  st_as_sf(\n",
    "    coords = c(\"long\",\"lat\"),\n",
    "    crs = 4326\n",
    "  )\n",
    "\n",
    "biz_geo_loc_sf %>% mapview()\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "####section d) adding simulated number of customer (qCustomer) and time spent (tCustomer) during busy hours\n",
    "\n",
    "biz_cat1 = data.frame(cbind(\n",
    "  c(\"RETAIL STORE (FOOD)\",\"HOLISTIC CENTRE\",\"DRIVING SCHOOL OPERATOR (B)\",\t\n",
    "    \"DRIVE-SELF RENTAL OWNER\",\"PLACE OF AMUSEMENT\",\t\"PRIVATE PARKING ENFORCEMENT AGENCY\",\t\n",
    "    \"SMOKE SHOP\",\t\"BILLIARD HALL\",\"BODY RUB PARLOUR\",\t\"TAXICAB BROKER\",\t\"BOWLING HOUSE\",\t\n",
    "    \"ADULT ENTERTAINMENT CLUB\",\t\"LIMOUSINE SERVICE COMPANY\",\t\n",
    "    \"PRIVATE TRANSPORTATION COMPANY\",\t\"CARNIVAL\",\t\"TEMPORARY SIGN PROVIDER\",\n",
    "    \"TAXICAB OPERATOR\",\t\"SHORT TERM RENTAL COMPANY\",\"CIRCUS\"), \n",
    "  c(30,5,5,10,30,5,10,20,10,10,20,5,10,10,3,3,10,3,100)) , \n",
    "  c(1,1.5,1,0.33,1,0.33,0.5,1,1,0.33,1,1,0.33,0.33,0.33,0.33,0.33,0.33,2) ,\n",
    "  c(0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5)\n",
    "  )\n",
    "colnames(biz_cat1) = c(\"Category\",\"lamda\",\"mu\",\"sigma\")\n",
    "biz_cat1$lamda = as.integer(biz_cat1$lamda)\n",
    "biz_cat1$mu = as.numeric(biz_cat1$mu)\n",
    "biz_cat1$sigma = as.numeric(biz_cat1$sigma)\n",
    "\n",
    "biz_customer = as.data.frame(biz_cat1)\n",
    "\n",
    "biz_geo_loc1 = left_join(biz_geo_loc1,biz_customer, by = \"Category\")\n",
    "\n",
    "# for reproducibility but mask it when want to do simulation\n",
    "set.seed(138)\n",
    "k = nrow(biz_geo_loc1)\n",
    "biz_geo_loc1 = data.frame(Category = biz_geo_loc1$Category, Operating.Name = biz_geo_loc1$'Operating.Name',\n",
    "                          city = biz_geo_loc1$city, Zip = biz_geo_loc1$Zip,  Street =biz_geo_loc1$Street,\n",
    "                          Address = biz_geo_loc1$Address, lat = biz_geo_loc1$lat,long = biz_geo_loc1$long,\n",
    "                          lamda =biz_geo_loc1$lamda,  mu = biz_geo_loc1$mu, sigma = biz_geo_loc1$sigma,\n",
    "                          qCustomer = rpois(k,biz_geo_loc1$lamda),\n",
    "                          tCustomer = rexp(k,biz_geo_loc1$mu)) \n",
    "#review qCustomer * tCustomer summary\n",
    "qCustomer_input_summary = biz_geo_loc1 %>%                            \n",
    "  group_by(Category = biz_geo_loc1$Category, lamda = biz_geo_loc1$lamda ) %>%\n",
    "  summarize(n = n(), min = min(qCustomer), q1 = quantile(qCustomer, 0.25), median = median(qCustomer), mean = mean(qCustomer), q3 = quantile(qCustomer, 0.75), max = max(qCustomer))\n",
    "#qCustomer_input_summary\n",
    "\n",
    "tCustomer_input_summary = biz_geo_loc1 %>%                            \n",
    "  group_by(Category = biz_geo_loc1$Category,mu = biz_geo_loc1$mu) %>%\n",
    "  summarize(n = n(), min = min(tCustomer), q1 = quantile(tCustomer, 0.25), median = median(tCustomer), mean = mean(tCustomer), q3 = quantile(tCustomer, 0.75), max = max(tCustomer))\n",
    "#tCustomer_input_summary\n",
    "\n",
    "##########################################################################\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Get data - GreenPParking\n",
    "# Output:\n",
    "# address : Address of the parking spot\n",
    "# lat : Latitude of parking spot\n",
    "# lng : Longitude of parking spot\n",
    "# half_hr : rate of parking/half hr\n",
    "# capacity : capacity of parking spot\n",
    "\n",
    "## Cleaning Green P Parking\n",
    "\n",
    "# Get Green P Parking package from Open Data-Toronto\n",
    "package <- show_package(\"b66466c3-69c8-4825-9c8b-04b270069193\")\n",
    "\n",
    "data=as.data.frame('Green P Parking')  # read the dataset Green P Parking in the package \n",
    "data<-show_package(package)\n",
    "\n",
    "resources<-list_package_resources(package)\n",
    "\n",
    "# Identify resources\n",
    "data_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"json\"))\n",
    "\n",
    "# Load Green P Parking data\n",
    "data <- filter(data_resources, row_number() == 1) %>% get_resource()\n",
    "\n",
    "# Extract required columns from main data\n",
    "data<- data.frame(address=data$carparks$address,\n",
    "                                     lat=data$carparks$lat,\n",
    "                                     lng=data$carparks$lng,\n",
    "                                      carpark_type=data$carparks$carpark_type_str,\n",
    "                                      rate_half_hr=data$carparks$rate_half_hour,\n",
    "                                      capacity=data$carparks$capacity,\n",
    "                                      rate=data$carparks$rate_half_hour\n",
    "                  )\n",
    "\n",
    "# Check class of each attribute\n",
    "sapply(data, class) \n",
    "\n",
    "# Convert char to numeric class\n",
    "data$lat<-as.numeric(data$lat)\n",
    "data$lng<-as.numeric(data$lng)\n",
    "data$rate_half_hr<-as.numeric(data$rate_half_hr)\n",
    "data$capacity<-as.numeric(data$capacity)\n",
    "\n",
    "sapply(data, class) \n",
    "\n",
    "# Check for missing values\n",
    "any(is.na(data))\n",
    "\n",
    "# Extract street name from address\n",
    "data <- data %>%\n",
    "  mutate(extracted_address = str_replace_all(data$address, \"\\\\(.*?\\\\)\",\"\"))\n",
    "\n",
    "data$extracted_address<-str_replace_all(data$extracted_address, \"-.*\", \"\")\n",
    "data$extracted_address<-str_replace_all(data$extracted_address, \",.*\", \"\")\n",
    "\n",
    "# Extract data with carpark_type as 'Surface'\n",
    "data <- data %>%\n",
    "  filter(carpark_type == \"Surface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine Parking Data and Clean Traffic Data to prepare input data for Time Series Model to predict traffic / EV charging demand\n",
    "\n",
    "# loop through low to high year number\n",
    "# filter each year, to list of unique intersections with traffic volume\n",
    "# run knn algo against parking lot, find k nearst intersection\n",
    "# use knn nn.index to find the k intersection vol, get average, creating a vector\n",
    "# add vector to parking data as new column with year and volume\n",
    "# next loop for the next year\n",
    "\n",
    "#Output TS_Input\n",
    "\n",
    "K <- 8 # Parameter used in knn calculation. \n",
    "All_park <- data %>%\n",
    "    select(one_of(c(\"lat\",\"lng\"))) # location coordinates of all surface car parks. \n",
    "\n",
    "TS_Input <- data # TS_Input is the input data for the time series of traffic volume forecast. \n",
    "\n",
    "for (i in traffic_years) {\n",
    "    # print(paste(\"This is year\" ,i))\n",
    "    year_traffic<- filter(CleanTraffic, year == i) # get the traffic volume, intersection for each year.\n",
    "    All_int <-select(year_traffic,one_of(c(\"lat\",\"lng\"))) # extract just the coordinates for K nearest neighter calculation\n",
    "    knn_dist <- get.knnx(All_int, All_park, k=K, algorithm=\"kd_tree\") # get the K nearest intersection to the parking lot and their index list\n",
    "    \n",
    "    get.mean <- function(x) { # custom function defined to calculate the average of the K nearest intersection volume\n",
    "    mean(slice(year_traffic, c(x))$AvgTotal)\n",
    "    }\n",
    "\n",
    "    TS_Input[paste0(\"NearbyTraffic_\",i)]  <- apply(knn_dist$nn.index,1,get.mean) # calculate the avaerage per row of indices\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1 - Time Series Forecast\n",
    "\n",
    "# forecast traffic for 2024 given the TS_Input\n",
    "# apply % of EV vehicle multiplier for 2022 and predicted year 2024 to get amount of estimated EV traffic.\n",
    "# data frame that has the original location, EV traffic for 2022, and predicted EV traffic for 2024\n",
    "\n",
    "\n",
    "library(forecast)\n",
    "library(purrr)\n",
    "\n",
    "# Time series model and Forecast for 2024\n",
    "arima_models <- apply(TS_Input[, -c(1,2,3,4,5,6,7,8)], 1, auto.arima)\n",
    "model_forecasts_2024 <- lapply(arima_models, function(x) forecast(x, h = 1))\n",
    "\n",
    "TS_Output_2024 <- map_dbl(model_forecasts_2024, \"mean\")\n",
    "TS_Output_2024 <- round(TS_Output_2024)\n",
    "\n",
    "\n",
    "# Format output for 2024\n",
    "# Data frame that contains the original location, lat, and lng columns,\n",
    "# % of EV traffic for 2022 and % of EV traffic for predicted 2024\n",
    "\n",
    "# % of EV vehicle multiplier for 2022\n",
    "mulitplier_2022 = .03\n",
    "\n",
    "# % of EV Vehicle multiplier for predicted year \n",
    "multiplier_predicted = .0533\n",
    "\n",
    "TS_Output_df = data.frame(TS_Input$address,TS_Input$lat,TS_Input$lng, TS_Input$NearbyTraffic_2022,TS_Output_2024)\n",
    "#head(TS_Output_df)\n",
    "\n",
    "# Apply % of EV Vehicle multiplier to 2022 and predicted year 2024, present a new columns to Df\n",
    "traffic_2022 <- data.frame(TS_Output_df$TS_Input.NearbyTraffic_2022)\n",
    "traffic_2024 <-data.frame(TS_Output_df$TS_Output_2024)\n",
    "\n",
    "TS_Output_df$EV_nearbyTraffic_2022 <- apply(traffic_2022, 1, function(x) round(x * mulitplier_2022))\n",
    "TS_Output_df$EV_nearbyTraffic_2024 <- apply(traffic_2024, 1, function(x) round(x * multiplier_predicted))\n",
    "\n",
    "\n",
    "# Final Output\n",
    "head(TS_Output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Steps:\n",
    "# Add convert column to GreenPParking dataset.\n",
    "# Calculate distance between each parking spot and business.\n",
    "# Calculate number of nearest businesses.\n",
    "# Add EV traffic volume data for year 2022.\n",
    "# Make SVM model with 'convert' as dependent variable and 'distance', 'n_business' and 'traffic_volume' as independent variable.\n",
    "# Use coefficients from SVM model to calculate weighted score.\n",
    "# OUTPUT: Top 12 parking locations to convert to EV Charging stations.\n",
    "\n",
    "\n",
    "# Add convert column to GreenPParking dataset\n",
    "library(sf)\n",
    "\n",
    "# Extracting address, latitude, and longitude\n",
    "data <- data[, c(\"address\", \"lat\", \"lng\")]\n",
    "\n",
    "# Adding the new rows\n",
    "new_rows <- data.frame(\n",
    "  address = c(\n",
    "    \"365 Lippincott Street\",\n",
    "    \"35 Erindale Avenue\",\n",
    "    \"14 Arundel Avenue\",\n",
    "    \"265 Armadale Avenue\",\n",
    "    \"1612 Danforth Avenue\",\n",
    "    \"117 Hammersmith Avenue\",\n",
    "    \"166 Woodbine Ave\",\n",
    "    \"19 Spadina Road\",\n",
    "    \"2300 Lake shore Boulevard West\",\n",
    "    \"35 Erindale Avenue\",\n",
    "    \"265 Armadale Avenue\",\n",
    "    \"2300 Lake shore Boulevard West\"\n",
    "  ),\n",
    "  lat = c(\n",
    "    43.665054,\n",
    "    43.688543,\n",
    "    43.695882,\n",
    "    43.721568,\n",
    "    43.684903,\n",
    "    43.693819,\n",
    "    43.674124,\n",
    "    43.677754,\n",
    "    43.623545,\n",
    "    43.688543,\n",
    "    43.721568,\n",
    "    43.623545\n",
    "  ),\n",
    "  lng = c(\n",
    "    -79.409662,\n",
    "    -79.411305,\n",
    "    -79.42134,\n",
    "    -79.427191,\n",
    "    -79.325679,\n",
    "    -79.428246,\n",
    "    -79.319325,\n",
    "    -79.403948,\n",
    "    -79.479056,\n",
    "    -79.411305,\n",
    "    -79.427191,\n",
    "    -79.479056\n",
    "  )\n",
    ")\n",
    "\n",
    "# Adding the new rows to the extracted GreenPParking dataset\n",
    "# data <- rbind(data, new_rows)\n",
    "\n",
    "# Creating the 'Convert' column\n",
    "data$Convert <- ifelse(data$address %in% new_rows$address, 1, 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "############################################## METHOD 1 - SVM (Without KNN) ##################################################\n",
    "\n",
    "# Read data\n",
    "parking<-data\n",
    "business<-biz_geo_loc1\n",
    "\n",
    "parking_sf <- st_as_sf(parking, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Convert the business dataset to a spatial object\n",
    "business_sf <- st_as_sf(business, coords = c(\"long\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Convert the parking dataset to a spatial object\n",
    "parking_sf <- st_as_sf(parking, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Perform a spatial join to find the nearest business for each parking space\n",
    "nearest_business <- st_nearest_feature(parking_sf, business_sf)\n",
    "nearest_points <-st_nearest_points(parking_sf,business_sf)\n",
    "\n",
    "# Add the nearest business information to the parking dataset\n",
    "parking_data_with_nearest_business <- cbind(parking, nearest_business)\n",
    "\n",
    "# Function to calculate angular distance between two points on Earth\n",
    "haversine_distance <- function(lon1, lat1, lon2, lat2) {\n",
    "  R <- 6371 # Earth radius in km\n",
    "  dlat <- (lat2 - lat1) * pi / 180\n",
    "  dlon <- (lon2 - lon1) * pi / 180\n",
    "  a <- sin(dlat/2)^2 + cos(lat1 * pi / 180) * cos(lat2 * pi / 180) * sin(dlon/2)^2\n",
    "  c <- 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "  distance <- R * c\n",
    "  return(distance) # Distance in km\n",
    "}\n",
    "parking_data_with_nearest_business$traffic_volume=TS_Output_df$EV_nearbyTraffic_2022\t\n",
    "\n",
    "\n",
    "# # Convert Lat/Lng to address\n",
    "# geo_rev_data<-data %>%\n",
    "#   tidygeocoder::reverse_geocode(\n",
    "#     lat=lat,\n",
    "#     long=lng,\n",
    "#     method=\"osm\")\n",
    "\n",
    "\n",
    "## Calculate distance between each parking spot and each business\n",
    "\n",
    "# Create an empty list to store the results\n",
    "result_list <- list()\n",
    "\n",
    "for (i in 1:nrow(parking_data_with_nearest_business)){\n",
    "  \n",
    "  # Create a temporary data frame to store the results for this parking spot\n",
    "  temp_df <- data.frame(\n",
    "    address = character(),\n",
    "    lat = double(),\n",
    "    lng = double(),\n",
    "    Convert = integer(),\n",
    "    distance = double(),\n",
    "    #capacity = integer(),\n",
    "    traffic_volume = double(),\n",
    "    #rate_half_hr= double(),\n",
    "    n_business = double(),\n",
    "    n_customers =double(),\n",
    "    time_spent = double(),\n",
    "    category = character(),\n",
    "    Operating.name = character(),\n",
    "    interaction_term = double()\n",
    ")\n",
    "  \n",
    "  for( j in 1:nrow(business)){\n",
    "    lon1 <- parking_data_with_nearest_business[i,\"lng\"]\n",
    "    lat1 <- parking_data_with_nearest_business[i,\"lat\"]\n",
    "    lon2 <- business[j, \"long\"]\n",
    "    lat2 <- business[j, \"lat\"]\n",
    "\n",
    "    # # Calculate distance\n",
    "    distance <- haversine_distance(lon1,lat1, lon2, lat2)\n",
    "    \n",
    "    # Store the results in the temporary data frame\n",
    "    temp_df[nrow(temp_df) + 1, ] <- list(\n",
    "      address = parking_data_with_nearest_business[i,\"address\"],\n",
    "      lat = parking_data_with_nearest_business[i,\"lat\"],\n",
    "      lng = parking_data_with_nearest_business[i,\"lng\"],\n",
    "      Convert = parking_data_with_nearest_business[i,\"Convert\"],\n",
    "      distance = distance,\n",
    "      #capacity = parking_data_with_nearest_business[i,\"capacity\"],\n",
    "      traffic_volume = parking_data_with_nearest_business[i,\"traffic_volume\"],\n",
    "      n_business = parking_data_with_nearest_business[i,\"nearest_business\"],\n",
    "      #rate_half_hr = parking_data_with_nearest_business[i,\"rate_half_hr\"],\n",
    "      n_customers = business[j,\"qCustomer\"],\n",
    "      time_spent = business[j,\"tCustomer\"],\n",
    "      category = business[j,\"Category\"],\n",
    "      Operating.name = business[j,\"Operating.Name\"],\n",
    "      interaction_term = business[j,\"qCustomer\"] * business[j,\"tCustomer\"]\n",
    "    )\n",
    "  }\n",
    "  \n",
    "  # Append the temporary data frame to the result list\n",
    "  result_list[[i]] <- temp_df\n",
    "}\n",
    "\n",
    "# Combine all the results into a single data frame\n",
    "result_df <- do.call(rbind, result_list)\n",
    "\n",
    "library(dplyr)\n",
    "filtered_result_df2 <- result_df %>%\n",
    "  group_by(Operating.name) %>% \n",
    "  slice(which.min(distance))\n",
    "\n",
    "summarized_result_df <- filtered_result_df2 %>%\n",
    "  group_by(address) %>%\n",
    "  summarize(\n",
    "    mean_lat = mean(lat),\n",
    "    mean_lng = mean(lng),\n",
    "    mean_distance = mean(distance),\n",
    "    mean_traffic_volume = mean(traffic_volume),\n",
    "    mean_n_business = mean(n_business),\n",
    "    mean_n_customers = mean(n_customers),\n",
    "    mean_time_spent = mean(time_spent),\n",
    "    mean_interaction_term = mean(interaction_term),\n",
    "    convert=mean(Convert)\n",
    "  )\n",
    "\n",
    "# train_indices <- sample(1:nrow(parking_data]), 0.7 * nrow(parking_data))  # 70% for training\n",
    "# train_data <- parking_data[train_indices, ]\n",
    "# test_data <- parking_data[-train_indices, ]\n",
    "\n",
    "# Create a formula including predictor columns\n",
    "formula <- as.formula(\"convert ~ mean_distance + mean_traffic_volume + mean_n_business\")\n",
    "\n",
    "# Create the SVM model with the formula\n",
    "svm_model <- svm(formula, data = summarized_result_df, kernel = \"linear\")\n",
    "\n",
    "# Coefficients from the SVM model\n",
    "coefficients <- coef(svm_model)[-1]  # Exclude the intercept\n",
    "\n",
    "# Select the columns for which to calculate the score\n",
    "cols <- c(\"mean_distance\", \"mean_n_business\", \"mean_traffic_volume\")\n",
    "\n",
    "# Calculate the score for each row\n",
    "summarized_result_df$score <- rowSums(summarized_result_df[cols] * coefficients)\n",
    "# Sort the rows in descending order according to the score\n",
    "summarized_result_df <- summarized_result_df %>%\n",
    "  arrange(desc(score))\n",
    "\n",
    "# View the sorted result (Top 12 Parking Locations)\n",
    "head(summarized_result_df,12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "############################################## METHOD 2 - SVM (With KNN) ##################################################\n",
    "\n",
    "## Steps: \n",
    "# Use KNN to find nearest distance, average number of customers and average time spent at business location.\n",
    "# Add EV traffic volume data for year 2022.\n",
    "# Make SVM model with 'convert' as dependent variable and 'distance' and 'traffic_volume' as inependent variables.\n",
    "# Use coefficients from SVM model to calculate weighted score.\n",
    "# OUTPUT: Top 12 parking locations to convert to EV Charging stations.\n",
    "\n",
    "# Pre-processing\n",
    "\n",
    "# Read data\n",
    "parking_data <- data\n",
    "business_data <- biz_geo_loc1\n",
    "\n",
    "K <- 8  # Number of nearest businesses to consider\n",
    "\n",
    "for (i in 1:nrow(parking_data)) {\n",
    "    parking_spot <- parking_data[i, c(\"lat\", \"lng\")]  # Coordinates of the parking spot\n",
    "    nearest_biz_indices <- get.knnx(business_data[, c(\"lat\", \"long\")], parking_spot, k = K, algorithm = \"kd_tree\")$nn.index\n",
    "    nearest_biz_distances <- get.knnx(business_data[, c(\"lat\", \"long\")], parking_spot, k = K, algorithm = \"kd_tree\")$nn.dist\n",
    "    \n",
    "    # Calculate the number of nearest businesses and their distances\n",
    "    num_nearest_biz <- length(nearest_biz_indices)\n",
    "    avg_distance <- mean(nearest_biz_distances)\n",
    "    \n",
    "    nearest_biz_customers <- sapply(nearest_biz_indices, function(idx) {\n",
    "  mean(business_data[idx, \"qCustomer\"])\n",
    "})\n",
    "    nearest_biz_time_spent <- sapply(nearest_biz_indices, function(idx) {\n",
    "  mean(business_data[idx, \"tCustomer\"])\n",
    "})\n",
    "\n",
    "    overall_mean_customers <- mean(nearest_biz_customers)\n",
    "    overall_mean_time_spent <- mean(nearest_biz_time_spent)\n",
    "\n",
    "\n",
    "    # Add the results to the parking_data dataframe\n",
    "    parking_data[i, paste0(\"nearest_biz_count_\", K)] <- num_nearest_biz\n",
    "    parking_data[i, paste0(\"avg_distance_to_biz_\", K)] <- avg_distance\n",
    "    parking_data[i, paste0(\"avg_customers_nearby_\", K)] <- mean(overall_mean_customers)\n",
    "    parking_data[i, paste0(\"avg_time_spent_nearby_\", K)] <- mean(overall_mean_time_spent)\n",
    "}\n",
    "\n",
    "\n",
    "# Add EV Traffic data\n",
    "parking_data$traffic_volume=TS_Output_df$EV_nearbyTraffic_2022\t\n",
    "\n",
    "# Group by address\n",
    "parking_data <- parking_data %>%\n",
    "  group_by(address) %>%\n",
    "  summarise(\n",
    "    distance = mean(avg_distance_to_biz_8),\n",
    "    n_business = mean(nearest_biz_count_8),\n",
    "    time_spent =mean(avg_time_spent_nearby_8),\n",
    "    n_customers=mean(avg_customers_nearby_8),\n",
    "    traffic_volume = mean(traffic_volume),\n",
    "    convert = mean(Convert)\n",
    "  )\n",
    "  \n",
    "# Normalize predictors\n",
    "parking_data$distance <- scale(parking_data$distance)\n",
    "parking_data$traffic_volume <- scale(parking_data$traffic_volume)\n",
    "parking_data$time_spent<- scale(parking_data$time_spent)\n",
    "parking_data$n_customers<- scale(parking_data$n_customers)\n",
    "\n",
    "set.seed(123)  # for reproducibility\n",
    "\n",
    "# train_indices <- sample(1:nrow(parking_data]), 0.7 * nrow(parking_data))  # 70% for training\n",
    "# train_data <- parking_data[train_indices, ]\n",
    "# test_data <- parking_data[-train_indices, ]\n",
    "\n",
    "\n",
    "# # Create a formula including predictor columns\n",
    "formula <- as.formula(\"convert ~ distance + traffic_volume \")\n",
    "\n",
    "# Create the SVM model with the formula\n",
    "svm_model <- svm(formula, data = parking_data, kernel = \"linear\")\n",
    "\n",
    "# Get the coefficients (weights) of the model\n",
    "weights <- coef(svm_model)\n",
    "\n",
    "# Coefficients from the SVM model\n",
    "coefficients <- coef(svm_model)[-1]  # Exclude the intercept\n",
    "\n",
    "# Select the columns for which to calculate the score\n",
    "cols <- c(\"distance\",  \"traffic_volume\")\n",
    "\n",
    "# Calculate the score for each row\n",
    "parking_data$score <- rowSums(parking_data[cols] * coefficients)\n",
    "\n",
    "\n",
    "# Sort the rows in descending order according to the score\n",
    "sorted_result <- parking_data %>%\n",
    "  arrange(desc(score))\n",
    "\n",
    "# View the sorted result (Top 12 parking locations)\n",
    "head(sorted_result,12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Intersection\n",
    "# output Data Description:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define Region of Interest - Boundary\n",
    "## coordinates manually looked up from location dataset\n",
    "# 1406\t5370\tDUPONT ST AT OSSINGTON AVE (PX 842)\t-79.429019\t43.670031996501194\n",
    "# 251\t4180\tDUPONT ST AT SPADINA RD (PX 840)\t-79.407122\t43.67485699954096\n",
    "# 1885\t5864\tCOLLEGE ST AT OSSINGTON AVE (PX 829)\t-79.422705\t43.65439999619167\n",
    "# 241\t4170\tCOLLEGE ST AT SPADINA AVE (PX 279)\t-79.400048\t43.65794800150128\n",
    "\n",
    "# Input\n",
    "# Output\n",
    "\n",
    "boundary <- location %>%\n",
    "  select(location_id, location, lng, lat) %>%\n",
    "  filter(location_id %in% list(5370, 4180, 5864, 4170)) # boundary intersection ID\n",
    "\n",
    "lng_min <- min(boundary$lng) # west most value since it's negative\n",
    "lng_max <- max(boundary$lng) # east most value\n",
    "lat_min <- min(boundary$lat) # south most value\n",
    "lat_max <- max(boundary$lat) # north most value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Result and Discussion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
