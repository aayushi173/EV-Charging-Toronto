{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: opendatatoronto\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: tidyjson\n",
      "\n",
      "\n",
      "Attaching package: 'tidyjson'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "Loading required package: tidygeocoder\n",
      "\n",
      "Loading required package: sf\n",
      "\n",
      "Linking to GEOS 3.11.2, GDAL 3.8.2, PROJ 9.3.1; sf_use_s2() is TRUE\n",
      "\n",
      "Loading required package: ggspatial\n",
      "\n",
      "Loading required package: stringr\n",
      "\n",
      "Loading required package: dplyr\n",
      "\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n",
      "Loading required package: tidyverse\n",
      "\n",
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.2     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.0\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mtidyjson\u001b[39m::filter(), \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "Loading required package: FNN\n",
      "\n",
      "Loading required package: mapview\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load all required libraries for the notebook, including data package\n",
    "if(!require(\"opendatatoronto\")) {\n",
    "    install.packages(\"opendatatoronto\")\n",
    "    library(opendatatoronto) # data source\n",
    "}\n",
    "if(!require(\"tidyjson\")) {\n",
    "    install.packages(\"tidyjson\")\n",
    "    library(tidyjson)\n",
    "}\n",
    "if(!require(\"tidygeocoder\")) {\n",
    "    install.packages(\"tidygeocoder\")\n",
    "    library(tidygeocoder)\n",
    "}\n",
    "if(!require(\"sf\")) {\n",
    "    install.packages(\"sf\")\n",
    "    library(sf)\n",
    "}\n",
    "\n",
    "if(!require(\"ggspatial\")) {\n",
    "    install.packages(\"ggspatial\")\n",
    "    library(ggspatial)\n",
    "}\n",
    "if(!require(\"stringr\")) {\n",
    "    install.packages(\"stringr\")\n",
    "    library(stringr)\n",
    "}\n",
    "if(!require(\"dplyr\")) {\n",
    "    install.packages(\"dplyr\")\n",
    "    library(dplyr)\n",
    "}\n",
    "if(!require(\"ggplot2\")) {\n",
    "    install.packages(\"ggplot2\")\n",
    "    library(ggplot2)\n",
    "}\n",
    "if(!require(\"tidyverse\")) {\n",
    "    install.packages(\"tidyverse\")\n",
    "    library(tidyverse)\n",
    "}\n",
    "if(!require(\"FNN\")) {\n",
    "    install.packages(\"FNN\")\n",
    "    library(FNN)\n",
    "}\n",
    "\n",
    "if(!require(\"mapview\")) {\n",
    "    install.packages(\"mapview\")\n",
    "    library(mapview)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Traffic\n",
    "# output Data Description:\n",
    "# Dataframe with all intersection and daily count ( peak 4 hours), including lng / lat\n",
    "\n",
    "# # ? and todo:\n",
    "# # is separate street name needed\n",
    "# # direction of the street to be determined. How?\n",
    "\n",
    "\n",
    "# # package_traffic <- show_package(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# # get all resources for this package\n",
    "# resources <- list_package_resources(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# # identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "# datastore_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"geojson\"))\n",
    "\n",
    "# # load data # The method of loading data directly using turns out to be insufficient as the get_resource() only returns first 32000 rows of record. \n",
    "# location <- filter(datastore_resources, row_number() == 1) %>% get_resource()\n",
    "# traffic1 <- filter(datastore_resources, row_number() == 3) %>% get_resource()\n",
    "# traffic2 <- filter(datastore_resources, row_number() == 4) %>% get_resource()\n",
    "# traffic3 <- filter(datastore_resources, row_number() == 5) %>% get_resource()\n",
    "# traffic4 <- filter(datastore_resources, row_number() == 6) %>% get_resource()\n",
    "# traffic5 <- filter(datastore_resources, row_number() == 7) %>% get_resource()\n",
    "\n",
    "# To Run the code download the raw files from \n",
    "# https://open.toronto.ca/dataset/traffic-volumes-at-intersections-for-all-modes/ \n",
    "# and save the files in .csv format to the path: ../Data/Toronto/Traffic, 7 Files below. \n",
    "# count_metadata.csv\n",
    "# locations.csv\n",
    "# raw-data-1980-1989.csv\n",
    "# raw-data-1990-1999.csv\n",
    "# raw-data-2000-2009.csv\n",
    "# raw-data-2010-2019.csv\n",
    "# raw-data-2020-2029.csv\n",
    "location <- read.csv(\"../Data/Toronto/Traffic/locations.csv\") # ensure these path are correct if you have to download the files manually. \n",
    "traffic1 <- read.csv(\"../Data/Toronto/Traffic/raw-data-1980-1989.csv\")\n",
    "traffic2 <- read.csv(\"../Data/Toronto/Traffic/raw-data-1990-1999.csv\")\n",
    "traffic3 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2000-2009.csv\")\n",
    "traffic4 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2010-2019.csv\")\n",
    "traffic5 <- read.csv(\"../Data/Toronto/Traffic/raw-data-2020-2029.csv\")\n",
    "all_traffic = bind_rows(traffic1,traffic2,traffic3,traffic4,traffic5) # combine all raw data into one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# clean and transform load - Traffic Data\n",
    "# Output data for modelling CleanTraffic\n",
    "# define parameters for cleaning\n",
    "peakhours <- 4 # number of peak hours of data per day. value should be between 1 and 10\n",
    "\n",
    "# get full intersection volume for each intersection based on peak hours of each day. \n",
    "# get average vol per intersection per year. \n",
    "# get number of years list, sort from low to high\n",
    "\n",
    "# \n",
    "\n",
    "CleanTraffic <- all_traffic %>%\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise_at(\"total_int_traffic\",sum) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise_at(\"total_int_traffic\", sum)%>% # aggregate daily peak hour volume\n",
    "  mutate(count_date= as.Date(count_date, format(\"%Y-%m-%d\"))) %>% \n",
    "  mutate(year = as.numeric(format(count_date,'%Y'))) %>% #add year\n",
    "  group_by(across(all_of(c(\"year\", \"location_id\", \"location\", \"lat\",\"lng\")))) %>% # group by year to get the average per intersection per year\n",
    "  summarise(AvgTotal = mean(total_int_traffic), .groups = \"drop\")  # average traffic volume for that year and location\n",
    "traffic_years <- unique(CleanTraffic$year) # get number of years list, sort from low to high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>address</dt><dd>'character'</dd><dt>lat</dt><dd>'character'</dd><dt>lng</dt><dd>'character'</dd><dt>carpark_type</dt><dd>'character'</dd><dt>rate_half_hr</dt><dd>'character'</dd><dt>capacity</dt><dd>'character'</dd><dt>rate</dt><dd>'character'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[address] 'character'\n",
       "\\item[lat] 'character'\n",
       "\\item[lng] 'character'\n",
       "\\item[carpark\\textbackslash{}\\_type] 'character'\n",
       "\\item[rate\\textbackslash{}\\_half\\textbackslash{}\\_hr] 'character'\n",
       "\\item[capacity] 'character'\n",
       "\\item[rate] 'character'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "address\n",
       ":   'character'lat\n",
       ":   'character'lng\n",
       ":   'character'carpark_type\n",
       ":   'character'rate_half_hr\n",
       ":   'character'capacity\n",
       ":   'character'rate\n",
       ":   'character'\n",
       "\n"
      ],
      "text/plain": [
       "     address          lat          lng carpark_type rate_half_hr     capacity \n",
       " \"character\"  \"character\"  \"character\"  \"character\"  \"character\"  \"character\" \n",
       "        rate \n",
       " \"character\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>address</dt><dd>'character'</dd><dt>lat</dt><dd>'numeric'</dd><dt>lng</dt><dd>'numeric'</dd><dt>carpark_type</dt><dd>'character'</dd><dt>rate_half_hr</dt><dd>'numeric'</dd><dt>capacity</dt><dd>'numeric'</dd><dt>rate</dt><dd>'character'</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[address] 'character'\n",
       "\\item[lat] 'numeric'\n",
       "\\item[lng] 'numeric'\n",
       "\\item[carpark\\textbackslash{}\\_type] 'character'\n",
       "\\item[rate\\textbackslash{}\\_half\\textbackslash{}\\_hr] 'numeric'\n",
       "\\item[capacity] 'numeric'\n",
       "\\item[rate] 'character'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "address\n",
       ":   'character'lat\n",
       ":   'numeric'lng\n",
       ":   'numeric'carpark_type\n",
       ":   'character'rate_half_hr\n",
       ":   'numeric'capacity\n",
       ":   'numeric'rate\n",
       ":   'character'\n",
       "\n"
      ],
      "text/plain": [
       "     address          lat          lng carpark_type rate_half_hr     capacity \n",
       " \"character\"    \"numeric\"    \"numeric\"  \"character\"    \"numeric\"    \"numeric\" \n",
       "        rate \n",
       " \"character\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "FALSE"
      ],
      "text/latex": [
       "FALSE"
      ],
      "text/markdown": [
       "FALSE"
      ],
      "text/plain": [
       "[1] FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get Green P Parking package from Open Data-Toronto\n",
    "package <- show_package(\"b66466c3-69c8-4825-9c8b-04b270069193\")\n",
    "\n",
    "data=as.data.frame('Green P Parking')  # read the dataset Green P Parking in the package \n",
    "data<-show_package(package)\n",
    "\n",
    "resources<-list_package_resources(package)\n",
    "\n",
    "# Identify resources\n",
    "data_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"json\"))\n",
    "\n",
    "# Load Green P Parking 2019 data\n",
    "data <- filter(data_resources, row_number() == 1) %>% get_resource()\n",
    "\n",
    "# Extract required columns from main data\n",
    "data<- data.frame(address=data$carparks$address,\n",
    "                                     lat=data$carparks$lat,\n",
    "                                     lng=data$carparks$lng,\n",
    "                                      carpark_type=data$carparks$carpark_type_str,\n",
    "                                      rate_half_hr=data$carparks$rate_half_hour,\n",
    "                                      capacity=data$carparks$capacity,\n",
    "                                      rate=data$carparks$rate_half_hour\n",
    "                  )\n",
    "\n",
    "# Check class of each attribute\n",
    "sapply(data, class) \n",
    "\n",
    "# Convert char to numeric class\n",
    "data$lat<-as.numeric(data$lat)\n",
    "data$lng<-as.numeric(data$lng)\n",
    "data$rate_half_hr<-as.numeric(data$rate_half_hr)\n",
    "data$capacity<-as.numeric(data$capacity)\n",
    "\n",
    "sapply(data, class) \n",
    "\n",
    "# Check for missing values\n",
    "any(is.na(data))\n",
    "\n",
    "# Extract street name from address\n",
    "data <- data %>%\n",
    "  mutate(extracted_address = str_replace_all(data$address, \"\\\\(.*?\\\\)\",\"\"))\n",
    "\n",
    "data$extracted_address<-str_replace_all(data$extracted_address, \"-.*\", \"\")\n",
    "data$extracted_address<-str_replace_all(data$extracted_address, \",.*\", \"\")\n",
    "\n",
    "# Extract data with carpark_type as 'Surface'\n",
    "data <- data %>%\n",
    "  filter(carpark_type == \"Surface\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing 220 coordinates to the Nominatim single coordinate geocoder\n",
      "\n",
      "Query completed in: 227 seconds\n",
      "\n",
      "\u001b[1m\u001b[22mNew names:\n",
      "\u001b[36m•\u001b[39m `address` -> `address...1`\n",
      "\u001b[36m•\u001b[39m `address` -> `address...9`\n"
     ]
    }
   ],
   "source": [
    "# Graphical View of Parking Data\n",
    "# Convert Lat/Lng to address\n",
    "geo_rev_data<-data %>%\n",
    "  tidygeocoder::reverse_geocode(\n",
    "    lat=lat,\n",
    "    long=lng,\n",
    "    method=\"osm\")\n",
    "\n",
    "# Plot map\n",
    "map<-data %>%\n",
    "  st_as_sf(\n",
    "    coords=c(\"lng\",\"lat\"),\n",
    "    crs=4326\n",
    "  )\n",
    "\n",
    "map %>% mapview()\n",
    "\n",
    "# Define the polygon coordinates\n",
    "polygon_coords <- matrix(c(\n",
    "  -79.4289964889767, 43.6700360241176, -79.4226792245877, 43.6543887000655, -79.4000484228339, 43.657948514946, -79.4070875693025, 43.6748646586934,-79.4289964889767, 43.6700360241176  # Repeat first point to close the polygon exactly\n",
    "), ncol = 2, byrow = TRUE)\n",
    "\n",
    "# Create a polygon geometry\n",
    "polygon <- st_polygon(list(polygon_coords))\n",
    "\n",
    "# Convert the polygon object to an 'sf' object with a specified CRS (Coordinate Reference System)\n",
    "polygon <- st_sfc(polygon, crs = 4326)\n",
    "\n",
    "# Convert the data frame 'data' to an 'sf' object, specifying the columns containing longitude and latitude as coordinates, and set the CRS\n",
    "data_sf <- st_as_sf(data, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Find the indices of the rows in 'data_sf' that fall within the polygon\n",
    "indices <- st_within(data_sf, polygon)\n",
    "\n",
    "# Convert the indices to a data frame\n",
    "indices_df<-data.frame(indices)\n",
    "\n",
    "selected_rows <- data_sf[match(indices_df$row.id, seq_len(nrow(data))), ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot selected rows on map\n",
    "map_df <- selected_rows %>%\n",
    "  st_as_sf() %>%\n",
    "  st_set_crs(4326) %>%\n",
    "  fortify()   # Convert the 'sf' object to a format suitable for use with 'ggplot2'\n",
    "\n",
    "# Display the spatial object using 'mapview'\n",
    "mapview(map_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(selected_rows, \"Parking.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Add lat, lng and remove geometry column\n",
    "selected_rows1<-selected_rows\n",
    "coords <- st_coordinates(selected_rows1$geometry)\n",
    "selected_rows1 <- cbind(selected_rows1, lng = coords[, \"X\"], lat = coords[, \"Y\"])\n",
    "parking_data <- st_drop_geometry(selected_rows1)\n",
    "write.csv(parking_data, \"Parking_data.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Intersection\n",
    "# output Data Description:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Business\n",
    "# output Data Description: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define Region of Interest - Boundary\n",
    "## coordinates manually looked up from location dataset\n",
    "# 1406\t5370\tDUPONT ST AT OSSINGTON AVE (PX 842)\t-79.429019\t43.670031996501194\n",
    "# 251\t4180\tDUPONT ST AT SPADINA RD (PX 840)\t-79.407122\t43.67485699954096\n",
    "# 1885\t5864\tCOLLEGE ST AT OSSINGTON AVE (PX 829)\t-79.422705\t43.65439999619167\n",
    "# 241\t4170\tCOLLEGE ST AT SPADINA AVE (PX 279)\t-79.400048\t43.65794800150128\n",
    "\n",
    "# Input\n",
    "# Output\n",
    "\n",
    "boundary <- location %>%\n",
    "  select(location_id, location, lng, lat) %>%\n",
    "  filter(location_id %in% list(5370, 4180, 5864, 4170)) # boundary intersection ID\n",
    "\n",
    "lng_min <- min(boundary$lng) # west most value since it's negative\n",
    "lng_max <- max(boundary$lng) # east most value\n",
    "lat_min <- min(boundary$lat) # south most value\n",
    "lat_max <- max(boundary$lat) # north most value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine Parking Data and Clean Traffic Data to prepare input data for Time Series Model to predict traffic / EV charging demand\n",
    "\n",
    "# loop through low to high year number\n",
    "# filter each year, to list of unique intersections with traffic volume\n",
    "# run knn algo against parking lot, find k nearst intersection\n",
    "# use knn nn.index to find the k intersection vol, get average, creating a vector\n",
    "# add vector to parking data as new column with year and volume\n",
    "# next loop for the next year\n",
    "\n",
    "#Output TS_Input\n",
    "\n",
    "K <- 5 # Parameter used in knn calculation. \n",
    "All_park <- data %>%\n",
    "    select(one_of(c(\"lat\",\"lng\"))) # location coordinates of all surface car parks. \n",
    "\n",
    "TS_Input <- data # TS_Input is the input data for the time series of traffic volume forecast. \n",
    "\n",
    "for (i in traffic_years) {\n",
    "    # print(paste(\"This is year\" ,i))\n",
    "    year_traffic<- filter(CleanTraffic, year == i) # get the traffic volume, intersection for each year.\n",
    "    All_int <-select(year_traffic,one_of(c(\"lat\",\"lng\"))) # extract just the coordinates for K nearest neighter calculation\n",
    "    knn_dist <- get.knnx(All_int, All_park, k=K, algorithm=\"kd_tree\") # get the K nearest intersection to the parking lot and their index list\n",
    "    \n",
    "    get.mean <- function(x) { # custom function defined to calculate the average of the K nearest intersection volume\n",
    "    mean(slice(year_traffic, c(x))$AvgTotal)\n",
    "    }\n",
    "\n",
    "    TS_Input[paste0(\"NearbyTraffic_\",i)]  <- apply(knn_dist$nn.index,1,get.mean) # calculate the avaerage per row of indices\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(TS_Input, \"TS_Input.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the data frame 'TS_Input' to an 'sf' object, specifying the columns containing longitude and latitude as coordinates, and set the CRS\n",
    "TS_Input_sf <- st_as_sf(TS_Input, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Find the indices of the rows in 'data_sf' that fall within the polygon\n",
    "t_indices <- st_within(TS_Input_sf, polygon)\n",
    "\n",
    "# Convert the indices to a data frame\n",
    "t_indices_df<-data.frame(t_indices)\n",
    "\n",
    "t_selected_rows <- TS_Input_sf[match(t_indices_df$row.id, seq_len(nrow(TS_Input))), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple feature collection with 8 features and 46 fields\n",
      "Geometry type: POINT\n",
      "Dimension:     XY\n",
      "Bounding box:  xmin: -79.42565 ymin: 43.65635 xmax: -79.40412 ymax: 43.66688\n",
      "Geodetic CRS:  WGS 84\n",
      "                                    address carpark_type rate_half_hr capacity\n",
      "16                    365 Lippincott Street      Surface          2.0      144\n",
      "27                    557 Palmerston Avenue      Surface          2.0       55\n",
      "33                       675 Manning Avenue      Surface          2.0       49\n",
      "34  745 Ossington Avenue, 16 Carling Avenue      Surface          2.0       45\n",
      "48                       376 Clinton Street      Surface          1.5       33\n",
      "90                        80 Clinton Street      Surface          1.5       25\n",
      "110                          4 Spadina Road      Surface          1.5       51\n",
      "121                    292 Brunswick Avenue      Surface          2.0       19\n",
      "    rate     extracted_address NearbyTraffic_1984 NearbyTraffic_1985\n",
      "16  2.00 365 Lippincott Street             6120.2             8807.3\n",
      "27  2.00 557 Palmerston Avenue             6183.0             7048.6\n",
      "33  2.00    675 Manning Avenue             7322.8             7048.6\n",
      "34  2.00  745 Ossington Avenue             7448.0             6148.2\n",
      "48  1.50    376 Clinton Street             6907.2             7048.6\n",
      "90  1.50     80 Clinton Street             5589.2             6144.2\n",
      "110 1.50        4 Spadina Road             6511.4            10332.9\n",
      "121 2.00  292 Brunswick Avenue             6120.2             8807.3\n",
      "    NearbyTraffic_1986 NearbyTraffic_1987 NearbyTraffic_1988 NearbyTraffic_1989\n",
      "16              9854.2             8660.2             7805.4             9049.4\n",
      "27             10214.4             7368.8             8046.2             9152.8\n",
      "33              9085.8             7526.2             7877.2             8387.0\n",
      "34              6440.8             5453.6             7182.0             6789.8\n",
      "48             10013.2             7526.2             7877.2             8387.0\n",
      "90              7318.4             6579.8             7049.2             6935.2\n",
      "110            10662.0            13324.0             7805.4             9245.6\n",
      "121             9395.6             9426.2             7805.4             9049.4\n",
      "    NearbyTraffic_1990 NearbyTraffic_1991 NearbyTraffic_1992 NearbyTraffic_1993\n",
      "16             10063.8             9267.6             5572.4             7305.4\n",
      "27             10412.6             9267.6             5690.8             7098.8\n",
      "33              9572.4             9015.8             6028.0             7098.8\n",
      "34              6726.8             6971.4             4984.6             6982.0\n",
      "48              8429.0             9015.8             6028.0             7937.4\n",
      "90              8800.8             7812.6             5292.2             5972.0\n",
      "110            10024.6             8944.0             6747.6             7407.2\n",
      "121            10193.6             9206.2             6608.6             7305.4\n",
      "    NearbyTraffic_1994 NearbyTraffic_1995 NearbyTraffic_1996 NearbyTraffic_1997\n",
      "16              5785.8             7120.8             6007.8             8442.4\n",
      "27              5785.8             6764.6             7281.4             6662.4\n",
      "33              4760.8             6764.6             8241.8             5992.8\n",
      "34              6361.8             6727.0             5407.3             5348.2\n",
      "48              5231.4             6552.6             8241.8             5992.8\n",
      "90              5139.0             5741.8             5590.8             5266.8\n",
      "110            13669.8             8512.8             6855.6            11644.8\n",
      "121             7336.4             7120.8             5735.0             8442.4\n",
      "    NearbyTraffic_1998 NearbyTraffic_1999 NearbyTraffic_2000 NearbyTraffic_2001\n",
      "16              7575.8             5888.4             8592.6             6585.4\n",
      "27             10399.2             5949.4             7532.8             7334.6\n",
      "33             10172.2             6088.4             8329.4             5691.4\n",
      "34             10711.0             6282.8             5659.8             4617.8\n",
      "48             11825.2             6088.4             8329.4             5181.2\n",
      "90              6278.0             4562.0             8329.6             5752.4\n",
      "110             7396.8             5564.6            10181.9             5541.8\n",
      "121             7575.8             5532.2             9476.1             6810.6\n",
      "    NearbyTraffic_2002 NearbyTraffic_2003 NearbyTraffic_2004 NearbyTraffic_2005\n",
      "16              7873.6             5616.8             6085.2             4458.2\n",
      "27              7040.6             5240.4             6897.8             1941.4\n",
      "33              4908.2             5416.0             5692.6             1941.4\n",
      "34              2531.0             3966.2             5209.0             5573.8\n",
      "48              4908.2             5404.8             5692.6              882.2\n",
      "90              5752.6             5074.2             5074.8              948.4\n",
      "110             6963.4             6686.2             6678.2             4002.0\n",
      "121             7873.6             6194.0             6860.0             6622.4\n",
      "    NearbyTraffic_2006 NearbyTraffic_2007 NearbyTraffic_2008 NearbyTraffic_2009\n",
      "16              3636.0             4903.9             8117.4             6384.8\n",
      "27              5088.4             5024.3             8005.6             6074.8\n",
      "33              4410.6             6146.2             8005.6             5916.6\n",
      "34              2292.2             4969.2             5346.0             6718.0\n",
      "48              4326.6             6110.0             6913.0             6274.0\n",
      "90              4693.4             5097.8             4854.7             5522.8\n",
      "110             1782.2             4850.1             7204.4             6341.8\n",
      "121             3589.2             4903.9             8916.6             6428.2\n",
      "    NearbyTraffic_2010 NearbyTraffic_2011 NearbyTraffic_2012 NearbyTraffic_2013\n",
      "16              5472.0             7825.6             8661.0             7032.4\n",
      "27              5984.8             7778.4             8454.9             5528.8\n",
      "33              5561.2             5725.0             8205.5             4533.6\n",
      "34              5571.0             3960.0             5380.5             1995.8\n",
      "48              5640.8             4317.8             6386.1             3708.2\n",
      "90              4718.8             6087.6             3567.0             4588.2\n",
      "110             5496.4             5696.6             6791.0             7032.4\n",
      "121             5614.8             7825.6             8929.4             7032.4\n",
      "    NearbyTraffic_2014 NearbyTraffic_2015 NearbyTraffic_2016 NearbyTraffic_2017\n",
      "16              6633.4             5695.4            8263.60           5599.400\n",
      "27              6633.4             7083.4            7210.20           4444.200\n",
      "33              6633.4             7083.4            6229.40           2852.778\n",
      "34               615.0             2166.8            8012.10           2964.378\n",
      "48              5857.6             6046.4            6229.40           2740.578\n",
      "90              2661.2             5493.7            5435.12           4838.200\n",
      "110             7548.2             5181.6            9197.60           5057.800\n",
      "121             6633.4             5695.4            7892.60           5057.800\n",
      "    NearbyTraffic_2018 NearbyTraffic_2019 NearbyTraffic_2020 NearbyTraffic_2021\n",
      "16              3936.6             4690.6           3009.483            2647.60\n",
      "27              3978.8             5558.0           3726.033            2150.80\n",
      "33              3183.0             4733.8           4563.133            1761.00\n",
      "34              4476.2             5666.5           4563.133            4548.32\n",
      "48              4301.4             4733.8           4563.133            1851.00\n",
      "90              2255.6             3212.4           3699.833            2347.60\n",
      "110             5712.0             4699.4           4246.000            3384.00\n",
      "121             5995.0             5697.6           2429.350            2777.20\n",
      "    NearbyTraffic_2022 NearbyTraffic_2023                   geometry\n",
      "16             5787.15             3171.0 POINT (-79.40966 43.66505)\n",
      "27             5146.10             2344.1 POINT (-79.41358 43.66504)\n",
      "33             5035.10             2430.2 POINT (-79.41601 43.66465)\n",
      "34             3388.30             2818.6 POINT (-79.42565 43.66243)\n",
      "48             3654.55             2430.2 POINT (-79.41758 43.66444)\n",
      "90             4587.00             3061.7 POINT (-79.41455 43.65635)\n",
      "110            5219.95             4965.9 POINT (-79.40412 43.66688)\n",
      "121            6321.50             3171.0 POINT (-79.40764 43.66537)\n"
     ]
    }
   ],
   "source": [
    "print(t_selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1 - Time Series Forecast\n",
    "# additional data processing needed before modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>8807.3</li><li>7048.6</li><li>7048.6</li><li>6148.2</li><li>7048.6</li><li>6144.2</li><li>10332.9</li><li>8807.3</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 8807.3\n",
       "\\item 7048.6\n",
       "\\item 7048.6\n",
       "\\item 6148.2\n",
       "\\item 7048.6\n",
       "\\item 6144.2\n",
       "\\item 10332.9\n",
       "\\item 8807.3\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 8807.3\n",
       "2. 7048.6\n",
       "3. 7048.6\n",
       "4. 6148.2\n",
       "5. 7048.6\n",
       "6. 6144.2\n",
       "7. 10332.9\n",
       "8. 8807.3\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  8807.3  7048.6  7048.6  6148.2  7048.6  6144.2 10332.9  8807.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_selected_rows$NearbyTraffic_1985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Model 2 - Regression Model\n",
    "\n",
    "# Read data\n",
    "parking<-read.csv(\"Parking_data.csv\")\n",
    "business<-read.csv(\"business.csv\")\n",
    "\n",
    "# Convert the business dataset to a spatial object\n",
    "business_sf <- st_as_sf(business, coords = c(\"long\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Convert the parking dataset to a spatial object\n",
    "parking_sf <- st_as_sf(parking, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Perform a spatial join to find the nearest business for each parking space\n",
    "nearest_business <- st_nearest_feature(parking_sf, business_sf)\n",
    "\n",
    "# Add the nearest business information to the parking dataset\n",
    "parking_data_with_nearest_business <- cbind(parking, nearest_business)\n",
    "#parking_data_with_nearest_business$traffic_volume= sample(2:200,nrow(parking), replace=F)  # To be replaced with traffic data\n",
    "parking_data_with_nearest_business$traffic_volume=t_selected_rows$NearbyTraffic_2024\n",
    "\n",
    "# An empty list to store the results\n",
    "result_list <- list()\n",
    "#parking_data_with_nearest_business <- parking\n",
    "\n",
    "\n",
    "# An empty list to store the results\n",
    "result_list <- list()\n",
    "\n",
    "# Function to calculate angular distance between two points on Earth\n",
    "haversine_distance <- function(lon1, lat1, lon2, lat2) {\n",
    "  R <- 6371 # Earth radius in km\n",
    "  dlat <- (lat2 - lat1) * pi / 180\n",
    "  dlon <- (lon2 - lon1) * pi / 180\n",
    "  a <- sin(dlat/2)^2 + cos(lat1 * pi / 180) * cos(lat2 * pi / 180) * sin(dlon/2)^2\n",
    "  c <- 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "  distance <- R * c\n",
    "  return(distance) # Distance in km\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in x[[jj]][iseq] <- vjj: replacement has length zero\n",
     "output_type": "error",
     "traceback": [
      "Error in x[[jj]][iseq] <- vjj: replacement has length zero\nTraceback:\n",
      "1. suppressWarnings({\n .     result_list <- list()\n .     for (i in 1:nrow(parking_data_with_nearest_business)) {\n .         temp_df <- data.frame(address = character(), lat = double(), \n .             lng = double(), distance = double(), capacity = integer(), \n .             traffic_volume = integer(), rate_half_hr = double(), \n .             n_customers = integer(), time_spent = double(), category = character(), \n .             interaction_term = integer())\n .         for (j in 1:nrow(business)) {\n .             lon1 <- parking_data_with_nearest_business[i, \"lng\"]\n .             lat1 <- parking_data_with_nearest_business[i, \"lat\"]\n .             lon2 <- business[j, \"long\"]\n .             lat2 <- business[j, \"lat\"]\n .             distance <- st_distance(st_point(c(lon1, lat1)), \n .                 st_point(c(lon2, lat2)))\n .             temp_df[nrow(temp_df) + 1, ] <- list(address = parking_data_with_nearest_business[i, \n .                 \"address\"], lat = parking_data_with_nearest_business[i, \n .                 \"lat\"], lng = parking_data_with_nearest_business[i, \n .                 \"lng\"], distance = distance, capacity = parking_data_with_nearest_business[i, \n .                 \"capacity\"], traffic_volume = parking_data_with_nearest_business[i, \n .                 \"traffic_volume\"], rate_half_hr = parking_data_with_nearest_business[i, \n .                 \"rate_half_hr\"], n_customers = business[j, \"qCustomer\"], \n .                 time_spent = business[j, \"tCustomer\"], category = business[j, \n .                   \"Category\"], interaction_term = business[j, \n .                   \"qCustomer\"] * business[j, \"tCustomer\"])\n .         }\n .         result_list[[i]] <- temp_df\n .     }\n .     result_df <- do.call(rbind, result_list)\n . })",
      "2. withCallingHandlers(expr, warning = function(w) if (inherits(w, \n .     classes)) tryInvokeRestart(\"muffleWarning\"))",
      "3. `[<-`(`*tmp*`, nrow(temp_df) + 1, , value = list(address = \"365 Lippincott Street\", \n .     lat = 43.665054, lng = -79.409662, distance = structure(0.022371028967734, dim = c(1L, \n .     1L)), capacity = 144L, traffic_volume = NULL, rate_half_hr = 2, \n .     n_customers = 5L, time_spent = 0.469866224, category = \"PRIVATE PARKING ENFORCEMENT AGENCY\", \n .     interaction_term = 2.34933112))   # at line 36-49 of file <text>",
      "4. `[<-.data.frame`(`*tmp*`, nrow(temp_df) + 1, , value = list(address = \"365 Lippincott Street\", \n .     lat = 43.665054, lng = -79.409662, distance = structure(0.022371028967734, dim = c(1L, \n .     1L)), capacity = 144L, traffic_volume = NULL, rate_half_hr = 2, \n .     n_customers = 5L, time_spent = 0.469866224, category = \"PRIVATE PARKING ENFORCEMENT AGENCY\", \n .     interaction_term = 2.34933112))   # at line 36-49 of file <text>"
     ]
    }
   ],
   "source": [
    "## Calculate distance between each parking spot and each business\n",
    "suppressWarnings({\n",
    "\n",
    "# Create an empty list to store the results\n",
    "result_list <- list()\n",
    "\n",
    "for (i in 1:nrow(parking_data_with_nearest_business)){\n",
    "  \n",
    "  # Create a temporary data frame to store the results for this parking spot\n",
    "  temp_df <- data.frame(\n",
    "    address = character(),\n",
    "    lat = double(),\n",
    "    lng = double(),\n",
    "    distance = double(),\n",
    "    capacity = integer(),\n",
    "    traffic_volume = integer(),\n",
    "    rate_half_hr= double(),\n",
    "    #n_business = integer(),\n",
    "    n_customers =integer(),\n",
    "    time_spent = double(),\n",
    "    category = character(),\n",
    "    interaction_term = integer()\n",
    "  )\n",
    "  \n",
    "  for( j in 1:nrow(business)){\n",
    "    lon1 <- parking_data_with_nearest_business[i,\"lng\"]\n",
    "    lat1 <- parking_data_with_nearest_business[i,\"lat\"]\n",
    "    lon2 <- business[j, \"long\"]\n",
    "    lat2 <- business[j, \"lat\"]\n",
    " \n",
    "\n",
    "    # Calculate distance\n",
    "    distance <- st_distance(st_point(c(lon1, lat1)), st_point(c(lon2, lat2)))\n",
    "    \n",
    "    # Store the results in the temporary data frame\n",
    "    temp_df[nrow(temp_df) + 1, ] <- list(\n",
    "      address = parking_data_with_nearest_business[i,\"address\"],\n",
    "      lat = parking_data_with_nearest_business[i,\"lat\"],\n",
    "      lng = parking_data_with_nearest_business[i,\"lng\"],\n",
    "      distance = distance,\n",
    "      capacity = parking_data_with_nearest_business[i,\"capacity\"],\n",
    "      traffic_volume = parking_data_with_nearest_business[i,\"traffic_volume\"],\n",
    "      #n_business = parking_data_with_nearest_business[i,\"nearest_business\"],\n",
    "      rate_half_hr = parking_data_with_nearest_business[i,\"rate_half_hr\"],\n",
    "      n_customers = business[j,\"qCustomer\"],\n",
    "      time_spent = business[j,\"tCustomer\"],\n",
    "      category = business[j,\"Category\"],\n",
    "      interaction_term = business[j,\"qCustomer\"] * business[j,\"tCustomer\"]\n",
    "    )\n",
    "  }\n",
    "  \n",
    "  # Append the temporary data frame to the result list\n",
    "  result_list[[i]] <- temp_df\n",
    "}\n",
    "\n",
    "# Combine all the results into a single data frame\n",
    "result_df <- do.call(rbind, result_list)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                address      lat       lng   distance rate_half_hr n_businesses\n",
      "1 365 Lippincott Street 43.66505 -79.40966 0.02237103            2          404\n",
      "2 365 Lippincott Street 43.66505 -79.40966 0.01805960            2          404\n",
      "3 365 Lippincott Street 43.66505 -79.40966 0.01440829            2          404\n",
      "4 365 Lippincott Street 43.66505 -79.40966 0.02334676            2          404\n",
      "5 365 Lippincott Street 43.66505 -79.40966 0.01839793            2          404\n",
      "6 365 Lippincott Street 43.66505 -79.40966 0.03068990            2          404\n",
      "  capacity n_customers time_spent traffic_volume interaction_term\n",
      "1      144           5  0.4698662           3171         2.349331\n",
      "2      144           2  4.9004879           3171         9.800976\n",
      "3      144           6  0.7990269           3171         4.794162\n",
      "4      144           2  0.7700175           3171         1.540035\n",
      "5      144           2  1.0064248           3171         2.012850\n",
      "6      144           4  1.1079138           3171         4.431655\n"
     ]
    }
   ],
   "source": [
    "# Filter rows according to radius\n",
    "\n",
    "filtered_result_df <- result_df[result_df$distance <= 0.50, ]\n",
    "a=filtered_result_df %>% count(address)\n",
    "\n",
    "\n",
    "filtered_result_df <- filtered_result_df %>%\n",
    "  left_join(a, by = \"address\")\n",
    "\n",
    "# Select desired columns and rename the \"n\" column\n",
    "filtered_result_df <- filtered_result_df %>%\n",
    "  select(address, lat,lng, distance,rate_half_hr, n_businesses = n, capacity, n_customers, time_spent, traffic_volume, interaction_term) \n",
    "\n",
    "\n",
    "print(head(filtered_result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# filtered_result_df2 <- filtered_result_df %>%\n",
    "#   group_by(address, lat, lng) %>%\n",
    "#   summarise(sum_n_customers = sum(n_customers),\n",
    "#             sum_time_spent = sum(time_spent),\n",
    "#             sum_traffic_volume =sum(traffic_volume)) %>%\n",
    "#   select(address, lat, lng, sum_n_customers, sum_time_spent, sum_traffic_volume)\n",
    "\n",
    "# print(head(filtered_result_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize predictors\n",
    "filtered_result_df$traffic_volume <- scale(filtered_result_df$traffic_volume)\n",
    "filtered_result_df$distance <- scale(filtered_result_df$distance)\n",
    "filtered_result_df$n_customers <- scale(filtered_result_df$n_customers)\n",
    "filtered_result_df$time_spent <- scale(filtered_result_df$time_spent)\n",
    "filtered_result_df$interaction_term <- scale(filtered_result_df$interaction_term)\n",
    "filtered_result_df$rate_half_hr <- scale(filtered_result_df$rate_half_hr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = capacity ~ traffic_volume + distance + n_customers + \n",
       "    time_spent + interaction_term + rate_half_hr, data = filtered_result_df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-51.105 -12.217  -5.173   2.246  79.441 \n",
       "\n",
       "Coefficients:\n",
       "                 Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)      52.62500    0.58264  90.322   <2e-16 ***\n",
       "traffic_volume   10.13521    0.64507  15.712   <2e-16 ***\n",
       "distance         -1.20104    0.58582  -2.050   0.0404 *  \n",
       "n_customers       0.03416    0.80525   0.042   0.9662    \n",
       "time_spent        0.15736    2.07850   0.076   0.9397    \n",
       "interaction_term -0.24799    2.13773  -0.116   0.9077    \n",
       "rate_half_hr     16.99202    0.64527  26.333   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 33.12 on 3225 degrees of freedom\n",
       "Multiple R-squared:  0.1821,\tAdjusted R-squared:  0.1806 \n",
       "F-statistic: 119.6 on 6 and 3225 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = capacity ~ traffic_volume + distance + rate_half_hr + \n",
       "    interaction_term, data = filtered_result_df)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-51.089 -12.207  -5.156   2.237  79.427 \n",
       "\n",
       "Coefficients:\n",
       "                 Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)       52.6250     0.5825  90.350   <2e-16 ***\n",
       "traffic_volume    10.1351     0.6449  15.717   <2e-16 ***\n",
       "distance          -1.1994     0.5852  -2.049   0.0405 *  \n",
       "rate_half_hr      16.9919     0.6451  26.341   <2e-16 ***\n",
       "interaction_term  -0.0942     0.5844  -0.161   0.8719    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 33.11 on 3227 degrees of freedom\n",
       "Multiple R-squared:  0.1821,\tAdjusted R-squared:  0.1811 \n",
       "F-statistic: 179.6 on 4 and 3227 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model1 <- lm(capacity ~ traffic_volume  + distance + n_customers + time_spent + interaction_term  + rate_half_hr, data = filtered_result_df)\n",
    "\n",
    "summary(model1)\n",
    "\n",
    "model2 <- lm(capacity ~ traffic_volume  + distance  + rate_half_hr + interaction_term, data = filtered_result_df)\n",
    "summary(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: variables 'traffic_volume', 'distance', 'rate_half_hr', 'interaction_term' were specified with different types from the fit\n",
     "output_type": "error",
     "traceback": [
      "Error: variables 'traffic_volume', 'distance', 'rate_half_hr', 'interaction_term' were specified with different types from the fit\nTraceback:\n",
      "1. predict(model2, newdata)",
      "2. predict.lm(model2, newdata)",
      "3. .checkMFClasses(cl, m)",
      "4. stop(gettextf(\"variables %s were specified with different types from the fit\", \n .     paste(sQuote(names(old)[wrong]), collapse = \", \")), call. = FALSE, \n .     domain = NA)"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------For 0.4 * existing traffic_volume -----------------------------------\n",
    "\n",
    "all_results <- data.frame()\n",
    "\n",
    "x_percent=0.4\n",
    "new_traffic_scenario = filtered_result_df$traffic_volume * x_percent\n",
    "newdata = data.frame(traffic_volume = new_traffic_scenario,\n",
    "                     address=filtered_result_df$address,\n",
    "                     distance = filtered_result_df$distance,\n",
    "                     n_customers = filtered_result_df$n_customers,\n",
    "                     time_spent = filtered_result_df$time_spent,\n",
    "                     interaction_term = filtered_result_df$interaction_term,\n",
    "                     rate_half_hr= filtered_result_df$rate_half_hr)\n",
    "\n",
    "# Make predictions\n",
    "predicted_capacity <- predict(model2, newdata)\n",
    "\n",
    "# Determine conversion needs\n",
    "capacity_needed <- ifelse(predicted_capacity > 1, ceiling(predicted_capacity), 0)\n",
    "\n",
    "# Store results for this scenario \n",
    "results <- data.frame(filtered_result_df$address, filtered_result_df$lat, filtered_result_df$lng, filtered_result_df$capacity,capacity_needed, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent)\n",
    "\n",
    "\n",
    "# ----------------------------For different % of traffic_volumes -----------------------------------\n",
    "\n",
    "# Iterate for different EV adoption rates\n",
    "x_percent_values <- seq(from = 0.1, to = 1, by = 0.4)  \n",
    "all_results <- data.frame()\n",
    "\n",
    "for (x_percent in x_percent_values) {\n",
    "  # Create new traffic scenario\n",
    "  new_traffic_scenario = result_df$traffic_volume * x_percent\n",
    "  newdata = data.frame(traffic_volume = new_traffic_scenario,\n",
    "                     address=filtered_result_df$address,\n",
    "                     distance = filtered_result_df$distance,\n",
    "                     n_customers = filtered_result_df$n_customers,\n",
    "                     time_spent = filtered_result_df$time_spent,\n",
    "                     interaction_term = filtered_result_df$interaction_term,\n",
    "                     rate_half_hr= filtered_result_df$rate_half_hr)\n",
    "\n",
    "  # Make predictions\n",
    "  predicted_capacity <- predict(model1, newdata)\n",
    "  # Determine conversion needs\n",
    "  capacity_needed <- ifelse(predicted_capacity > 1, ceiling(predicted_capacity), 0)\n",
    "\n",
    "  # Store results for this scenario \n",
    "  results <- data.frame(data.frame(filtered_result_df$address, filtered_result_df$lat, filtered_result_df$lng, filtered_result_df$capacity,capacity_needed, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent))\n",
    "  all_results <- rbind(all_results, results)\n",
    "}\n",
    "\n",
    "# Sort combined results\n",
    "all_results <- arrange(all_results, x_percent)\n",
    "\n",
    "# Create table\n",
    "library(kableExtra)  \n",
    "table <- kable(all_results, caption = \"Conversion Needs by EV Adoption Rate\")\n",
    "print(table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# # Scoring function\n",
    "# calculate_score <- function(traffic_volume, capacity, rate_half_hr, nearest_businesses, customers, c_time, distance) {\n",
    "#   # Define weights for each factor\n",
    "#   weights <- c(0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.1)\n",
    "  \n",
    "#   # Normalize each factor\n",
    "#   normalized_traffic <- (traffic_volume - min(traffic_volume)) / (max(traffic_volume) - min(traffic_volume))\n",
    "#   normalized_capacity <- (capacity - min(capacity)) / (max(capacity) - min(capacity))\n",
    "#   normalized_rate <- (rate_half_hr - min(rate_half_hr)) / (max(rate_half_hr) - min(rate_half_hr))\n",
    "#   normalized_n_businesses <- (nearest_businesses - min(nearest_businesses)) / (max(nearest_businesses) - min(nearest_businesses))\n",
    "#   normalized_customers <-(customers - min(customers)) / (max(customers) - min(customers))\n",
    "#   normalized_time <- (c_time - min(c_time)) / (max(c_time) - min(c_time))\n",
    "#   normalized_distance <- (distance - min(distance)) / (max(distance) - min(distance))\n",
    "\n",
    "#   # Calculate the score\n",
    "#   score <- weights[1] * normalized_traffic +\n",
    "#     weights[2] * normalized_capacity +\n",
    "#     weights[3] * normalized_distance +\n",
    "#     weights[4] * normalized_n_businesses + \n",
    "#     weights[5] * (normalized_customers * normalized_time) +\n",
    "#     weights[6] * (normalized_rate)\n",
    "\n",
    "#   return(abs(score))\n",
    "# }\n",
    "\n",
    "# # Calculate score for each parking spot\n",
    "# filtered_result_df$score <- calculate_score(filtered_result_df$traffic_volume, filtered_result_df$capacity, filtered_result_df$rate_half_hr, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent,filtered_result_df$distance)\n",
    "# # Rank the parking spots based on the score\n",
    "# ranked_data <- filtered_result_df[order(-filtered_result_df$score),]\n",
    "\n",
    "# # Find highest scored parking spot\n",
    "# highest_score_index <- which.max(ranked_data$score)\n",
    "# highest_score_parking_spot <- filtered_result_df[highest_score_index, ]\n",
    "\n",
    "# # Print the result\n",
    "# print(paste0(\"Address of parking spot: \",highest_score_parking_spot$address))\n",
    "# print(paste0(\"Latitude of parking spot: \",highest_score_parking_spot$lat))\n",
    "# print(paste0(\"Longitude of parking spot: \",highest_score_parking_spot$lng))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Result and Discussion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
