{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Load all required libraries for the notebook, including data package\n",
    "if(!require(\"opendatatoronto\")){\n",
    "    install.packages(\"opendatatoronto\")\n",
    "    library(opendatatoronto)\n",
    "} \n",
    "library(dplyr)\n",
    "library(stringr) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Traffice\n",
    "# output Data Description: \n",
    "# Dataframe with all intersection and daily count ( peak 4 hours), including lng / lat\n",
    "\n",
    "#? and todo:\n",
    "# is separate street name needed\n",
    "# direction of the street to be determined. How?\n",
    "\n",
    "\n",
    "# package_traffic <- show_package(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# get all resources for this package\n",
    "resources<- list_package_resources(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    " \n",
    "# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))\n",
    " \n",
    "# load data\n",
    "location <- filter(datastore_resources, row_number()==1) %>% get_resource()\n",
    "traffic1 <-filter(datastore_resources, row_number()==3) %>% get_resource()\n",
    "traffic2 <-filter(datastore_resources, row_number()==4) %>% get_resource()\n",
    "traffic3 <-filter(datastore_resources, row_number()==5) %>% get_resource()\n",
    "traffic4 <-filter(datastore_resources, row_number()==6) %>% get_resource()\n",
    "traffic5 <-filter(datastore_resources, row_number()==7) %>% get_resource()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# clean and transform load - Traffic Data\n",
    "# Output data for modelling CleanTraffic\n",
    "# define parameters for cleaning \n",
    "peakhours = 4 # number of peak hours of data per day. value should be between 1 and 10\n",
    "\n",
    "\n",
    "clean_T1 <- traffic1 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "clean_T2 <- traffic2 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T3 <- traffic3 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T4 <- traffic4 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T5 <- traffic5 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "\n",
    "CleanTraffic <-bind_rows(clean_T1,clean_T2,clean_T3,clean_T4,clean_T5)\n",
    "head(CleanTraffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Green P Parking\n",
    "# output Data Description: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Intersection\n",
    "# output Data Description: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Business\n",
    "# output Data Description: "
    # Load libraries needed
if (!require(tidyverse)) install.packages("tidyverse")
library(tidyverse)  
if (!require(tidygeocoder)) install.packages("tidygeocoder")
library(tidygeocoder)  
if (!require(sf)) install.packages("sf")
library(sf) 
if (!require(mapview)) install.packages("mapview")
library(mapview) 
# Load libraries needed
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggmap)

#load data from URL
url <- "https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/57b2285f-4f80-45fb-ae3e-41a02c3a137f/resource/54bddc5e-92d9-4102-89c1-43e82f8f4d2d/download/Business%20licences%20data.csv"
dest<- "c:/users/Public/Public Downloads"
download.file(url, dest)
setwd("~/Class/2024_1_GT_MGT6203_DataAnalyticInBiz/")
biz_data <- read.csv("c:/users/Public/Public Downloads",header = TRUE)

#load from l
#setwd("~/Class/2024_1_GT_MGT6203_DataAnalyticInBiz/project/")
#biz_data <- read.csv("business licences data.csv")
#biz_data_raw = biz_data
##########################################################
# This section is for import business data and clean up.
# The business data is download from https://open.toronto.ca/dataset/municipal-licensing-and-standards-business-licences-and-permits/
# Then it will be stored in local file as per setwd above
#Meaning of the data according to the readme from website are as follows
#Category=Type of licence or permit
#Licence No=Number. of licence issued by City of Toronto
#Operating Name=Name that company operates under
#Issued=Date of issue of licence/permit
#Client Name=Name that the licence is issued to
#Business Phone=Client Business Phone Number
#Business Phone Ext.=Client Business Phone Extension Number
#Licence Address Line 1=First line of client's business address
#Licence Address Line 2=Client address town and province
#Licence Address Line 3=Client address postal code
#Conditions=Restriction on the licence/permit recorded in the licensing system
#Free Form Conditions Line 1=Restriction/comment on the licence/permit
#Free Form Conditions Line 2=Continuation of line 1 
#Plate No.=Licence identifying plate, issued to most vehicles
#Endorsements=Activity permitted under the licence
#Cancel Date=Date the license or permit was cancelled
###################################################

biz_data$Category = as.factor(biz_data$Category)
biz_data$Licence.Address.Line.2 = as.factor(biz_data$Licence.Address.Line.2)
#biz_data$Licence.Address.Line.3 = as.factor(biz_data$Licence.Address.Line.3)
biz_data$Issued = as.Date(biz_data$Issued)
biz_data$Cancel.Date = as.Date(biz_data$Cancel.Date)
biz_data$Last.Record.Update = as.Date(biz_data$Last.Record.Update)
biz_data$Operating.Name <-ifelse(biz_data$Operating.Name =="",biz_data$Client.Name,biz_data$Operating.Name)

summary(biz_data)

#########
#remove biz that have cancel date as it indicates that business has already been cancelled (i.e. terminated)
# only select business in Toronto
# cleaned data is under biz_data (along the way, data will be backup to biz_data_bak)

biz_data_bak = biz_data
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define Region of Interest - Boundary\n",
    "## coordinates manually looked up from location dataset\n",
    "#1406\t5370\tDUPONT ST AT OSSINGTON AVE (PX 842)\t-79.429019\t43.670031996501194\n",
    "# 251\t4180\tDUPONT ST AT SPADINA RD (PX 840)\t-79.407122\t43.67485699954096\n",
    "#1885\t5864\tCOLLEGE ST AT OSSINGTON AVE (PX 829)\t-79.422705\t43.65439999619167\n",
    "#241\t4170\tCOLLEGE ST AT SPADINA AVE (PX 279)\t-79.400048\t43.65794800150128\n",
    "\n",
    "# Input\n",
    "# Output\n",
    "\n",
    "boundary <- location %>%\n",
    "  select(location_id,location,lng,lat) %>%\n",
    "  filter(location_id %in% list(5370,4180,5864,4170)) # boundary intersection ID\n",
    "\n",
    "lng_min <- min(boundary$lng) # west most value since it's negative\n",
    "lng_max <- max(boundary$lng) # east most value\n",
    "lat_min <- min(boundary$lat) # south most value\n",
    "lat_max <- max(boundary$lat) # north most value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine Data for model building\n",
    "# what is the expected output of data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1 - Time Series Forecast\n",
    "# additional data processing needed before modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 2 - Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Result and Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
