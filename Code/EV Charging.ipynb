{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load all required libraries for the notebook, including data package\n",
    "if(!require(\"opendatatoronto\")) {\n",
    "    install.packages(\"opendatatoronto\")\n",
    "    library(opendatatoronto)\n",
    "}\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "library(ggplot2)\n",
    "library(ggspatial)\n",
    "library(tidyjson)\n",
    "library(tidyverse)\n",
    "library(tidygeocoder)\n",
    "library(sf)\n",
    "library(mapview)\n",
    "library(opendatatoronto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Traffice\n",
    "# output Data Description:\n",
    "# Dataframe with all intersection and daily count ( peak 4 hours), including lng / lat\n",
    "\n",
    "# ? and todo:\n",
    "# is separate street name needed\n",
    "# direction of the street to be determined. How?\n",
    "\n",
    "\n",
    "# package_traffic <- show_package(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# get all resources for this package\n",
    "resources <- list_package_resources(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "datastore_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"geojson\"))\n",
    "\n",
    "# load data\n",
    "location <- filter(datastore_resources, row_number() == 1) %>% get_resource()\n",
    "traffic1 <- filter(datastore_resources, row_number() == 3) %>% get_resource()\n",
    "traffic2 <- filter(datastore_resources, row_number() == 4) %>% get_resource()\n",
    "traffic3 <- filter(datastore_resources, row_number() == 5) %>% get_resource()\n",
    "traffic4 <- filter(datastore_resources, row_number() == 6) %>% get_resource()\n",
    "traffic5 <- filter(datastore_resources, row_number() == 7) %>% get_resource()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# clean and transform load - Traffic Data\n",
    "# Output data for modelling CleanTraffic\n",
    "# define parameters for cleaning\n",
    "peakhours <- 4 # number of peak hours of data per day. value should be between 1 and 10\n",
    "\n",
    "\n",
    "clean_T1 <- traffic1 %>%\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"centreline_type\",\n",
    "    \"time_start\", \"sb_cars_r\", \"sb_cars_t\", \"sb_cars_l\",\n",
    "    \"nb_cars_r\", \"nb_cars_t\", \"nb_cars_l\", \"wb_cars_r\", \"wb_cars_t\", \"wb_cars_l\",\n",
    "    \"eb_cars_r\", \"eb_cars_t\", \"eb_cars_l\"\n",
    "  ))) %>% # select needed attributes\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t + eb_cars_l + wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t + eb_cars_r + wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t + nb_cars_l + sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t + nb_cars_r + sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) # aggregate daily peak hour volume\n",
    "clean_T2 <- traffic2 %>%\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"centreline_type\",\n",
    "    \"time_start\", \"sb_cars_r\", \"sb_cars_t\", \"sb_cars_l\",\n",
    "    \"nb_cars_r\", \"nb_cars_t\", \"nb_cars_l\", \"wb_cars_r\", \"wb_cars_t\", \"wb_cars_l\",\n",
    "    \"eb_cars_r\", \"eb_cars_t\", \"eb_cars_l\"\n",
    "  ))) %>% # select needed attributes\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t + eb_cars_l + wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t + eb_cars_r + wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t + nb_cars_l + sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t + nb_cars_r + sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggsregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T3 <- traffic3 %>%\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"centreline_type\",\n",
    "    \"time_start\", \"sb_cars_r\", \"sb_cars_t\", \"sb_cars_l\",\n",
    "    \"nb_cars_r\", \"nb_cars_t\", \"nb_cars_l\", \"wb_cars_r\", \"wb_cars_t\", \"wb_cars_l\",\n",
    "    \"eb_cars_r\", \"eb_cars_t\", \"eb_cars_l\"\n",
    "  ))) %>% # select needed attributes\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t + eb_cars_l + wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t + eb_cars_r + wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t + nb_cars_l + sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t + nb_cars_r + sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T4 <- traffic4 %>%\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"centreline_type\",\n",
    "    \"time_start\", \"sb_cars_r\", \"sb_cars_t\", \"sb_cars_l\",\n",
    "    \"nb_cars_r\", \"nb_cars_t\", \"nb_cars_l\", \"wb_cars_r\", \"wb_cars_t\", \"wb_cars_l\",\n",
    "    \"eb_cars_r\", \"eb_cars_t\", \"eb_cars_l\"\n",
    "  ))) %>% # select needed attributes\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t + eb_cars_l + wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t + eb_cars_r + wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t + nb_cars_l + sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t + nb_cars_r + sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T5 <- traffic5 %>%\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"centreline_type\",\n",
    "    \"time_start\", \"sb_cars_r\", \"sb_cars_t\", \"sb_cars_l\",\n",
    "    \"nb_cars_r\", \"nb_cars_t\", \"nb_cars_l\", \"wb_cars_r\", \"wb_cars_t\", \"wb_cars_l\",\n",
    "    \"eb_cars_r\", \"eb_cars_t\", \"eb_cars_l\"\n",
    "  ))) %>% # select needed attributes\n",
    "  filter(centreline_type == 2) %>% # only need intersection data\n",
    "  mutate(counthour = str_extract(time_start, \"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r + sb_cars_t + sb_cars_l +\n",
    "    nb_cars_r + nb_cars_t + nb_cars_l + wb_cars_r + wb_cars_t +\n",
    "    wb_cars_l + eb_cars_r + eb_cars_t + eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t + eb_cars_l + wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t + eb_cars_r + wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t + nb_cars_l + sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t + nb_cars_r + sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\n",
    "    \"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\",\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  ))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\", \"location_id\", \"location\", \"lng\", \"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\n",
    "    \"total_int_traffic\", \"nb_exit_traffic\", \"sb_exit_traffic\", \"wb_exit_traffic\",\n",
    "    \"eb_exit_traffic\"\n",
    "  )), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "\n",
    "CleanTraffic <- bind_rows(clean_T1, clean_T2, clean_T3, clean_T4, clean_T5)\n",
    "head(CleanTraffic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Green P Parking package from Open Data-Toronto\n",
    "package <- show_package(\"b66466c3-69c8-4825-9c8b-04b270069193\")\n",
    "\n",
    "data=as.data.frame('Green P Parking')  # read the dataset Green P Parking in the package \n",
    "data<-show_package(package)\n",
    "\n",
    "resources<-list_package_resources(package)\n",
    "\n",
    "# Identify resources\n",
    "data_resources <- filter(resources, tolower(format) %in% c(\"csv\", \"json\"))\n",
    "\n",
    "# Load Green P Parking 2019 data\n",
    "data <- filter(data_resources, row_number() == 1) %>% get_resource()\n",
    "\n",
    "# Extract required columns from main data\n",
    "data<- data.frame(address=data$carparks$address,\n",
    "                                     lat=data$carparks$lat,\n",
    "                                     lng=data$carparks$lng,\n",
    "                                      carpark_type=data$carparks$carpark_type_str,\n",
    "                                      rate_half_hr=data$carparks$rate_half_hour,\n",
    "                                      capacity=data$carparks$capacity,\n",
    "                                      rate=data$carparks$rate_half_hour\n",
    "                  )\n",
    "\n",
    "# Check class of each attribute\n",
    "sapply(data, class) \n",
    "\n",
    "# Convert char to numeric class\n",
    "data$lat<-as.numeric(data$lat)\n",
    "data$lng<-as.numeric(data$lng)\n",
    "data$rate_half_hr<-as.numeric(data$rate_half_hr)\n",
    "data$capacity<-as.numeric(data$capacity)\n",
    "\n",
    "sapply(data, class) \n",
    "\n",
    "# Check for missing values\n",
    "any(is.na(data))\n",
    "\n",
    "# Extract street name from address\n",
    "data <- data %>%\n",
    "  mutate(extracted_address = str_replace_all(data$address, \"\\\\(.*?\\\\)\",\"\"))\n",
    "\n",
    "data$extracted_address<-str_replace_all(data$extracted_address, \"-.*\", \"\")\n",
    "data$extracted_address<-str_replace_all(data$extracted_address, \",.*\", \"\")\n",
    "\n",
    "# Extract data with carpark_type as 'Surface'\n",
    "data <- data %>%\n",
    "  filter(carpark_type == \"Surface\")\n",
    "\n",
    "# Convert Lat/Lng to address\n",
    "geo_rev_data<-data %>%\n",
    "  tidygeocoder::reverse_geocode(\n",
    "    lat=lat,\n",
    "    long=lng,\n",
    "    method=\"osm\")\n",
    "\n",
    "# Plot map\n",
    "map<-data %>%\n",
    "  st_as_sf(\n",
    "    coords=c(\"lng\",\"lat\"),\n",
    "    crs=4326\n",
    "  )\n",
    "\n",
    "map %>% mapview()\n",
    "\n",
    "# Define the polygon coordinates\n",
    "polygon_coords <- matrix(c(\n",
    "  -79.4289964889767, 43.6700360241176, -79.4226792245877, 43.6543887000655, -79.4000484228339, 43.657948514946, -79.4070875693025, 43.6748646586934,-79.4289964889767, 43.6700360241176  # Repeat first point to close the polygon exactly\n",
    "), ncol = 2, byrow = TRUE)\n",
    "\n",
    "# Create a polygon geometry\n",
    "polygon <- st_polygon(list(polygon_coords))\n",
    "\n",
    "# Convert the polygon object to an 'sf' object with a specified CRS (Coordinate Reference System)\n",
    "polygon <- st_sfc(polygon, crs = 4326)\n",
    "\n",
    "# Convert the data frame 'data' to an 'sf' object, specifying the columns containing longitude and latitude as coordinates, and set the CRS\n",
    "data_sf <- st_as_sf(data, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Find the indices of the rows in 'data_sf' that fall within the polygon\n",
    "indices <- st_within(data_sf, polygon)\n",
    "\n",
    "# Convert the indices to a data frame\n",
    "indices_df<-data.frame(indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "selected_rows <- data_sf[match(indices_df$row.id, seq_len(nrow(data))), ]\n",
    "\n",
    "# Plot selected rows on map\n",
    "map_df <- selected_rows %>%\n",
    "  st_as_sf() %>%\n",
    "  st_set_crs(4326) %>%\n",
    "  fortify()   # Convert the 'sf' object to a format suitable for use with 'ggplot2'\n",
    "\n",
    "# Display the spatial object using 'mapview'\n",
    "mapview(map_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Store output in a csv file\n",
    "write.csv(selected_rows, \"Parking.csv\", row.names = FALSE)\n",
    "print(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "selected_rows1<-selected_rows\n",
    "coords <- st_coordinates(selected_rows1$geometry)\n",
    "selected_rows1 <- cbind(selected_rows1, lng = coords[, \"X\"], lat = coords[, \"Y\"])\n",
    "# Remove the geometry column\n",
    "selected_rows1 <- selected_rows1[, !(names(selected_rows1) %in% c(\"geometry\"))]\n",
    "\n",
    "sf_df <- st_drop_geometry(selected_rows1)\n",
    "\n",
    "\n",
    "parking_data<- sf_df\n",
    "print(parking_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p<-read.csv(\"Parking.csv\")\n",
    "print(p)\n",
    "coords <- st_coordinates(selected_rows$geometry)\n",
    "selected_rows1 <- cbind(selected_rows1, lng = coords[, \"X\"], lat = coords[, \"Y\"])\n",
    "# Remove the geometry column\n",
    "selected_rows1 <- selected_rows1[, !(names(selected_rows1) %in% c(\"geometry\"))]\n",
    "\n",
    "sf_df <- st_drop_geometry(selected_rows1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Intersection\n",
    "# output Data Description:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Business\n",
    "# output Data Description: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define Region of Interest - Boundary\n",
    "## coordinates manually looked up from location dataset\n",
    "# 1406\t5370\tDUPONT ST AT OSSINGTON AVE (PX 842)\t-79.429019\t43.670031996501194\n",
    "# 251\t4180\tDUPONT ST AT SPADINA RD (PX 840)\t-79.407122\t43.67485699954096\n",
    "# 1885\t5864\tCOLLEGE ST AT OSSINGTON AVE (PX 829)\t-79.422705\t43.65439999619167\n",
    "# 241\t4170\tCOLLEGE ST AT SPADINA AVE (PX 279)\t-79.400048\t43.65794800150128\n",
    "\n",
    "# Input\n",
    "# Output\n",
    "\n",
    "boundary <- location %>%\n",
    "  select(location_id, location, lng, lat) %>%\n",
    "  filter(location_id %in% list(5370, 4180, 5864, 4170)) # boundary intersection ID\n",
    "\n",
    "lng_min <- min(boundary$lng) # west most value since it's negative\n",
    "lng_max <- max(boundary$lng) # east most value\n",
    "lat_min <- min(boundary$lat) # south most value\n",
    "lat_max <- max(boundary$lat) # north most value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine Data for model building\n",
    "# what is the expected output of data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1 - Time Series Forecast\n",
    "# additional data processing needed before modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "write.csv(parking_data, \"Parking_data.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Model 2 - Regression Model\n",
    "\n",
    "# Read data\n",
    "parking<-read.csv(\"Parking_data.csv\")\n",
    "business<-read.csv(\"business.csv\")\n",
    "\n",
    "# Convert the business dataset to a spatial object\n",
    "business_sf <- st_as_sf(business, coords = c(\"long\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Convert the parking dataset to a spatial object\n",
    "parking_sf <- st_as_sf(parking, coords = c(\"lng\", \"lat\"), crs = 4326)\n",
    "\n",
    "# Perform a spatial join to find the nearest business for each parking space\n",
    "nearest_business <- st_nearest_feature(parking_sf, business_sf)\n",
    "\n",
    "# Add the nearest business information to the parking dataset\n",
    "parking_data_with_nearest_business <- cbind(parking, nearest_business)\n",
    "parking_data_with_nearest_business$traffic_volume= sample(2:200,nrow(parking), replace=F)  # To be replaced with traffic data\n",
    "\n",
    "# An empty list to store the results\n",
    "result_list <- list()\n",
    "#parking_data_with_nearest_business <- parking\n",
    "\n",
    "\n",
    "# An empty list to store the results\n",
    "result_list <- list()\n",
    "\n",
    "# Function to calculate angular distance between two points on Earth\n",
    "haversine_distance <- function(lon1, lat1, lon2, lat2) {\n",
    "  R <- 6371 # Earth radius in km\n",
    "  dlat <- (lat2 - lat1) * pi / 180\n",
    "  dlon <- (lon2 - lon1) * pi / 180\n",
    "  a <- sin(dlat/2)^2 + cos(lat1 * pi / 180) * cos(lat2 * pi / 180) * sin(dlon/2)^2\n",
    "  c <- 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "  distance <- R * c\n",
    "  return(distance) # Distance in km\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate distance between each parking spot and each business\n",
    "\n",
    "# Create an empty list to store the results\n",
    "result_list <- list()\n",
    "\n",
    "for (i in 1:nrow(parking_data_with_nearest_business)){\n",
    "  \n",
    "  # Create a temporary data frame to store the results for this parking spot\n",
    "  temp_df <- data.frame(\n",
    "    address = character(),\n",
    "    lat = double(),\n",
    "    lng = double(),\n",
    "    distance = double(),\n",
    "    capacity = integer(),\n",
    "    traffic_volume = integer(),\n",
    "    rate_half_hr= double(),\n",
    "    #n_business = integer(),\n",
    "    n_customers =integer(),\n",
    "    time_spent = double(),\n",
    "    category = character(),\n",
    "    interaction_term = integer()\n",
    "  )\n",
    "  \n",
    "  for( j in 1:nrow(business)){\n",
    "    lon1 <- parking_data_with_nearest_business[i,\"lng\"]\n",
    "    lat1 <- parking_data_with_nearest_business[i,\"lat\"]\n",
    "    lon2 <- business[j, \"long\"]\n",
    "    lat2 <- business[j, \"lat\"]\n",
    " \n",
    "\n",
    "    # Calculate distance\n",
    "    distance <- st_distance(st_point(c(lon1, lat1)), st_point(c(lon2, lat2)))\n",
    "    \n",
    "    # Store the results in the temporary data frame\n",
    "    temp_df[nrow(temp_df) + 1, ] <- list(\n",
    "      address = parking_data_with_nearest_business[i,\"address\"],\n",
    "      lat = parking_data_with_nearest_business[i,\"lat\"],\n",
    "      lng = parking_data_with_nearest_business[i,\"lng\"],\n",
    "      distance = distance,\n",
    "      capacity = parking_data_with_nearest_business[i,\"capacity\"],\n",
    "      traffic_volume = parking_data_with_nearest_business[i,\"traffic_volume\"],\n",
    "      #n_business = parking_data_with_nearest_business[i,\"nearest_business\"],\n",
    "      rate_half_hr = parking_data_with_nearest_business[i,\"rate_half_hr\"],\n",
    "      n_customers = business[j,\"qCustomer\"],\n",
    "      time_spent = business[j,\"tCustomer\"],\n",
    "      category = business[j,\"Category\"],\n",
    "      interaction_term = business[j,\"qCustomer\"] * business[j,\"tCustomer\"]\n",
    "    )\n",
    "  }\n",
    "  \n",
    "  # Append the temporary data frame to the result list\n",
    "  result_list[[i]] <- temp_df\n",
    "}\n",
    "\n",
    "# Combine all the results into a single data frame\n",
    "result_df <- do.call(rbind, result_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Filter rows according to radius\n",
    "\n",
    "filtered_result_df <- result_df[result_df$distance <= 0.50, ]\n",
    "a=filtered_result_df %>% count(address)\n",
    "\n",
    "\n",
    "filtered_result_df <- filtered_result_df %>%\n",
    "  left_join(a, by = \"address\")\n",
    "\n",
    "# Select desired columns and rename the \"n\" column\n",
    "filtered_result_df <- filtered_result_df %>%\n",
    "  select(address, lat,lng, distance,rate_half_hr, n_businesses = n, capacity, n_customers, time_spent, traffic_volume, interaction_term) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model1 <- lm(capacity ~ traffic_volume  + distance + n_customers + time_spent + interaction_term  + rate_half_hr, data = filtered_result_df)\n",
    "\n",
    "summary(model1)\n",
    "\n",
    "model2 <- lm(capacity ~ traffic_volume  + distance  + rate_half_hr + interaction_term, data = filtered_result_df)\n",
    "summary(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------For 0.4 * existing traffic_volume -----------------------------------\n",
    "\n",
    "all_results <- data.frame()\n",
    "\n",
    "x_percent=0.4\n",
    "new_traffic_scenario = filtered_result_df$traffic_volume * x_percent\n",
    "newdata = data.frame(traffic_volume = new_traffic_scenario,\n",
    "                     address=filtered_result_df$address,\n",
    "                     distance = filtered_result_df$distance,\n",
    "                     n_customers = filtered_result_df$n_customers,\n",
    "                     time_spent = filtered_result_df$time_spent,\n",
    "                     interaction_term = filtered_result_df$interaction_term,\n",
    "                     rate_half_hr= filtered_result_df$rate_half_hr)\n",
    "\n",
    "# Make predictions\n",
    "predicted_capacity <- predict(model2, newdata)\n",
    "\n",
    "# Determine conversion needs\n",
    "capacity_needed <- ifelse(predicted_capacity > 1, ceiling(predicted_capacity), 0)\n",
    "\n",
    "# Store results for this scenario \n",
    "results <- data.frame(filtered_result_df$address, filtered_result_df$lat, filtered_result_df$lng, filtered_result_df$capacity,capacity_needed, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent)\n",
    "\n",
    "\n",
    "# ----------------------------For different % of traffic_volumes -----------------------------------\n",
    "\n",
    "# Iterate for different EV adoption rates\n",
    "x_percent_values <- seq(from = 0.1, to = 1, by = 0.4)  \n",
    "all_results <- data.frame()\n",
    "\n",
    "for (x_percent in x_percent_values) {\n",
    "  # Create new traffic scenario\n",
    "  new_traffic_scenario = result_df$traffic_volume * x_percent\n",
    "  newdata = data.frame(traffic_volume = new_traffic_scenario,\n",
    "                     address=filtered_result_df$address,\n",
    "                     distance = filtered_result_df$distance,\n",
    "                     n_customers = filtered_result_df$n_customers,\n",
    "                     time_spent = filtered_result_df$time_spent,\n",
    "                     interaction_term = filtered_result_df$interaction_term,\n",
    "                     rate_half_hr= filtered_result_df$rate_half_hr)\n",
    "\n",
    "  # Make predictions\n",
    "  predicted_capacity <- predict(model1, newdata)\n",
    "  # Determine conversion needs\n",
    "  capacity_needed <- ifelse(predicted_capacity > 1, ceiling(predicted_capacity), 0)\n",
    "\n",
    "  # Store results for this scenario \n",
    "  results <- data.frame(data.frame(filtered_result_df$address, filtered_result_df$lat, filtered_result_df$lng, filtered_result_df$capacity,capacity_needed, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent))\n",
    "  all_results <- rbind(all_results, results)\n",
    "}\n",
    "\n",
    "# Sort combined results\n",
    "all_results <- arrange(all_results, x_percent)\n",
    "\n",
    "# Create table\n",
    "library(kableExtra)  \n",
    "table <- kable(all_results, caption = \"Conversion Needs by EV Adoption Rate\")\n",
    "print(table)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# # Scoring function\n",
    "# calculate_score <- function(traffic_volume, capacity, rate_half_hr, nearest_businesses, customers, c_time, distance) {\n",
    "#   # Define weights for each factor\n",
    "#   weights <- c(0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.1)\n",
    "  \n",
    "#   # Normalize each factor\n",
    "#   normalized_traffic <- (traffic_volume - min(traffic_volume)) / (max(traffic_volume) - min(traffic_volume))\n",
    "#   normalized_capacity <- (capacity - min(capacity)) / (max(capacity) - min(capacity))\n",
    "#   normalized_rate <- (rate_half_hr - min(rate_half_hr)) / (max(rate_half_hr) - min(rate_half_hr))\n",
    "#   normalized_n_businesses <- (nearest_businesses - min(nearest_businesses)) / (max(nearest_businesses) - min(nearest_businesses))\n",
    "#   normalized_customers <-(customers - min(customers)) / (max(customers) - min(customers))\n",
    "#   normalized_time <- (c_time - min(c_time)) / (max(c_time) - min(c_time))\n",
    "#   normalized_distance <- (distance - min(distance)) / (max(distance) - min(distance))\n",
    "\n",
    "#   # Calculate the score\n",
    "#   score <- weights[1] * normalized_traffic +\n",
    "#     weights[2] * normalized_capacity +\n",
    "#     weights[3] * normalized_distance +\n",
    "#     weights[4] * normalized_n_businesses + \n",
    "#     weights[5] * (normalized_customers * normalized_time) +\n",
    "#     weights[6] * (normalized_rate)\n",
    "\n",
    "#   return(abs(score))\n",
    "# }\n",
    "\n",
    "# # Calculate score for each parking spot\n",
    "# filtered_result_df$score <- calculate_score(filtered_result_df$traffic_volume, filtered_result_df$capacity, filtered_result_df$rate_half_hr, filtered_result_df$n_businesses, filtered_result_df$n_customers, filtered_result_df$time_spent,filtered_result_df$distance)\n",
    "# # Rank the parking spots based on the score\n",
    "# ranked_data <- filtered_result_df[order(-filtered_result_df$score),]\n",
    "\n",
    "# # Find highest scored parking spot\n",
    "# highest_score_index <- which.max(ranked_data$score)\n",
    "# highest_score_parking_spot <- filtered_result_df[highest_score_index, ]\n",
    "\n",
    "# # Print the result\n",
    "# print(paste0(\"Address of parking spot: \",highest_score_parking_spot$address))\n",
    "# print(paste0(\"Latitude of parking spot: \",highest_score_parking_spot$lat))\n",
    "# print(paste0(\"Longitude of parking spot: \",highest_score_parking_spot$lng))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Result and Discussion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
