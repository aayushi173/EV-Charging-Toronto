{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Load all required libraries for the notebook, including data package\n",
    "if(!require(\"opendatatoronto\")){\n",
    "    install.packages(\"opendatatoronto\")\n",
    "    library(opendatatoronto)\n",
    "} \n",
    "library(dplyr)\n",
    "library(stringr) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Traffice\n",
    "# output Data Description: \n",
    "# Dataframe with all intersection and daily count ( peak 4 hours), including lng / lat\n",
    "\n",
    "#? and todo:\n",
    "# is separate street name needed\n",
    "# direction of the street to be determined. How?\n",
    "\n",
    "\n",
    "# package_traffic <- show_package(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    "\n",
    "# get all resources for this package\n",
    "resources<- list_package_resources(\"traffic-volumes-at-intersections-for-all-modes\")\n",
    " \n",
    "# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources\n",
    "datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))\n",
    " \n",
    "# load data\n",
    "location <- filter(datastore_resources, row_number()==1) %>% get_resource()\n",
    "traffic1 <-filter(datastore_resources, row_number()==3) %>% get_resource()\n",
    "traffic2 <-filter(datastore_resources, row_number()==4) %>% get_resource()\n",
    "traffic3 <-filter(datastore_resources, row_number()==5) %>% get_resource()\n",
    "traffic4 <-filter(datastore_resources, row_number()==6) %>% get_resource()\n",
    "traffic5 <-filter(datastore_resources, row_number()==7) %>% get_resource()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# clean and transform load - Traffic Data\n",
    "# Output data for modelling CleanTraffic\n",
    "# define parameters for cleaning \n",
    "peakhours = 4 # number of peak hours of data per day. value should be between 1 and 10\n",
    "\n",
    "\n",
    "clean_T1 <- traffic1 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "clean_T2 <- traffic2 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T3 <- traffic3 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T4 <- traffic4 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "clean_T5 <- traffic5 %>%\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"centreline_type\",\n",
    "                                      \"time_start\",\"sb_cars_r\",\"sb_cars_t\",\"sb_cars_l\",\n",
    "                                      \"nb_cars_r\",\"nb_cars_t\",\"nb_cars_l\",\"wb_cars_r\",\"wb_cars_t\",\"wb_cars_l\",\n",
    "                                      \"eb_cars_r\",\"eb_cars_t\",\"eb_cars_l\"))) %>% #select needed attributes\n",
    "  filter(centreline_type ==2) %>% #only need intersection data\n",
    "  mutate(counthour = str_extract(time_start,\"(?<=T)(\\\\d+)(?=\\\\:)\")) %>% # extract hour\n",
    "  mutate(total_int_traffic = sb_cars_r+sb_cars_t+sb_cars_l+\n",
    "           nb_cars_r+nb_cars_t+nb_cars_l+wb_cars_r + wb_cars_t+\n",
    "           wb_cars_l+eb_cars_r+eb_cars_t+eb_cars_l) %>% # get total sum\n",
    "  mutate(nb_exit_traffic = nb_cars_t+eb_cars_l+wb_cars_r) %>% # get north bound exit volume\n",
    "  mutate(sb_exit_traffic = sb_cars_t+eb_cars_r+wb_cars_l) %>% # get south bound exit volume\n",
    "  mutate(wb_exit_traffic = wb_cars_t+nb_cars_l+sb_cars_r) %>% # get west bound exit volume\n",
    "  mutate(eb_exit_traffic = eb_cars_t+nb_cars_r+sb_cars_l) %>% # get east bound exit volume\n",
    "  select(one_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\",\n",
    "                  \"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                  \"eb_exit_traffic\"))) %>% # remove raw attributes, retain aggregate only\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\", \"counthour\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) %>% # agregate hourly volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  slice_max(order_by = total_int_traffic, n = peakhours) %>% # filter top peak hour volume\n",
    "  group_by(across(all_of(c(\"count_date\",\"location_id\",\"location\",\"lng\",\"lat\")))) %>%\n",
    "  summarise(across(any_of(c(\"total_int_traffic\", \"nb_exit_traffic\",\"sb_exit_traffic\",\"wb_exit_traffic\",\n",
    "                            \"eb_exit_traffic\")), sum)) # aggregate daily peak hour volume\n",
    "\n",
    "\n",
    "CleanTraffic <-bind_rows(clean_T1,clean_T2,clean_T3,clean_T4,clean_T5)\n",
    "head(CleanTraffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Green P Parking\n",
    "# output Data Description: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Intersection\n",
    "# output Data Description: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data - Business\n",
    "# output Data Description: "
    ### output dataframe for this section is biz_geo_loc1
# Load libraries needed for general use
library(dplyr)
library(tidyr)
library(ggplot2)

############### This part is to load biz data from Toronto Open Data Source######################
### The business data is download from https://open.toronto.ca/dataset/municipal-licensing-and-standards-business-licences-and-permits/
### Using code from developer section as follows.
# Load libraries needed for loading data from toronto open data source
if (!require(opendatatoronto)) install.packages("opendatatoronto")
library(opendatatoronto)

# get package
package <- show_package("57b2285f-4f80-45fb-ae3e-41a02c3a137f")
package

# get all resources for this package
resources <- list_package_resources("57b2285f-4f80-45fb-ae3e-41a02c3a137f")

# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))

# load the first datastore resource as a sample
biz_data <- filter(datastore_resources, row_number()==1) %>% get_resource()
biz_data

### backup data to biz_data_bak
biz_data_bak = biz_data

###Meaning of the data according to the readme from website are as follows
###Category=Type of licence or permit
###Licence No=Number. of licence issued by City of Toronto
###Operating Name=Name that company operates under
###Issued=Date of issue of licence/permit
###Client Name=Name that the licence is issued to
###Business Phone=Client Business Phone Number
###Business Phone Ext.=Client Business Phone Extension Number
###Licence Address Line 1=First line of client's business address
###Licence Address Line 2=Client address town and province
###Licence Address Line 3=Client address postal code
###Conditions=Restriction on the licence/permit recorded in the licensing system
###Free Form Conditions Line 1=Restriction/comment on the licence/permit
###Free Form Conditions Line 2=Continuation of line 1 
###Plate No.=Licence identifying plate, issued to most vehicles
###Endorsements=Activity permitted under the licence
###Cancel Date=Date the license or permit was cancelled
############### End Of Data loading from  Toronto Open Data Source###############################

############################### Data Cleansing ##################################################
### Start cleaning up with change data type, filled in any empty data in Operating Name
biz_data$Category = as.factor(biz_data$Category)
biz_data$`Licence Address Line 2` = as.factor(biz_data$`Licence Address Line 2`)
biz_data$Issued = as.Date(biz_data$Issued)
biz_data$`Cancel Date` = as.Date(biz_data$`Cancel Date`)
biz_data$`Last Record Update` = as.Date(biz_data$`Last Record Update`)
biz_data$'Operating Name' <-ifelse(biz_data$'Operating Name' == "",biz_data$'Client Name',biz_data$'Operating Name')
#str(biz_data)
#summary(biz_data)
head(biz_data)

### remove biz that have cancel date as it indicates that business has already been cancelled (i.e. terminated)
biz_data = biz_data[which(is.na(biz_data$'Cancel Date')),]

#################################################################################################
### only select business in Toronto with zip code starting with M3, M4, M5 and M6
biz_data = biz_data[which(biz_data$'Licence Address Line 2' == "TORONTO, ON"),]
biz_data = biz_data[which(biz_data$'Licence Address Line 3' > "M3" & biz_data$'Licence Address Line 3' < "M7"),]
#################################################################################################
#biz_data = biz_data %>%
#  select(-'Cancel Date')

###make column to identify street name from Licence.Address.Line.1 (might be useful for cluster work later)
###first extracting the address number. grab only the data that are after the first space
biz_data$Street <- sub("^\\S+\\s+",'', biz_data$'Licence Address Line 1')
###first extracting the address number. remove number
biz_data$Street <- gsub("[[:digit:]]", "", biz_data$Street)
###remove other unneccessary characters
biz_data$Street <- sub('-  ', '', biz_data$Street)
biz_data$Street <- sub('&A ', '', biz_data$Street)
biz_data$Street <- sub('& A ', '', biz_data$Street)
biz_data$Street <- sub('&B ', '', biz_data$Street)
biz_data$Street <- sub('& B ', '', biz_data$Street)
biz_data$Street <- sub('&  ', '', biz_data$Street)
biz_data$Street <- sub('&& ', '', biz_data$Street)
biz_data$Street <- sub('& ', '', biz_data$Street)
biz_data$Street <- sub('/ ', '', biz_data$Street)
biz_data$Street <- sub('-A ', '', biz_data$Street)
biz_data$Street <- sub('A-', '', biz_data$Street)
biz_data$Street <- sub('- A ', '', biz_data$Street)
biz_data$Street <- sub('-B ', '', biz_data$Street)
biz_data$Street <- sub('- B ', '', biz_data$Street)
biz_data$Street <- sub("(?<=^.{0}),", "", biz_data$Street, perl = TRUE )
biz_data$Street <- sub("(?<=^.{0})&", "", biz_data$Street, perl = TRUE )
biz_data$Street <- sub("(?<=^.{0})/", "", biz_data$Street, perl = TRUE )
biz_data$Street <- sub("(?<=^.{0})-", "", biz_data$Street, perl = TRUE )
### as data is not clean, there are sometimes suite number or other suffix follow them. therefore, we clean that part up too.
biz_data$Street <- sub(", #.*", '', biz_data$Street)
biz_data$Street <- sub(" #.*", '', biz_data$Street)
biz_data$Street <- sub("#.*", '', biz_data$Street)
biz_data$Street <- sub(" ,.*", '', biz_data$Street)
biz_data$Street <- sub(",.*", '', biz_data$Street)

### use similar code to clean data and prepare for geo location
biz_data$StreetAddress = paste(biz_data$'Licence Address Line 1')
###remove other characters from address one
biz_data$StreetAddress <- sub('-  ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('&A ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('& A ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('&B ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('& B ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('&  ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('&& ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('& ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('/ ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('-A ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('A-', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('- A ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('-B ', '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub('- B ', '', biz_data$StreetAddress)
### Removing suite number or other suffix follow them. therefore
biz_data$StreetAddress <- sub(", #.*", '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub(" #.*", '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub("#.*", '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub(" ,.*", '', biz_data$StreetAddress)
biz_data$StreetAddress <- sub(",.*", '', biz_data$StreetAddress)
############################### End of Data Cleansing ###########################################

#######################Converting Address to Lat-Long ###########################################
###convert to Lat- Long using tidygeocode : Reference https://www.youtube.com/watch?v=7nFZ5BwkAXc
### Load libraries needed for geocode
if (!require(tidyverse)) install.packages("tidyverse")
library(tidyverse)  
if (!require(tidygeocoder)) install.packages("tidygeocoder")
library(tidygeocoder)  
if (!require(sf)) install.packages("sf")
library(sf) 
if (!require(mapview)) install.packages("mapview")
library(mapview) 

### Prepare Data to be converted
biz_data$Address <- paste(biz_data$StreetAddress,biz_data$'Licence Address Line 2',biz_data$'Licence Address Line 3', sep = ",")
biz_geo_loc = biz_data %>%
  select(Category,`Operating Name`,city = 'Licence Address Line 2',Zip = 'Licence Address Line 3',Street, Address)

### We narrow down the area to save time in processing, we have identify Toronoto City Center with following zipcode
### Toronto area within Ossington Ave/Dupont Street intersection, Ossington Ave/College Street intersection, 
### College Street/Spadina Ave Intersection and Spadina Ave/Dupont Street intersection 
### which are under zip code M6G, M6H, M6J, M5T, M5S, M5R and M4V. 
biz_geo_loc = biz_geo_loc %>% filter(str_detect(Zip, "M6G|M6H|M6J|M5T|M5S|M5R|M4V"))

### Convert address to lat - long
biz_geo_loc = biz_geo_loc %>%
  tidygeocoder:: geocode(address = Address, method = "osm")

###check if any na
sapply(biz_geo_loc, function(x) sum(is.na(x)))

biz_geo_loc1 = biz_geo_loc[-which(is.na(biz_geo_loc$lat)),]
biz_geo_loc2 = biz_geo_loc[which(is.na(biz_geo_loc$lat)),]


###display on map
biz_geo_loc_sf = biz_geo_loc1 %>%
  st_as_sf(
    coords = c("long","lat"),
    crs = 4326
  )

biz_geo_loc_sf %>% mapview()
####################### End of Biz Data Conversion and Prepartion################################
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define Region of Interest - Boundary\n",
    "## coordinates manually looked up from location dataset\n",
    "#1406\t5370\tDUPONT ST AT OSSINGTON AVE (PX 842)\t-79.429019\t43.670031996501194\n",
    "# 251\t4180\tDUPONT ST AT SPADINA RD (PX 840)\t-79.407122\t43.67485699954096\n",
    "#1885\t5864\tCOLLEGE ST AT OSSINGTON AVE (PX 829)\t-79.422705\t43.65439999619167\n",
    "#241\t4170\tCOLLEGE ST AT SPADINA AVE (PX 279)\t-79.400048\t43.65794800150128\n",
    "\n",
    "# Input\n",
    "# Output\n",
    "\n",
    "boundary <- location %>%\n",
    "  select(location_id,location,lng,lat) %>%\n",
    "  filter(location_id %in% list(5370,4180,5864,4170)) # boundary intersection ID\n",
    "\n",
    "lng_min <- min(boundary$lng) # west most value since it's negative\n",
    "lng_max <- max(boundary$lng) # east most value\n",
    "lat_min <- min(boundary$lat) # south most value\n",
    "lat_max <- max(boundary$lat) # north most value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine Data for model building\n",
    "# what is the expected output of data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1 - Time Series Forecast\n",
    "# additional data processing needed before modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Model 2 - Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Result and Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
